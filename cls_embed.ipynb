{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "394fd2a47b379d55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Before we start\n",
    "\n",
    "We first need to go over the dependencies needed for this notebook to function properly."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "173a52054227e2f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use the following libraries:\n",
    "\n",
    "- `pandas` for data manipulation\n",
    "- `numpy` for numerical operations\n",
    "- `matplotlib` for visualization\n",
    "---\n",
    "- `json` for JSON manipulation\n",
    "---\n",
    "- `sklearn` for the Machine Learning algorithms, metrics and useful visualization tools such as t-SNE\n",
    "- `optuna` for hyperparameter tuning\n",
    "- `tensorflow` for the neural network model\n",
    "- `keras` for the neural network model\n",
    "- `tensorflow_docs` for the visualization tools used in the neural network model\n",
    "- `catboost` for the CatBoost model\n",
    "---\n",
    "- `chromadb` to retrieve the embeddings to a vector database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed0bdb4629e22923"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score # for cross-validation\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import catboost as cb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:22.837959100Z",
     "start_time": "2024-02-24T14:49:14.799959200Z"
    }
   },
   "id": "fa234cafe136d166",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Let's now retrieve the classification embeddings from the chromadb vector database and perform classification on them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb007503dc588dee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = client.get_collection(\"nomic_classification_v1\")"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:22.940517500Z",
     "start_time": "2024-02-24T14:49:22.838958900Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let us get the words along with their classes and division and sections from the json file we created earlier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84452ecc48ce9511"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"hierarchy.json\", \"r\") as f:\n",
    "    categories = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:22.947797200Z",
     "start_time": "2024-02-24T14:49:22.941517600Z"
    }
   },
   "id": "6185d3b32070a313",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's retrieve the embeddings and the words along with the class, division, and section from the chromadb and create a dataframe with them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d5ef59ed70ec91"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                   word                                          embedding  \\\n0             Existence  [-0.029754638671875, -0.0263671875, -0.0127792...   \n1           Inexistence  [-0.01029205322265625, 0.019256591796875, -0.0...   \n2         Consanguinity  [0.0386962890625, -0.01026153564453125, -0.013...   \n3            Trisection  [0.007350921630859375, -0.001903533935546875, ...   \n4             Innocence  [0.0338134765625, 0.0139923095703125, -0.03097...   \n...                 ...                                                ...   \n1052              Knave  [0.0032215118408203125, 0.01201629638671875, -...   \n1053  Disinterestedness  [-0.01776123046875, 0.020965576171875, -0.0221...   \n1054        Selfishness  [0.01071929931640625, 0.049468994140625, -0.03...   \n1055             Virtue  [0.0201416015625, 0.006626129150390625, -0.035...   \n1056               Vice  [0.0035228729248046875, -0.028533935546875, -0...   \n\n                                                class division  \\\n0                 WORDS EXPRESSING ABSTRACT RELATIONS      N/A   \n1                 WORDS EXPRESSING ABSTRACT RELATIONS      N/A   \n2                 WORDS EXPRESSING ABSTRACT RELATIONS      N/A   \n3                 WORDS EXPRESSING ABSTRACT RELATIONS      N/A   \n4     WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n...                                               ...      ...   \n1052  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n1053  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n1054  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n1055  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n1056  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n\n               section  \n0            EXISTENCE  \n1            EXISTENCE  \n2             RELATION  \n3               NUMBER  \n4     MORAL AFFECTIONS  \n...                ...  \n1052  MORAL AFFECTIONS  \n1053  MORAL AFFECTIONS  \n1054  MORAL AFFECTIONS  \n1055  MORAL AFFECTIONS  \n1056  MORAL AFFECTIONS  \n\n[1057 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>embedding</th>\n      <th>class</th>\n      <th>division</th>\n      <th>section</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Existence</td>\n      <td>[-0.029754638671875, -0.0263671875, -0.0127792...</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Inexistence</td>\n      <td>[-0.01029205322265625, 0.019256591796875, -0.0...</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Consanguinity</td>\n      <td>[0.0386962890625, -0.01026153564453125, -0.013...</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>RELATION</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trisection</td>\n      <td>[0.007350921630859375, -0.001903533935546875, ...</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>NUMBER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Innocence</td>\n      <td>[0.0338134765625, 0.0139923095703125, -0.03097...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>Knave</td>\n      <td>[0.0032215118408203125, 0.01201629638671875, -...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>Disinterestedness</td>\n      <td>[-0.01776123046875, 0.020965576171875, -0.0221...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>Selfishness</td>\n      <td>[0.01071929931640625, 0.049468994140625, -0.03...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>Virtue</td>\n      <td>[0.0201416015625, 0.006626129150390625, -0.035...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>Vice</td>\n      <td>[0.0035228729248046875, -0.028533935546875, -0...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n  </tbody>\n</table>\n<p>1057 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the embeddings, words, and metadata\n",
    "words = collection.get(include=[\"embeddings\", \"documents\"])['documents']\n",
    "embeddings = collection.get(include=[\"embeddings\", \"documents\"])['embeddings']\n",
    "metadata = collection.get(include=[\"embeddings\", \"documents\", \"metadatas\"])['metadatas']\n",
    "\n",
    "# Create a dataframe with the embeddings and the words\n",
    "cls_df = pd.DataFrame({'word': words, 'embedding': embeddings})\n",
    "\n",
    "# Add the class, division, and section from metadata to the dataframe\n",
    "cls_df['class'] = [md['class'] for md in metadata]\n",
    "cls_df['division'] = [md['division'] for md in metadata]\n",
    "cls_df['section'] = [md['section'] for md in metadata]\n",
    "\n",
    "cls_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:23.055412500Z",
     "start_time": "2024-02-24T14:49:22.944796200Z"
    }
   },
   "id": "b09af619c5292133",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the number of classes\n",
    "n_classes = cls_df['class'].nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:23.055412500Z",
     "start_time": "2024-02-24T14:49:23.051117100Z"
    }
   },
   "id": "cd0630a75478e058",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's prepare the data for classification by converting the class, division, and section to numerical values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3501a068561a6136"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                   word                                          embedding  \\\n0             Existence  [-0.029754638671875, -0.0263671875, -0.0127792...   \n1           Inexistence  [-0.01029205322265625, 0.019256591796875, -0.0...   \n2         Consanguinity  [0.0386962890625, -0.01026153564453125, -0.013...   \n3            Trisection  [0.007350921630859375, -0.001903533935546875, ...   \n4             Innocence  [0.0338134765625, 0.0139923095703125, -0.03097...   \n...                 ...                                                ...   \n1052              Knave  [0.0032215118408203125, 0.01201629638671875, -...   \n1053  Disinterestedness  [-0.01776123046875, 0.020965576171875, -0.0221...   \n1054        Selfishness  [0.01071929931640625, 0.049468994140625, -0.03...   \n1055             Virtue  [0.0201416015625, 0.006626129150390625, -0.035...   \n1056               Vice  [0.0035228729248046875, -0.028533935546875, -0...   \n\n      class  division  section  \n0         0         4        7  \n1         0         4        7  \n2         0         4       29  \n3         0         4       19  \n4         4         4       16  \n...     ...       ...      ...  \n1052      4         4       16  \n1053      4         4       16  \n1054      4         4       16  \n1055      4         4       16  \n1056      4         4       16  \n\n[1057 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>embedding</th>\n      <th>class</th>\n      <th>division</th>\n      <th>section</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Existence</td>\n      <td>[-0.029754638671875, -0.0263671875, -0.0127792...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Inexistence</td>\n      <td>[-0.01029205322265625, 0.019256591796875, -0.0...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Consanguinity</td>\n      <td>[0.0386962890625, -0.01026153564453125, -0.013...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trisection</td>\n      <td>[0.007350921630859375, -0.001903533935546875, ...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Innocence</td>\n      <td>[0.0338134765625, 0.0139923095703125, -0.03097...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>Knave</td>\n      <td>[0.0032215118408203125, 0.01201629638671875, -...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>Disinterestedness</td>\n      <td>[-0.01776123046875, 0.020965576171875, -0.0221...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>Selfishness</td>\n      <td>[0.01071929931640625, 0.049468994140625, -0.03...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>Virtue</td>\n      <td>[0.0201416015625, 0.006626129150390625, -0.035...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>Vice</td>\n      <td>[0.0035228729248046875, -0.028533935546875, -0...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n<p>1057 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all classes and divisions/sections as numerical values\n",
    "cls_df['class'] = pd.Categorical(cls_df['class'])\n",
    "cls_df['division'] = pd.Categorical(cls_df['division'])\n",
    "cls_df['section'] = pd.Categorical(cls_df['section'])\n",
    "\n",
    "cls_df['class'] = cls_df['class'].cat.codes\n",
    "cls_df['division'] = cls_df['division'].cat.codes\n",
    "cls_df['section'] = cls_df['section'].cat.codes\n",
    "cls_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:23.068412600Z",
     "start_time": "2024-02-24T14:49:23.053411700Z"
    }
   },
   "id": "516a1edf25fbdd15",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Easy to notice is that when the class has no division, the division is 4, which means `N/A` in our case.\n",
    "This will become important later when we perform the two-level classification.\n",
    "\n",
    "Let's also prepare the embeddings for classification by converting them to a numpy array."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "891ef0bbf5ddeecc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = np.vstack(cls_df['embedding'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:23.140141700Z",
     "start_time": "2024-02-24T14:49:23.067412500Z"
    }
   },
   "id": "1d2b8c0fca50cf83",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class logistic regression\n",
    "\n",
    "Let us start by training a multi-class logistic regression model on the embeddings and the class.\n",
    "\n",
    "Before we do that, however, let's split the data into training and testing sets, using 80% of the data for training and 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0da1d957a8e1533"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y = cls_df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:23.142141500Z",
     "start_time": "2024-02-24T14:49:23.090545600Z"
    }
   },
   "id": "e541551066686048",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's train a logistic regression model on the training data and evaluate it on the testing data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b8a7c1f9edc9e63"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=1000, multi_class='ovr', n_jobs=-1, random_state=42)",
      "text/html": "<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;ovr&#x27;, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;ovr&#x27;, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, multi_class='ovr' , n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:39:36.256954100Z",
     "start_time": "2024-02-24T14:39:34.458092500Z"
    }
   },
   "id": "2a20c0e4ce5e28ab",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65        43\n",
      "           1       0.73      0.61      0.67        31\n",
      "           2       0.79      0.56      0.66        34\n",
      "           3       0.70      0.73      0.72        26\n",
      "           4       0.55      0.63      0.59        27\n",
      "           5       0.66      0.75      0.70        51\n",
      "\n",
      "    accuracy                           0.67       212\n",
      "   macro avg       0.68      0.66      0.66       212\n",
      "weighted avg       0.68      0.67      0.67       212\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:39:36.259953600Z",
     "start_time": "2024-02-24T14:39:36.251954100Z"
    }
   },
   "id": "8caa5ddbc9c9df03",
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having trained and evaluated the model, we can see that the model has an accuracy of 0.67, \n",
    "which is not great but also not bad considering the previous results we got from the clustering of the embeddings.\n",
    "\n",
    "However, let's use a hyperparameter tuning library such as `optuna` to find the best hyperparameters for the model.\n",
    "\n",
    "We will use the `cross_val_score` function from `sklearn` to evaluate the model using cross-validation and the `optuna` library to find the best hyperparameters for the model based on the maximization of the accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f52da790af8442a3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 16:39:37,559] A new study created in memory with name: no-name-33ec3e39-0889-4146-b9b3-23350ecc4d3c\n",
      "[I 2024-02-24 16:39:43,075] Trial 0 finished with value: 0.21570240543682373 and parameters: {'multi_class': 'ovr', 'C': 0.00014787434096747015}. Best is trial 0 with value: 0.21570240543682373.\n",
      "[I 2024-02-24 16:39:48,240] Trial 1 finished with value: 0.27907538227666995 and parameters: {'multi_class': 'ovr', 'C': 0.07387018905518451}. Best is trial 1 with value: 0.27907538227666995.\n",
      "[I 2024-02-24 16:39:53,414] Trial 2 finished with value: 0.21570240543682373 and parameters: {'multi_class': 'multinomial', 'C': 0.0007336019894654171}. Best is trial 1 with value: 0.27907538227666995.\n",
      "[I 2024-02-24 16:39:58,590] Trial 3 finished with value: 0.21570240543682373 and parameters: {'multi_class': 'multinomial', 'C': 0.009009186083797662}. Best is trial 1 with value: 0.27907538227666995.\n",
      "[I 2024-02-24 16:40:03,787] Trial 4 finished with value: 0.4749441115979612 and parameters: {'multi_class': 'ovr', 'C': 2418.940985318291}. Best is trial 4 with value: 0.4749441115979612.\n",
      "[I 2024-02-24 16:40:09,598] Trial 5 finished with value: 0.4844049002950907 and parameters: {'multi_class': 'multinomial', 'C': 161.0829093422779}. Best is trial 5 with value: 0.4844049002950907.\n",
      "[I 2024-02-24 16:40:14,777] Trial 6 finished with value: 0.5184431726728069 and parameters: {'multi_class': 'ovr', 'C': 0.620275645544694}. Best is trial 6 with value: 0.5184431726728069.\n",
      "[I 2024-02-24 16:40:20,293] Trial 7 finished with value: 0.4673567021371725 and parameters: {'multi_class': 'multinomial', 'C': 9306.708401114189}. Best is trial 6 with value: 0.5184431726728069.\n",
      "[I 2024-02-24 16:40:25,575] Trial 8 finished with value: 0.5298086381114191 and parameters: {'multi_class': 'multinomial', 'C': 0.6250568543360635}. Best is trial 8 with value: 0.5298086381114191.\n",
      "[I 2024-02-24 16:40:30,752] Trial 9 finished with value: 0.31124921756237145 and parameters: {'multi_class': 'multinomial', 'C': 0.0724448144377768}. Best is trial 8 with value: 0.5298086381114191.\n",
      "[I 2024-02-24 16:40:36,364] Trial 10 finished with value: 0.5137351336850577 and parameters: {'multi_class': 'multinomial', 'C': 16.142925788775067}. Best is trial 8 with value: 0.5298086381114191.\n",
      "[I 2024-02-24 16:40:41,541] Trial 11 finished with value: 0.5392917821693641 and parameters: {'multi_class': 'ovr', 'C': 2.293456071506692}. Best is trial 11 with value: 0.5392917821693641.\n",
      "[I 2024-02-24 16:40:46,718] Trial 12 finished with value: 0.5241393186086023 and parameters: {'multi_class': 'ovr', 'C': 7.041567370175355}. Best is trial 11 with value: 0.5392917821693641.\n",
      "[I 2024-02-24 16:40:51,899] Trial 13 finished with value: 0.5345613878207994 and parameters: {'multi_class': 'ovr', 'C': 3.292405708662239}. Best is trial 11 with value: 0.5392917821693641.\n",
      "[I 2024-02-24 16:40:57,089] Trial 14 finished with value: 0.5061879638737369 and parameters: {'multi_class': 'ovr', 'C': 53.10306623500311}. Best is trial 11 with value: 0.5392917821693641.\n",
      "[I 2024-02-24 16:41:02,310] Trial 15 finished with value: 0.47021818832155954 and parameters: {'multi_class': 'ovr', 'C': 404.86686625114964}. Best is trial 11 with value: 0.5392917821693641.\n",
      "[I 2024-02-24 16:41:07,484] Trial 16 finished with value: 0.5269829205043369 and parameters: {'multi_class': 'ovr', 'C': 3.67513329503251}. Best is trial 11 with value: 0.5392917821693641.\n",
      "[I 2024-02-24 16:41:12,662] Trial 17 finished with value: 0.30273629616382003 and parameters: {'multi_class': 'ovr', 'C': 0.08685028607618073}. Best is trial 11 with value: 0.5392917821693641.\n",
      "[I 2024-02-24 16:41:17,841] Trial 18 finished with value: 0.5411830456943575 and parameters: {'multi_class': 'ovr', 'C': 1.8547566821076642}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:41:22,990] Trial 19 finished with value: 0.21570240543682373 and parameters: {'multi_class': 'ovr', 'C': 0.006030637970509985}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:41:28,170] Trial 20 finished with value: 0.4995081820620585 and parameters: {'multi_class': 'ovr', 'C': 0.4561648255998597}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:41:33,343] Trial 21 finished with value: 0.5279307878029151 and parameters: {'multi_class': 'ovr', 'C': 4.099419095717064}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:41:38,528] Trial 22 finished with value: 0.49764821604220694 and parameters: {'multi_class': 'ovr', 'C': 58.93561241895527}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:41:43,707] Trial 23 finished with value: 0.5383394437986229 and parameters: {'multi_class': 'ovr', 'C': 1.7381070701784422}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:41:48,870] Trial 24 finished with value: 0.42763122596798714 and parameters: {'multi_class': 'ovr', 'C': 0.2042961586930764}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:41:54,060] Trial 25 finished with value: 0.5118572833765537 and parameters: {'multi_class': 'ovr', 'C': 20.918427372577852}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:41:59,216] Trial 26 finished with value: 0.21570240543682373 and parameters: {'multi_class': 'ovr', 'C': 0.019420593651280373}. Best is trial 18 with value: 0.5411830456943575.\n",
      "[I 2024-02-24 16:42:04,393] Trial 27 finished with value: 0.5430698381471877 and parameters: {'multi_class': 'ovr', 'C': 1.8311898938374636}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:09,594] Trial 28 finished with value: 0.4834480908521863 and parameters: {'multi_class': 'ovr', 'C': 264.90856816012996}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:14,771] Trial 29 finished with value: 0.5373960475722078 and parameters: {'multi_class': 'ovr', 'C': 1.3052808530221869}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:19,952] Trial 30 finished with value: 0.5127827953143165 and parameters: {'multi_class': 'ovr', 'C': 14.084274367924522}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:25,131] Trial 31 finished with value: 0.5402351783957793 and parameters: {'multi_class': 'ovr', 'C': 1.6220807659164378}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:30,297] Trial 32 finished with value: 0.4436913171778592 and parameters: {'multi_class': 'ovr', 'C': 0.23301459073970876}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:35,439] Trial 33 finished with value: 0.21948046141464722 and parameters: {'multi_class': 'ovr', 'C': 0.03507592968402774}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:40,595] Trial 34 finished with value: 0.21570240543682373 and parameters: {'multi_class': 'ovr', 'C': 0.0006854080275840966}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:45,775] Trial 35 finished with value: 0.5402307073236161 and parameters: {'multi_class': 'ovr', 'C': 1.6833121405953082}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:50,954] Trial 36 finished with value: 0.42763122596798714 and parameters: {'multi_class': 'ovr', 'C': 0.20447312157721917}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:42:56,165] Trial 37 finished with value: 0.49860055441294826 and parameters: {'multi_class': 'ovr', 'C': 48.005897656310665}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:01,339] Trial 38 finished with value: 0.21570240543682373 and parameters: {'multi_class': 'multinomial', 'C': 0.0033922366390465772}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:06,529] Trial 39 finished with value: 0.5194133953322007 and parameters: {'multi_class': 'ovr', 'C': 7.952042818415765}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:11,816] Trial 40 finished with value: 0.5393007243136904 and parameters: {'multi_class': 'multinomial', 'C': 0.876995373780339}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:17,094] Trial 41 finished with value: 0.5392962532415273 and parameters: {'multi_class': 'multinomial', 'C': 0.9091265982499357}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:22,338] Trial 42 finished with value: 0.5250693016185282 and parameters: {'multi_class': 'multinomial', 'C': 0.5742632682038956}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:27,549] Trial 43 finished with value: 0.40400160958597875 and parameters: {'multi_class': 'multinomial', 'C': 0.13508553242217014}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:32,870] Trial 44 finished with value: 0.5411919878386836 and parameters: {'multi_class': 'multinomial', 'C': 1.419227582705239}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:38,388] Trial 45 finished with value: 0.5241437896807655 and parameters: {'multi_class': 'multinomial', 'C': 7.913293967433467}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:44,250] Trial 46 finished with value: 0.5383573280872753 and parameters: {'multi_class': 'multinomial', 'C': 1.935896788314893}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:49,523] Trial 47 finished with value: 0.5184476437449701 and parameters: {'multi_class': 'multinomial', 'C': 0.4989756136460368}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:54,680] Trial 48 finished with value: 0.2213672538674774 and parameters: {'multi_class': 'ovr', 'C': 0.03715226800731779}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:43:59,867] Trial 49 finished with value: 0.5203746758472682 and parameters: {'multi_class': 'ovr', 'C': 25.597673648088886}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:05,575] Trial 50 finished with value: 0.48062237324510415 and parameters: {'multi_class': 'multinomial', 'C': 748.0554594528693}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:11,015] Trial 51 finished with value: 0.528865241885004 and parameters: {'multi_class': 'multinomial', 'C': 4.487371500588088}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:16,356] Trial 52 finished with value: 0.5383528570151122 and parameters: {'multi_class': 'multinomial', 'C': 1.56261771413845}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:21,588] Trial 53 finished with value: 0.49571224179558254 and parameters: {'multi_class': 'multinomial', 'C': 0.3410598382579487}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:26,872] Trial 54 finished with value: 0.5317043727085755 and parameters: {'multi_class': 'multinomial', 'C': 0.6935176056487544}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:32,248] Trial 55 finished with value: 0.5355047840472145 and parameters: {'multi_class': 'multinomial', 'C': 3.0569476255348813}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:37,423] Trial 56 finished with value: 0.521309129929357 and parameters: {'multi_class': 'ovr', 'C': 8.367696332746073}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:42,603] Trial 57 finished with value: 0.5383483859429491 and parameters: {'multi_class': 'ovr', 'C': 1.047569228036775}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:47,812] Trial 58 finished with value: 0.3216534024859161 and parameters: {'multi_class': 'multinomial', 'C': 0.07508483527412337}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:52,994] Trial 59 finished with value: 0.5279263167307521 and parameters: {'multi_class': 'ovr', 'C': 3.987036842978037}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:44:58,215] Trial 60 finished with value: 0.493852275775731 and parameters: {'multi_class': 'ovr', 'C': 129.62268681641496}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:03,514] Trial 61 finished with value: 0.5411919878386837 and parameters: {'multi_class': 'multinomial', 'C': 0.9632666850898328}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:08,846] Trial 62 finished with value: 0.5364615934901188 and parameters: {'multi_class': 'multinomial', 'C': 2.1015783117346873}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:14,149] Trial 63 finished with value: 0.5383528570151123 and parameters: {'multi_class': 'multinomial', 'C': 0.8738603207998618}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:19,381] Trial 64 finished with value: 0.49570329965125637 and parameters: {'multi_class': 'multinomial', 'C': 0.32854279183625557}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:24,603] Trial 65 finished with value: 0.39171063220960384 and parameters: {'multi_class': 'multinomial', 'C': 0.12703521431000753}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:29,782] Trial 66 finished with value: 0.515626397210051 and parameters: {'multi_class': 'ovr', 'C': 13.475365389280887}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:34,959] Trial 67 finished with value: 0.5241482607529286 and parameters: {'multi_class': 'ovr', 'C': 5.262557452157163}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:40,283] Trial 68 finished with value: 0.5421398551372619 and parameters: {'multi_class': 'multinomial', 'C': 1.2819701855048387}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:45,495] Trial 69 finished with value: 0.5118617544487167 and parameters: {'multi_class': 'ovr', 'C': 32.79014683285383}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:50,686] Trial 70 finished with value: 0.5392917821693641 and parameters: {'multi_class': 'ovr', 'C': 2.27775697098187}. Best is trial 27 with value: 0.5430698381471877.\n",
      "[I 2024-02-24 16:45:55,997] Trial 71 finished with value: 0.5430877224358401 and parameters: {'multi_class': 'multinomial', 'C': 1.211768903470654}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:01,220] Trial 72 finished with value: 0.4919163015291067 and parameters: {'multi_class': 'multinomial', 'C': 0.3039402393115285}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:06,562] Trial 73 finished with value: 0.5421353840650988 and parameters: {'multi_class': 'multinomial', 'C': 1.2725761205063943}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:11,936] Trial 74 finished with value: 0.5355092551193776 and parameters: {'multi_class': 'multinomial', 'C': 2.862812835794071}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:17,198] Trial 75 finished with value: 0.5193955110435482 and parameters: {'multi_class': 'multinomial', 'C': 0.5115501489064285}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:22,735] Trial 76 finished with value: 0.5175221318072074 and parameters: {'multi_class': 'multinomial', 'C': 12.439028481363462}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:28,079] Trial 77 finished with value: 0.5393051953858535 and parameters: {'multi_class': 'multinomial', 'C': 1.3691415686338966}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:33,257] Trial 78 finished with value: 0.44180899579719213 and parameters: {'multi_class': 'multinomial', 'C': 0.1848789135928994}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:38,833] Trial 79 finished with value: 0.4692479656621658 and parameters: {'multi_class': 'multinomial', 'C': 8258.121846047588}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:44,164] Trial 80 finished with value: 0.5421398551372618 and parameters: {'multi_class': 'multinomial', 'C': 1.311176683369191}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:49,463] Trial 81 finished with value: 0.5411919878386838 and parameters: {'multi_class': 'multinomial', 'C': 1.1081034718920904}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:46:54,774] Trial 82 finished with value: 0.5411919878386837 and parameters: {'multi_class': 'multinomial', 'C': 0.9646248716989088}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:00,042] Trial 83 finished with value: 0.5260171689171063 and parameters: {'multi_class': 'multinomial', 'C': 0.6012311469698232}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:05,361] Trial 84 finished with value: 0.5411919878386838 and parameters: {'multi_class': 'multinomial', 'C': 1.0363955985814999}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:10,592] Trial 85 finished with value: 0.49570329965125637 and parameters: {'multi_class': 'multinomial', 'C': 0.32681992336858195}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:15,806] Trial 86 finished with value: 0.391715103281767 and parameters: {'multi_class': 'multinomial', 'C': 0.1263978181942728}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:21,267] Trial 87 finished with value: 0.5288831261736565 and parameters: {'multi_class': 'multinomial', 'C': 5.86597644385404}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:26,552] Trial 88 finished with value: 0.5392962532415273 and parameters: {'multi_class': 'multinomial', 'C': 0.9157625506194329}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:31,937] Trial 89 finished with value: 0.5364526513457928 and parameters: {'multi_class': 'multinomial', 'C': 3.0505067183536037}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:37,174] Trial 90 finished with value: 0.21570240543682373 and parameters: {'multi_class': 'multinomial', 'C': 0.00012011292301609818}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:42,495] Trial 91 finished with value: 0.5421398551372619 and parameters: {'multi_class': 'multinomial', 'C': 1.1961963540329694}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:47,742] Trial 92 finished with value: 0.5127649110256639 and parameters: {'multi_class': 'multinomial', 'C': 0.436133725664054}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:53,073] Trial 93 finished with value: 0.5411919878386838 and parameters: {'multi_class': 'multinomial', 'C': 1.1433023929537822}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:47:58,400] Trial 94 finished with value: 0.5402485916122687 and parameters: {'multi_class': 'multinomial', 'C': 1.2949007268429835}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:48:03,688] Trial 95 finished with value: 0.5326477689349907 and parameters: {'multi_class': 'multinomial', 'C': 0.702936505365562}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:48:09,074] Trial 96 finished with value: 0.5393007243136904 and parameters: {'multi_class': 'multinomial', 'C': 2.4055528261852706}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:48:14,496] Trial 97 finished with value: 0.5307609764821605 and parameters: {'multi_class': 'multinomial', 'C': 4.2539308495780475}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:48:20,016] Trial 98 finished with value: 0.5203567915586158 and parameters: {'multi_class': 'multinomial', 'C': 9.932269773896287}. Best is trial 71 with value: 0.5430877224358401.\n",
      "[I 2024-02-24 16:48:25,204] Trial 99 finished with value: 0.2516364124116963 and parameters: {'multi_class': 'multinomial', 'C': 0.04600548566211192}. Best is trial 71 with value: 0.5430877224358401.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'multi_class': 'multinomial', 'C': 1.211768903470654}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    multi_class = trial.suggest_categorical('multi_class', ['ovr', 'multinomial'])\n",
    "    C = trial.suggest_float('C', 1e-4, 1e4, log=True)\n",
    "\n",
    "    # Create logistic regression model with suggested hyperparameters\n",
    "    model = LogisticRegression(C=C, random_state=42, max_iter=1000, multi_class=multi_class , n_jobs=-1)\n",
    "    # Perform cross-validation and return the mean score\n",
    "    score = cross_val_score(model, X, y, scoring='accuracy')\n",
    "    return score.mean()\n",
    "\n",
    "\n",
    "# Create a study object and specify the optimization direction\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print('Best trial:', study.best_trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:48:25.208252800Z",
     "start_time": "2024-02-24T14:39:37.559180200Z"
    }
   },
   "id": "9e76682b23c63239",
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class SVM\n",
    "\n",
    "Let's now train a multi-class SVM model on the embeddings and the class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e86e3dc9de132389"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(random_state=22)",
      "text/html": "<style>#sk-container-id-6 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-6 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-6 pre {\n  padding: 0;\n}\n\n#sk-container-id-6 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-6 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-6 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-6 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-6 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-6 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-6 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-6 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-6 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-6 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-6 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-6 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-6 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-6 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n#sk-container-id-6 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-6 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-6 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-6 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-6 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-6 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-6 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-6 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=22)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(random_state=22)</pre></div> </div></div></div></div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=22)\n",
    "svm_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:41.567936200Z",
     "start_time": "2024-02-24T13:37:41.483041400Z"
    }
   },
   "id": "2c66c7edab0d64",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65        43\n",
      "           1       0.78      0.68      0.72        31\n",
      "           2       0.77      0.68      0.72        34\n",
      "           3       0.69      0.77      0.73        26\n",
      "           4       0.58      0.56      0.57        27\n",
      "           5       0.70      0.78      0.74        51\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.69      0.69      0.69       212\n",
      "weighted avg       0.70      0.69      0.69       212\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:41.699568600Z",
     "start_time": "2024-02-24T13:37:41.657120800Z"
    }
   },
   "id": "62835de5722c9451",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use the `optuna` library to find the best hyperparameters for the model based on the maximization of the accuracy.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a87564b264fa6a83"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:21:53,815] A new study created in memory with name: no-name-fbb0df03-3332-4ee6-88b9-63dab539915d\n",
      "[I 2024-02-24 15:21:54,150] Trial 0 finished with value: 0.4844272556559063 and parameters: {'C': 7.601359404948779, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.4844272556559063.\n",
      "[I 2024-02-24 15:21:54,670] Trial 1 finished with value: 0.21570240543682373 and parameters: {'C': 0.001925613168034482, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 0 with value: 0.4844272556559063.\n",
      "[I 2024-02-24 15:21:55,067] Trial 2 finished with value: 0.46643566127157293 and parameters: {'C': 24.637615145321337, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.4844272556559063.\n",
      "[I 2024-02-24 15:21:55,604] Trial 3 finished with value: 0.425744433515157 and parameters: {'C': 6832.795980529893, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.4844272556559063.\n",
      "[I 2024-02-24 15:21:56,014] Trial 4 finished with value: 0.5317401412858803 and parameters: {'C': 1.4379973680508373, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:56,618] Trial 5 finished with value: 0.21570240543682373 and parameters: {'C': 0.000217696136663899, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:57,206] Trial 6 finished with value: 0.21570240543682373 and parameters: {'C': 0.06706648734553318, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:57,771] Trial 7 finished with value: 0.21570240543682373 and parameters: {'C': 0.0003486572030786427, 'kernel': 'poly', 'gamma': 'scale', 'degree': 9}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:58,274] Trial 8 finished with value: 0.21570240543682373 and parameters: {'C': 0.00019261412167823918, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:58,703] Trial 9 finished with value: 0.5345748010372887 and parameters: {'C': 1349.686937395348, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:21:59,136] Trial 10 finished with value: 0.4626263077886078 and parameters: {'C': 44898.19741475613, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:00,089] Trial 11 finished with value: 0.5109049450058124 and parameters: {'C': 362.64192955214537, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:00,800] Trial 12 finished with value: 0.21665027273540197 and parameters: {'C': 0.16166637889362026, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:01,631] Trial 13 finished with value: 0.5109049450058124 and parameters: {'C': 457.7325417452622, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:02,233] Trial 14 finished with value: 0.21570240543682373 and parameters: {'C': 2.6596456078573207, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:02,836] Trial 15 finished with value: 0.21570240543682373 and parameters: {'C': 0.013186305784828524, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:03,275] Trial 16 finished with value: 0.42193508003219177 and parameters: {'C': 173.5294969190992, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:03,884] Trial 17 finished with value: 0.4711660556201377 and parameters: {'C': 5308.8213445462225, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:04,311] Trial 18 finished with value: 0.4607395153357775 and parameters: {'C': 35.01917464112912, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:04,974] Trial 19 finished with value: 0.21570240543682373 and parameters: {'C': 0.6164190668102112, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:05,393] Trial 20 finished with value: 0.4626263077886078 and parameters: {'C': 79144.72132756445, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:06,085] Trial 21 finished with value: 0.5109049450058124 and parameters: {'C': 736.8500821551859, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:06,747] Trial 22 finished with value: 0.5109049450058124 and parameters: {'C': 2094.8480298218074, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:07,406] Trial 23 finished with value: 0.5109049450058124 and parameters: {'C': 71.13359417171642, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:07,970] Trial 24 finished with value: 0.5364839488509345 and parameters: {'C': 1.2898399952483892, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 24 with value: 0.5364839488509345.\n",
      "[I 2024-02-24 15:22:08,554] Trial 25 finished with value: 0.5374139318608602 and parameters: {'C': 0.7230932292213924, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:09,184] Trial 26 finished with value: 0.21570240543682373 and parameters: {'C': 1.4471352501689741e-05, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:09,849] Trial 27 finished with value: 0.21570240543682373 and parameters: {'C': 0.018144029431884836, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:10,488] Trial 28 finished with value: 0.21570240543682373 and parameters: {'C': 0.24751487521293652, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:11,141] Trial 29 finished with value: 0.21570240543682373 and parameters: {'C': 10.378344769194756, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:11,497] Trial 30 finished with value: 0.5043101135652329 and parameters: {'C': 7.710235543437327, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:11,893] Trial 31 finished with value: 0.5393051953858536 and parameters: {'C': 0.9821176466487772, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:12,420] Trial 32 finished with value: 0.21570240543682373 and parameters: {'C': 0.023957248284480558, 'kernel': 'poly', 'gamma': 'scale', 'degree': 10}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:12,973] Trial 33 finished with value: 0.5307788607708128 and parameters: {'C': 2.007292432436496, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:13,419] Trial 34 finished with value: 0.5222659393722615 and parameters: {'C': 0.428706656618169, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:13,938] Trial 35 finished with value: 0.21570240543682373 and parameters: {'C': 0.003076987031322429, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:14,424] Trial 36 finished with value: 0.21570240543682373 and parameters: {'C': 3.2099247266279747, 'kernel': 'poly', 'gamma': 'auto', 'degree': 1}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:14,905] Trial 37 finished with value: 0.21570240543682373 and parameters: {'C': 0.07169969401820692, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:15,552] Trial 38 finished with value: 0.21570240543682373 and parameters: {'C': 16.025041858118353, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:16,069] Trial 39 finished with value: 0.21570240543682373 and parameters: {'C': 0.0037381167878459557, 'kernel': 'poly', 'gamma': 'scale', 'degree': 7}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:16,434] Trial 40 finished with value: 0.4626263077886078 and parameters: {'C': 21593.214598857678, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:16,820] Trial 41 finished with value: 0.5364705356344451 and parameters: {'C': 1.1698150360061574, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:17,221] Trial 42 finished with value: 0.5421398551372618 and parameters: {'C': 0.8233556021830791, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 42 with value: 0.5421398551372618.\n",
      "[I 2024-02-24 15:22:17,630] Trial 43 finished with value: 0.5459357954037378 and parameters: {'C': 0.751796233971926, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:18,116] Trial 44 finished with value: 0.21665027273540197 and parameters: {'C': 0.10817776622138571, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:18,543] Trial 45 finished with value: 0.5374273450773496 and parameters: {'C': 0.5448644436372487, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:18,900] Trial 46 finished with value: 0.5071268890279889 and parameters: {'C': 4.255075471261124, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:19,336] Trial 47 finished with value: 0.5364794777787714 and parameters: {'C': 0.5422385226700206, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:19,818] Trial 48 finished with value: 0.21570240543682373 and parameters: {'C': 0.04948907568078755, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:20,184] Trial 49 finished with value: 0.4616873826343557 and parameters: {'C': 42.58697250850883, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:20,652] Trial 50 finished with value: 0.46735223106500945 and parameters: {'C': 0.3004121182515278, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:21,038] Trial 51 finished with value: 0.541205401055173 and parameters: {'C': 1.1347945577487542, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:21,437] Trial 52 finished with value: 0.5411964589108468 and parameters: {'C': 0.8860052238966536, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:21,917] Trial 53 finished with value: 0.2904274344987928 and parameters: {'C': 0.17204781345243164, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:22,263] Trial 54 finished with value: 0.5137619601180363 and parameters: {'C': 3.4011581200321803, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:22,605] Trial 55 finished with value: 0.48726638647947773 and parameters: {'C': 6.432656089682004, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:22,960] Trial 56 finished with value: 0.4645533398909058 and parameters: {'C': 20.406183611007563, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:23,444] Trial 57 finished with value: 0.21570240543682373 and parameters: {'C': 0.04157224783572025, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:23,809] Trial 58 finished with value: 0.4626263077886078 and parameters: {'C': 95.90704161792591, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:24,294] Trial 59 finished with value: 0.21570240543682373 and parameters: {'C': 0.006704431105845286, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:24,682] Trial 60 finished with value: 0.5345748010372888 and parameters: {'C': 1.236608983033544, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:25,096] Trial 61 finished with value: 0.5431011356523293 and parameters: {'C': 0.7190603593664717, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:25,578] Trial 62 finished with value: 0.22704104444245732 and parameters: {'C': 0.1320401009237171, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:26,036] Trial 63 finished with value: 0.4929044084771529 and parameters: {'C': 0.3634492134956047, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:26,400] Trial 64 finished with value: 0.5345748010372887 and parameters: {'C': 1.8450902275469931, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:26,794] Trial 65 finished with value: 0.5440400608065815 and parameters: {'C': 1.0153308599928903, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:27,135] Trial 66 finished with value: 0.4825136367700974 and parameters: {'C': 9.814389807499674, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:27,529] Trial 67 finished with value: 0.5431011356523294 and parameters: {'C': 1.033051130805212, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:28,006] Trial 68 finished with value: 0.38408745417151036 and parameters: {'C': 0.21803648360561836, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:28,477] Trial 69 finished with value: 0.21570240543682373 and parameters: {'C': 0.0004999350391905135, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:29,028] Trial 70 finished with value: 0.5336358758830367 and parameters: {'C': 2.232089419195453, 'kernel': 'poly', 'gamma': 'scale', 'degree': 7}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:29,434] Trial 71 finished with value: 0.542144326209425 and parameters: {'C': 0.8000766304187258, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:29,847] Trial 72 finished with value: 0.5449923991773227 and parameters: {'C': 0.7327553642642187, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:30,202] Trial 73 finished with value: 0.5071492443888044 and parameters: {'C': 4.910351842357012, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:30,692] Trial 74 finished with value: 0.21570240543682373 and parameters: {'C': 0.06835665082698622, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:31,157] Trial 75 finished with value: 0.471134758114996 and parameters: {'C': 0.327076276738437, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:31,644] Trial 76 finished with value: 0.21570240543682373 and parameters: {'C': 0.03302706149767862, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:32,019] Trial 77 finished with value: 0.5345748010372887 and parameters: {'C': 1.75688732122823, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:32,525] Trial 78 finished with value: 0.21570240543682373 and parameters: {'C': 0.08460924014026831, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:32,876] Trial 79 finished with value: 0.47020924617723325 and parameters: {'C': 15.592646875269537, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:33,301] Trial 80 finished with value: 0.5440490029509075 and parameters: {'C': 0.711073742609546, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:33,709] Trial 81 finished with value: 0.5421398551372618 and parameters: {'C': 0.8964628292134403, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:34,138] Trial 82 finished with value: 0.5431011356523294 and parameters: {'C': 0.6520191273530229, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:34,636] Trial 83 finished with value: 0.44369131717785926 and parameters: {'C': 0.1978114966062945, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:35,073] Trial 84 finished with value: 0.5383707413037646 and parameters: {'C': 0.557726303171182, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:35,579] Trial 85 finished with value: 0.5232227488151658 and parameters: {'C': 2.988764946775258, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:36,062] Trial 86 finished with value: 0.519431279620853 and parameters: {'C': 0.4322847775280805, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:36,560] Trial 87 finished with value: 0.5014396852365197 and parameters: {'C': 6.843422616226855, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:37,078] Trial 88 finished with value: 0.21570240543682373 and parameters: {'C': 0.012122349937956727, 'kernel': 'poly', 'gamma': 'scale', 'degree': 6}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:37,548] Trial 89 finished with value: 0.21570240543682373 and parameters: {'C': 0.11950824827629233, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:38,028] Trial 90 finished with value: 0.5392962532415273 and parameters: {'C': 0.6683908109340915, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:38,410] Trial 91 finished with value: 0.5336314048108737 and parameters: {'C': 1.4834634070191286, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:38,818] Trial 92 finished with value: 0.540266475900921 and parameters: {'C': 0.8055984278138975, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:39,300] Trial 93 finished with value: 0.4597961191093624 and parameters: {'C': 0.28599700246719006, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:39,692] Trial 94 finished with value: 0.5222614683000983 and parameters: {'C': 2.7146086036731907, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:40,136] Trial 95 finished with value: 0.5449879281051596 and parameters: {'C': 1.003831959485295, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:40,492] Trial 96 finished with value: 0.5099704909237235 and parameters: {'C': 5.500791921280731, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:40,835] Trial 97 finished with value: 0.4967227041044442 and parameters: {'C': 11.772657150834235, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:41,353] Trial 98 finished with value: 0.21665027273540197 and parameters: {'C': 0.16566131148520663, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:41,709] Trial 99 finished with value: 0.4531834033801306 and parameters: {'C': 32.66110696578537, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'C': 0.751796233971926, 'kernel': 'linear', 'gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    C = trial.suggest_float('C', 1e-5, 1e5, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "\n",
    "    # If kernel is 'poly', we also tune degree\n",
    "    if kernel == 'poly':\n",
    "        degree = trial.suggest_int('degree', 1, 10)\n",
    "\n",
    "    # Create and train the SVM model\n",
    "    if kernel == 'poly':\n",
    "        model = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, random_state=22)\n",
    "    else:\n",
    "        model = SVC(C=C, kernel=kernel, gamma=gamma, random_state=22)\n",
    "\n",
    "    score = cross_val_score(model, X, y, scoring='accuracy')\n",
    "    return score.mean()\n",
    "\n",
    "\n",
    "# Create a study object and specify the optimization direction\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print('Best trial:', study.best_trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:22:41.713803300Z",
     "start_time": "2024-02-24T13:21:53.816564400Z"
    }
   },
   "id": "3352fe02bac0f7c4",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class SGD\n",
    "\n",
    "Let's now train a multi-class SGD model on the embeddings and the class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78bd39336c8fa4c1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SGDClassifier(alpha=2.6545371602330262e-06, eta0=0.007698135990041223,\n              learning_rate='adaptive', loss='squared_hinge', n_jobs=-1,\n              random_state=42)",
      "text/html": "<style>#sk-container-id-7 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-7 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-7 pre {\n  padding: 0;\n}\n\n#sk-container-id-7 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-7 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-7 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-7 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-7 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-7 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-7 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-7 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-7 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-7 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-7 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-7 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-7 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-7 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n#sk-container-id-7 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-7 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-7 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-7 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-7 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-7 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-7 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-7 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=2.6545371602330262e-06, eta0=0.007698135990041223,\n              learning_rate=&#x27;adaptive&#x27;, loss=&#x27;squared_hinge&#x27;, n_jobs=-1,\n              random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(alpha=2.6545371602330262e-06, eta0=0.007698135990041223,\n              learning_rate=&#x27;adaptive&#x27;, loss=&#x27;squared_hinge&#x27;, n_jobs=-1,\n              random_state=42)</pre></div> </div></div></div></div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model = SGDClassifier(loss='squared_hinge', max_iter=1000, n_jobs=-1, random_state=42,\n",
    "                          penalty='l2', alpha=2.6545371602330262e-06,\n",
    "                          learning_rate='adaptive', eta0=0.007698135990041223)\n",
    "sgd_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:47.218605400Z",
     "start_time": "2024-02-24T13:37:47.065594200Z"
    }
   },
   "id": "52c78921d9b40eea",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73        43\n",
      "           1       0.73      0.71      0.72        31\n",
      "           2       0.76      0.74      0.75        34\n",
      "           3       0.67      0.69      0.68        26\n",
      "           4       0.62      0.67      0.64        27\n",
      "           5       0.72      0.76      0.74        51\n",
      "\n",
      "    accuracy                           0.72       212\n",
      "   macro avg       0.71      0.71      0.71       212\n",
      "weighted avg       0.72      0.72      0.72       212\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:47.428834600Z",
     "start_time": "2024-02-24T13:37:47.419665Z"
    }
   },
   "id": "fe95d6f1c77a888d",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use the `optuna` library to find the best hyperparameters for the model based on the maximization of the accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc1256b67572c199"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:24:16,607] A new study created in memory with name: no-name-92fe01f2-11bc-4229-83df-456aa2fb7503\n",
      "[I 2024-02-24 15:24:17,084] Trial 0 finished with value: 0.6047337278106509 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'alpha': 5.849013687796652e-06, 'learning_rate': 'adaptive', 'eta0': 0.0013475657567535645}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:17,609] Trial 1 finished with value: 0.4958579881656805 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 0.02749692429366791, 'learning_rate': 'constant', 'eta0': 0.02176202623344909}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:18,008] Trial 2 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.997101470441552e-05, 'learning_rate': 'invscaling', 'eta0': 0.00022191668819864202}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:20,501] Trial 3 finished with value: 0.5396449704142012 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 0.0027546216060563697, 'learning_rate': 'optimal', 'eta0': 0.018066274256286548}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:21,326] Trial 4 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.02074583715225828, 'learning_rate': 'constant', 'eta0': 0.0003352475325948246}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:21,547] Trial 5 finished with value: 0.2201183431952663 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.05143432818927347, 'learning_rate': 'optimal', 'eta0': 0.00012016007598521636}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:22,919] Trial 6 finished with value: 0.5893491124260355 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 3.622916129577757e-06, 'learning_rate': 'optimal', 'eta0': 5.1519238307542115e-05}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:29,176] Trial 7 finished with value: 0.6142011834319527 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 2.4658544456124004e-06, 'learning_rate': 'adaptive', 'eta0': 0.041784241447272046}. Best is trial 7 with value: 0.6142011834319527.\n",
      "[I 2024-02-24 15:24:38,191] Trial 8 finished with value: 0.20946745562130178 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 0.01089458426470588, 'learning_rate': 'invscaling', 'eta0': 0.0003731696632510087}. Best is trial 7 with value: 0.6142011834319527.\n",
      "[I 2024-02-24 15:24:38,972] Trial 9 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 2.9232576203632103e-06, 'learning_rate': 'constant', 'eta0': 0.0015070036355670194}. Best is trial 7 with value: 0.6142011834319527.\n",
      "[I 2024-02-24 15:24:43,898] Trial 10 finished with value: 0.6390532544378698 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 6.589324727664278e-05, 'learning_rate': 'adaptive', 'eta0': 0.08356603976765953}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:24:48,910] Trial 11 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.00015472275939682194, 'learning_rate': 'adaptive', 'eta0': 0.07214098202895726}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:24:50,617] Trial 12 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.00013082160055436523, 'learning_rate': 'adaptive', 'eta0': 0.006157260960841587}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:24:55,857] Trial 13 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.00022018770025387775, 'learning_rate': 'adaptive', 'eta0': 0.08714171846882023}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:01,245] Trial 14 finished with value: 0.5207100591715975 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 4.17909630361708e-05, 'learning_rate': 'adaptive', 'eta0': 1.3261119506900109e-05}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:03,856] Trial 15 finished with value: 0.6082840236686391 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.0009466504317401401, 'learning_rate': 'adaptive', 'eta0': 0.006781869493491628}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:08,408] Trial 16 finished with value: 0.5644970414201185 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.0009254901771484319, 'learning_rate': 'adaptive', 'eta0': 0.07813984729698077}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:09,761] Trial 17 finished with value: 0.5988165680473372 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 4.461737082127643e-05, 'learning_rate': 'adaptive', 'eta0': 0.005397831626914724}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:10,106] Trial 18 finished with value: 0.5680473372781065 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.0005269081311306156, 'learning_rate': 'invscaling', 'eta0': 0.01847177863689828}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:11,404] Trial 19 finished with value: 0.6319526627218934 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.368260880751569e-05, 'learning_rate': 'adaptive', 'eta0': 0.002339578979223399}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:12,710] Trial 20 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.1656724363060256e-05, 'learning_rate': 'adaptive', 'eta0': 0.0023451391210514974}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:18,284] Trial 21 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 9.129068390023895e-05, 'learning_rate': 'adaptive', 'eta0': 0.03833904395068281}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:23,936] Trial 22 finished with value: 0.6390532544378699 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 6.094233103368964e-05, 'learning_rate': 'adaptive', 'eta0': 0.03109242239810391}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:29,518] Trial 23 finished with value: 0.6366863905325444 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.0077028865768343e-06, 'learning_rate': 'adaptive', 'eta0': 0.03027255997202756}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:30,875] Trial 24 finished with value: 0.6106508875739645 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 6.298287413893196e-05, 'learning_rate': 'adaptive', 'eta0': 0.010208342086710027}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:36,649] Trial 25 finished with value: 0.6378698224852072 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 9.333890637054054e-05, 'learning_rate': 'adaptive', 'eta0': 0.03271768553364727}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:40,416] Trial 26 finished with value: 0.6402366863905327 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 2.4517122913654277e-05, 'learning_rate': 'constant', 'eta0': 0.051398377365923134}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:40,980] Trial 27 finished with value: 0.1668639053254438 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.003040172537221823, 'learning_rate': 'constant', 'eta0': 0.011143504220698161}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:42,578] Trial 28 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 3.368863594442148e-05, 'learning_rate': 'constant', 'eta0': 0.044670007113525256}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:42,867] Trial 29 finished with value: 0.5218934911242603 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 6.131674963415057e-06, 'learning_rate': 'constant', 'eta0': 0.0029964481147388596}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:42,985] Trial 30 finished with value: 0.5171597633136095 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'alpha': 0.0004042595929359824, 'learning_rate': 'constant', 'eta0': 0.01331598840483221}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:48,276] Trial 31 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 2.2626975368050612e-05, 'learning_rate': 'adaptive', 'eta0': 0.05078285892294987}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:48,603] Trial 32 finished with value: 0.6047337278106509 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 8.48230027257953e-05, 'learning_rate': 'invscaling', 'eta0': 0.09505167605303566}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:49,992] Trial 33 finished with value: 0.6118343195266271 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 9.162039909506961e-06, 'learning_rate': 'optimal', 'eta0': 0.026192826582771528}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:54,082] Trial 34 finished with value: 0.6343195266272189 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.0002365930290977371, 'learning_rate': 'constant', 'eta0': 0.05231901036370639}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:00,077] Trial 35 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.143420229730486e-05, 'learning_rate': 'adaptive', 'eta0': 0.020428283199518556}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:04,008] Trial 36 finished with value: 0.6224852071005917 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 2.6099381430023626e-05, 'learning_rate': 'constant', 'eta0': 0.01950741511716031}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:05,758] Trial 37 finished with value: 0.6082840236686391 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.961410920515086e-05, 'learning_rate': 'optimal', 'eta0': 0.0006325547775143147}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:06,717] Trial 38 finished with value: 0.527810650887574 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 6.520491994011774e-06, 'learning_rate': 'invscaling', 'eta0': 0.0047027675379338624}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:11,757] Trial 39 finished with value: 0.6295857988165681 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 0.0008312018683092522, 'learning_rate': 'adaptive', 'eta0': 0.012902186487012749}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:12,397] Trial 40 finished with value: 0.629585798816568 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.0001442648624306383, 'learning_rate': 'optimal', 'eta0': 0.023642247680951686}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:17,206] Trial 41 finished with value: 0.6355029585798817 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 6.108223589075113e-05, 'learning_rate': 'adaptive', 'eta0': 0.05905816590017775}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:22,452] Trial 42 finished with value: 0.6449704142011834 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.729800114837331e-05, 'learning_rate': 'adaptive', 'eta0': 0.033509293980144975}. Best is trial 42 with value: 0.6449704142011834.\n",
      "[I 2024-02-24 15:26:27,804] Trial 43 finished with value: 0.6461538461538462 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.7499949023290976e-05, 'learning_rate': 'adaptive', 'eta0': 0.03319923042456373}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:31,454] Trial 44 finished with value: 0.5609467455621302 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.7621278758057134e-06, 'learning_rate': 'adaptive', 'eta0': 0.00880784824834428}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:37,542] Trial 45 finished with value: 0.6426035502958581 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.7440042741295888e-06, 'learning_rate': 'adaptive', 'eta0': 0.017623850473962473}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:41,304] Trial 46 finished with value: 0.6142011834319526 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 1.4423096221857117e-06, 'learning_rate': 'constant', 'eta0': 0.034002953946884}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:46,941] Trial 47 finished with value: 0.6142011834319527 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.593211858817286e-06, 'learning_rate': 'adaptive', 'eta0': 0.014988404944759112}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:47,259] Trial 48 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.9173757848567267e-06, 'learning_rate': 'invscaling', 'eta0': 7.023619819020812e-05}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:48,591] Trial 49 finished with value: 0.6153846153846153 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.3074713151045884e-05, 'learning_rate': 'adaptive', 'eta0': 0.0010075540222191607}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:53,889] Trial 50 finished with value: 0.6390532544378699 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 7.742939554346577e-06, 'learning_rate': 'adaptive', 'eta0': 0.0439092946727205}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:00,130] Trial 51 finished with value: 0.6402366863905324 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.756650371494326e-05, 'learning_rate': 'adaptive', 'eta0': 0.01725164367434085}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:05,012] Trial 52 finished with value: 0.6272189349112426 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.080318847179081e-05, 'learning_rate': 'adaptive', 'eta0': 0.06868712243602494}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:10,698] Trial 53 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.5139324229184716e-06, 'learning_rate': 'adaptive', 'eta0': 0.022755423722794578}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:15,950] Trial 54 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.1349372544940304e-05, 'learning_rate': 'adaptive', 'eta0': 0.0406391196291012}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:17,472] Trial 55 finished with value: 0.6307692307692309 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 0.00010879128576158248, 'learning_rate': 'adaptive', 'eta0': 0.003801484093519012}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:18,999] Trial 56 finished with value: 0.6153846153846154 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 0.00021438572253088046, 'learning_rate': 'optimal', 'eta0': 0.008107910827243379}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:19,253] Trial 57 finished with value: 0.6047337278106509 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'alpha': 1.0349142361786697e-05, 'learning_rate': 'adaptive', 'eta0': 1.5894750858133533e-05}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:24,160] Trial 58 finished with value: 0.6201183431952663 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.8339055783562057e-05, 'learning_rate': 'adaptive', 'eta0': 0.09418321880152757}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:27,741] Trial 59 finished with value: 0.6366863905325444 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.612901291256103e-05, 'learning_rate': 'constant', 'eta0': 0.06042658452201947}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:29,979] Trial 60 finished with value: 0.3266272189349112 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 4.222195503637995e-06, 'learning_rate': 'adaptive', 'eta0': 0.0002209500955097753}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:35,543] Trial 61 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.6175731446975987e-06, 'learning_rate': 'adaptive', 'eta0': 0.023740258123560534}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:41,233] Trial 62 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.0317760235238744e-06, 'learning_rate': 'adaptive', 'eta0': 0.02136314822286426}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:46,600] Trial 63 finished with value: 0.6331360946745562 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.540962524625386e-06, 'learning_rate': 'adaptive', 'eta0': 0.03690411791753403}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:52,677] Trial 64 finished with value: 0.6260355029585799 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 5.26171863566028e-06, 'learning_rate': 'adaptive', 'eta0': 0.01598755568285184}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:53,544] Trial 65 finished with value: 0.6390532544378699 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 0.014164119490744293, 'learning_rate': 'adaptive', 'eta0': 0.028181530778404625}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:56,284] Trial 66 finished with value: 0.18224852071005918 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 0.050569739746178774, 'learning_rate': 'adaptive', 'eta0': 0.007230384154053116}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:00,535] Trial 67 finished with value: 0.6071005917159763 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.4364807854786401e-05, 'learning_rate': 'constant', 'eta0': 0.012313921642563681}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:00,804] Trial 68 finished with value: 0.5384615384615385 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 1.7327964392623613e-06, 'learning_rate': 'invscaling', 'eta0': 0.07236881796373945}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:05,953] Trial 69 finished with value: 0.6366863905325444 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 8.122723961897233e-05, 'learning_rate': 'adaptive', 'eta0': 0.04597295428927044}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:11,736] Trial 70 finished with value: 0.6366863905325444 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 2.881835059095232e-05, 'learning_rate': 'adaptive', 'eta0': 0.02733796761417704}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:17,485] Trial 71 finished with value: 0.6390532544378699 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.1348685796616186e-06, 'learning_rate': 'adaptive', 'eta0': 0.02281236536068055}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:23,530] Trial 72 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 7.934722287542843e-06, 'learning_rate': 'adaptive', 'eta0': 0.02027568566039753}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:28,137] Trial 73 finished with value: 0.5633136094674557 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.0181553918743127e-06, 'learning_rate': 'adaptive', 'eta0': 0.010083061150161705}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:33,871] Trial 74 finished with value: 0.6355029585798817 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.2858028497333426e-06, 'learning_rate': 'adaptive', 'eta0': 0.031373631761620856}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:37,567] Trial 75 finished with value: 0.6355029585798817 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.383630875530443e-05, 'learning_rate': 'constant', 'eta0': 0.05719417373653118}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:43,721] Trial 76 finished with value: 0.6331360946745562 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.98513114866299e-06, 'learning_rate': 'adaptive', 'eta0': 0.016537481341585433}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:44,032] Trial 77 finished with value: 0.6248520710059171 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 0.003872411961116476, 'learning_rate': 'optimal', 'eta0': 0.02706755209776727}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:49,390] Trial 78 finished with value: 0.6414201183431952 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.1317787288624247e-05, 'learning_rate': 'adaptive', 'eta0': 0.03792404261143385}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:54,758] Trial 79 finished with value: 0.6142011834319527 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 1.111629341915845e-05, 'learning_rate': 'adaptive', 'eta0': 0.042097302347849405}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:55,309] Trial 80 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 2.39577120875724e-05, 'learning_rate': 'invscaling', 'eta0': 0.07867622985011734}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:00,875] Trial 81 finished with value: 0.6426035502958579 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 6.0603723744988215e-06, 'learning_rate': 'adaptive', 'eta0': 0.03250384817821399}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:06,445] Trial 82 finished with value: 0.6402366863905324 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 6.133728148303729e-06, 'learning_rate': 'adaptive', 'eta0': 0.03604613772705587}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:11,610] Trial 83 finished with value: 0.6319526627218934 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.6519577301724026e-05, 'learning_rate': 'adaptive', 'eta0': 0.05230894739829345}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:17,301] Trial 84 finished with value: 0.6414201183431952 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 8.152398768953956e-06, 'learning_rate': 'adaptive', 'eta0': 0.03612362602656391}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:20,829] Trial 85 finished with value: 0.621301775147929 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 9.324509642630837e-06, 'learning_rate': 'constant', 'eta0': 0.09801696771656891}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:28,705] Trial 86 finished with value: 0.6295857988165681 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.312578783182247e-05, 'learning_rate': 'adaptive', 'eta0': 0.06560105052700987}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:30,371] Trial 87 finished with value: 0.6082840236686391 and parameters: {'loss': 'perceptron', 'penalty': 'elasticnet', 'alpha': 3.596316541720573e-05, 'learning_rate': 'adaptive', 'eta0': 0.0380677037021714}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:32,648] Trial 88 finished with value: 0.6272189349112426 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.4041182862169785e-05, 'learning_rate': 'adaptive', 'eta0': 0.001825738121680838}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:41,807] Trial 89 finished with value: 0.6011834319526628 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 7.268343629978522e-06, 'learning_rate': 'adaptive', 'eta0': 0.013217401165933477}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:43,561] Trial 90 finished with value: 0.5928994082840237 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.877475500937537e-06, 'learning_rate': 'optimal', 'eta0': 0.04712126042135343}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:49,660] Trial 91 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.632998727978862e-06, 'learning_rate': 'adaptive', 'eta0': 0.03192419064252167}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:55,711] Trial 92 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.064220540824863e-05, 'learning_rate': 'adaptive', 'eta0': 0.018577702171666956}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:01,372] Trial 93 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.0087416452567715e-05, 'learning_rate': 'adaptive', 'eta0': 0.023155230359199735}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:06,537] Trial 94 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.90458921367411e-05, 'learning_rate': 'adaptive', 'eta0': 0.05462757278666812}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:11,843] Trial 95 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.480110009535194e-05, 'learning_rate': 'adaptive', 'eta0': 0.03515945949812483}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:13,290] Trial 96 finished with value: 0.5455621301775148 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 5.21180559585955e-06, 'learning_rate': 'constant', 'eta0': 0.009875472269278235}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:18,860] Trial 97 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.1270292862131553e-06, 'learning_rate': 'adaptive', 'eta0': 0.026803505699946262}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:24,199] Trial 98 finished with value: 0.6272189349112426 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 6.688330585800623e-05, 'learning_rate': 'adaptive', 'eta0': 0.015511386799331539}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:29,355] Trial 99 finished with value: 0.6236686390532544 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 8.205474790778455e-06, 'learning_rate': 'adaptive', 'eta0': 0.07998705012365065}. Best is trial 43 with value: 0.6461538461538462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.7499949023290976e-05, 'learning_rate': 'adaptive', 'eta0': 0.03319923042456373}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    loss = trial.suggest_categorical('loss', ['hinge', 'log_loss', 'squared_hinge', 'perceptron'])\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'l1', 'elasticnet'])\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1e-1, log=True)\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive'])\n",
    "    eta0 = trial.suggest_float('eta0', 1e-5, 1e-1, log=True)  # Only relevant for certain learning rates\n",
    "\n",
    "    # Create and train the SGD Classifier\n",
    "    model = SGDClassifier(loss=loss, penalty=penalty, alpha=alpha, learning_rate=learning_rate, eta0=eta0,\n",
    "                          random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Perform cross-validation and return the mean score\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)  # cv=5 for 5-fold cross-validation\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "# Create a study object and specify the optimization direction\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # Adjust the number of trials as needed\n",
    "\n",
    "# Best hyperparameters\n",
    "print('Best trial:', study.best_trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:30:29.359516Z",
     "start_time": "2024-02-24T13:24:16.607724900Z"
    }
   },
   "id": "4477cdb859019617",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "We notice that the SGD model gave the best accuracy of 0.72, which is the highest among the models we have tried so far.\n",
    "\n",
    "So, we will get the best hyperparameters for the model and use them to train the model again, for later use."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68f9ee6d9062ffe6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SGDClassifier(alpha=1.7499949023290976e-05, eta0=0.03319923042456373,\n              learning_rate='adaptive', penalty='elasticnet', random_state=42)",
      "text/html": "<style>#sk-container-id-12 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-12 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-12 pre {\n  padding: 0;\n}\n\n#sk-container-id-12 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-12 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-12 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-12 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-12 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-12 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-12 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-12 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-12 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-12 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-12 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-12 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-12 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-12 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-12 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-12 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n#sk-container-id-12 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-12 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-12 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-12 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-12 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-12 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-12 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-12 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-12 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-12 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=1.7499949023290976e-05, eta0=0.03319923042456373,\n              learning_rate=&#x27;adaptive&#x27;, penalty=&#x27;elasticnet&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(alpha=1.7499949023290976e-05, eta0=0.03319923042456373,\n              learning_rate=&#x27;adaptive&#x27;, penalty=&#x27;elasticnet&#x27;, random_state=42)</pre></div> </div></div></div></div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "sgd_model = SGDClassifier(**best_params, random_state=42)\n",
    "sgd_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:31:30.169150200Z",
     "start_time": "2024-02-24T13:31:28.113148500Z"
    }
   },
   "id": "114f2bb29b45ae2d",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class Naive Bayes\n",
    "\n",
    "It is known that Naive Bayes is a simple and effective algorithm for classification for NLP tasks. \n",
    "Let's now train a multi-class Naive Bayes model on the embeddings and the class, to see how it performs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fab4ff2e2e09606"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        43\n",
      "           1       0.64      0.68      0.66        31\n",
      "           2       0.71      0.71      0.71        34\n",
      "           3       0.65      0.77      0.70        26\n",
      "           4       0.48      0.48      0.48        27\n",
      "           5       0.67      0.65      0.66        51\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.64      0.65      0.65       212\n",
      "weighted avg       0.65      0.65      0.65       212\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:32:25.746345800Z",
     "start_time": "2024-02-24T13:32:25.733285500Z"
    }
   },
   "id": "fa13a14098b3636c",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the Naive Bayes model has an accuracy of 0.65, which does not differ much from the logistic regression model.\n",
    "So there is no need to use `optuna` to find the best hyperparameters for the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e859bc93b6dcd506"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class Random Forest\n",
    "\n",
    "Let's now train a multi-class Random Forest model on the embeddings and the class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c9e62a3e6912a48"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61        43\n",
      "           1       0.86      0.61      0.72        31\n",
      "           2       0.90      0.56      0.69        34\n",
      "           3       0.71      0.65      0.68        26\n",
      "           4       0.55      0.67      0.60        27\n",
      "           5       0.59      0.73      0.65        51\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.70      0.64      0.66       212\n",
      "weighted avg       0.68      0.65      0.66       212\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=15,\n",
    "                               max_depth=100, min_samples_split=2, min_samples_leaf=1, max_features='sqrt')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:32:40.117971900Z",
     "start_time": "2024-02-24T13:32:36.844346100Z"
    }
   },
   "id": "a8fc25a6a41a309b",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class CatBoost\n",
    "\n",
    "Having tried the above models, let us now proceed to more advanced models such as CatBoost, \n",
    "which is a gradient boosting library that is known to perform well on tabular data, to see how it performs \n",
    "and if it can outperform the other models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28cda8d8bf460600"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.134538\n",
      "0:\tlearn: 1.7254025\ttotal: 26.8ms\tremaining: 10.7s\n",
      "1:\tlearn: 1.6695749\ttotal: 51.8ms\tremaining: 10.3s\n",
      "2:\tlearn: 1.6175593\ttotal: 76ms\tremaining: 10.1s\n",
      "3:\tlearn: 1.5654316\ttotal: 98.7ms\tremaining: 9.77s\n",
      "4:\tlearn: 1.5203243\ttotal: 123ms\tremaining: 9.69s\n",
      "5:\tlearn: 1.4711252\ttotal: 147ms\tremaining: 9.65s\n",
      "6:\tlearn: 1.4305325\ttotal: 172ms\tremaining: 9.68s\n",
      "7:\tlearn: 1.3919494\ttotal: 197ms\tremaining: 9.66s\n",
      "8:\tlearn: 1.3552363\ttotal: 221ms\tremaining: 9.62s\n",
      "9:\tlearn: 1.3184468\ttotal: 245ms\tremaining: 9.55s\n",
      "10:\tlearn: 1.2855703\ttotal: 267ms\tremaining: 9.43s\n",
      "11:\tlearn: 1.2561113\ttotal: 289ms\tremaining: 9.34s\n",
      "12:\tlearn: 1.2270124\ttotal: 310ms\tremaining: 9.22s\n",
      "13:\tlearn: 1.1986041\ttotal: 331ms\tremaining: 9.13s\n",
      "14:\tlearn: 1.1696553\ttotal: 352ms\tremaining: 9.04s\n",
      "15:\tlearn: 1.1413859\ttotal: 374ms\tremaining: 8.98s\n",
      "16:\tlearn: 1.1152895\ttotal: 395ms\tremaining: 8.91s\n",
      "17:\tlearn: 1.0871917\ttotal: 417ms\tremaining: 8.86s\n",
      "18:\tlearn: 1.0641851\ttotal: 438ms\tremaining: 8.79s\n",
      "19:\tlearn: 1.0398989\ttotal: 460ms\tremaining: 8.74s\n",
      "20:\tlearn: 1.0156924\ttotal: 482ms\tremaining: 8.7s\n",
      "21:\tlearn: 0.9948616\ttotal: 503ms\tremaining: 8.65s\n",
      "22:\tlearn: 0.9726854\ttotal: 525ms\tremaining: 8.6s\n",
      "23:\tlearn: 0.9536191\ttotal: 545ms\tremaining: 8.54s\n",
      "24:\tlearn: 0.9316483\ttotal: 566ms\tremaining: 8.49s\n",
      "25:\tlearn: 0.9129895\ttotal: 587ms\tremaining: 8.45s\n",
      "26:\tlearn: 0.8971149\ttotal: 609ms\tremaining: 8.41s\n",
      "27:\tlearn: 0.8806011\ttotal: 629ms\tremaining: 8.36s\n",
      "28:\tlearn: 0.8645505\ttotal: 650ms\tremaining: 8.31s\n",
      "29:\tlearn: 0.8487692\ttotal: 671ms\tremaining: 8.27s\n",
      "30:\tlearn: 0.8300379\ttotal: 692ms\tremaining: 8.24s\n",
      "31:\tlearn: 0.8133141\ttotal: 714ms\tremaining: 8.21s\n",
      "32:\tlearn: 0.7992926\ttotal: 734ms\tremaining: 8.16s\n",
      "33:\tlearn: 0.7830541\ttotal: 755ms\tremaining: 8.13s\n",
      "34:\tlearn: 0.7664586\ttotal: 776ms\tremaining: 8.09s\n",
      "35:\tlearn: 0.7521716\ttotal: 796ms\tremaining: 8.05s\n",
      "36:\tlearn: 0.7375230\ttotal: 816ms\tremaining: 8.01s\n",
      "37:\tlearn: 0.7250831\ttotal: 836ms\tremaining: 7.96s\n",
      "38:\tlearn: 0.7111226\ttotal: 855ms\tremaining: 7.91s\n",
      "39:\tlearn: 0.6979888\ttotal: 876ms\tremaining: 7.88s\n",
      "40:\tlearn: 0.6836488\ttotal: 896ms\tremaining: 7.84s\n",
      "41:\tlearn: 0.6741129\ttotal: 917ms\tremaining: 7.81s\n",
      "42:\tlearn: 0.6623060\ttotal: 937ms\tremaining: 7.78s\n",
      "43:\tlearn: 0.6509261\ttotal: 956ms\tremaining: 7.74s\n",
      "44:\tlearn: 0.6388545\ttotal: 977ms\tremaining: 7.71s\n",
      "45:\tlearn: 0.6299115\ttotal: 998ms\tremaining: 7.68s\n",
      "46:\tlearn: 0.6196012\ttotal: 1.02s\tremaining: 7.64s\n",
      "47:\tlearn: 0.6076836\ttotal: 1.04s\tremaining: 7.62s\n",
      "48:\tlearn: 0.5962132\ttotal: 1.06s\tremaining: 7.58s\n",
      "49:\tlearn: 0.5865849\ttotal: 1.08s\tremaining: 7.56s\n",
      "50:\tlearn: 0.5775476\ttotal: 1.1s\tremaining: 7.52s\n",
      "51:\tlearn: 0.5676391\ttotal: 1.12s\tremaining: 7.49s\n",
      "52:\tlearn: 0.5593348\ttotal: 1.14s\tremaining: 7.46s\n",
      "53:\tlearn: 0.5495879\ttotal: 1.16s\tremaining: 7.44s\n",
      "54:\tlearn: 0.5405557\ttotal: 1.18s\tremaining: 7.4s\n",
      "55:\tlearn: 0.5314888\ttotal: 1.2s\tremaining: 7.37s\n",
      "56:\tlearn: 0.5242776\ttotal: 1.22s\tremaining: 7.34s\n",
      "57:\tlearn: 0.5157721\ttotal: 1.24s\tremaining: 7.32s\n",
      "58:\tlearn: 0.5075079\ttotal: 1.26s\tremaining: 7.3s\n",
      "59:\tlearn: 0.4993940\ttotal: 1.28s\tremaining: 7.27s\n",
      "60:\tlearn: 0.4916620\ttotal: 1.3s\tremaining: 7.25s\n",
      "61:\tlearn: 0.4846284\ttotal: 1.32s\tremaining: 7.22s\n",
      "62:\tlearn: 0.4762148\ttotal: 1.34s\tremaining: 7.2s\n",
      "63:\tlearn: 0.4691315\ttotal: 1.37s\tremaining: 7.17s\n",
      "64:\tlearn: 0.4607116\ttotal: 1.39s\tremaining: 7.15s\n",
      "65:\tlearn: 0.4554044\ttotal: 1.41s\tremaining: 7.12s\n",
      "66:\tlearn: 0.4496414\ttotal: 1.43s\tremaining: 7.08s\n",
      "67:\tlearn: 0.4431803\ttotal: 1.44s\tremaining: 7.05s\n",
      "68:\tlearn: 0.4369143\ttotal: 1.47s\tremaining: 7.03s\n",
      "69:\tlearn: 0.4324129\ttotal: 1.48s\tremaining: 6.99s\n",
      "70:\tlearn: 0.4276288\ttotal: 1.5s\tremaining: 6.95s\n",
      "71:\tlearn: 0.4227143\ttotal: 1.52s\tremaining: 6.92s\n",
      "72:\tlearn: 0.4170892\ttotal: 1.54s\tremaining: 6.89s\n",
      "73:\tlearn: 0.4118747\ttotal: 1.56s\tremaining: 6.86s\n",
      "74:\tlearn: 0.4058334\ttotal: 1.58s\tremaining: 6.83s\n",
      "75:\tlearn: 0.4014829\ttotal: 1.6s\tremaining: 6.8s\n",
      "76:\tlearn: 0.3961519\ttotal: 1.62s\tremaining: 6.78s\n",
      "77:\tlearn: 0.3919467\ttotal: 1.63s\tremaining: 6.75s\n",
      "78:\tlearn: 0.3861807\ttotal: 1.65s\tremaining: 6.72s\n",
      "79:\tlearn: 0.3808253\ttotal: 1.68s\tremaining: 6.7s\n",
      "80:\tlearn: 0.3744535\ttotal: 1.69s\tremaining: 6.67s\n",
      "81:\tlearn: 0.3696623\ttotal: 1.71s\tremaining: 6.64s\n",
      "82:\tlearn: 0.3644553\ttotal: 1.73s\tremaining: 6.62s\n",
      "83:\tlearn: 0.3601316\ttotal: 1.75s\tremaining: 6.59s\n",
      "84:\tlearn: 0.3565833\ttotal: 1.77s\tremaining: 6.56s\n",
      "85:\tlearn: 0.3524690\ttotal: 1.79s\tremaining: 6.54s\n",
      "86:\tlearn: 0.3485837\ttotal: 1.81s\tremaining: 6.51s\n",
      "87:\tlearn: 0.3442450\ttotal: 1.83s\tremaining: 6.48s\n",
      "88:\tlearn: 0.3396056\ttotal: 1.85s\tremaining: 6.46s\n",
      "89:\tlearn: 0.3355214\ttotal: 1.87s\tremaining: 6.43s\n",
      "90:\tlearn: 0.3313087\ttotal: 1.89s\tremaining: 6.41s\n",
      "91:\tlearn: 0.3266425\ttotal: 1.91s\tremaining: 6.38s\n",
      "92:\tlearn: 0.3243103\ttotal: 1.92s\tremaining: 6.35s\n",
      "93:\tlearn: 0.3205719\ttotal: 1.94s\tremaining: 6.32s\n",
      "94:\tlearn: 0.3165374\ttotal: 1.96s\tremaining: 6.3s\n",
      "95:\tlearn: 0.3123869\ttotal: 1.98s\tremaining: 6.28s\n",
      "96:\tlearn: 0.3087995\ttotal: 2s\tremaining: 6.26s\n",
      "97:\tlearn: 0.3049524\ttotal: 2.02s\tremaining: 6.24s\n",
      "98:\tlearn: 0.3012952\ttotal: 2.04s\tremaining: 6.21s\n",
      "99:\tlearn: 0.2981261\ttotal: 2.06s\tremaining: 6.18s\n",
      "100:\tlearn: 0.2947523\ttotal: 2.08s\tremaining: 6.16s\n",
      "101:\tlearn: 0.2906915\ttotal: 2.1s\tremaining: 6.14s\n",
      "102:\tlearn: 0.2874717\ttotal: 2.12s\tremaining: 6.11s\n",
      "103:\tlearn: 0.2841607\ttotal: 2.14s\tremaining: 6.09s\n",
      "104:\tlearn: 0.2805698\ttotal: 2.16s\tremaining: 6.07s\n",
      "105:\tlearn: 0.2774673\ttotal: 2.18s\tremaining: 6.04s\n",
      "106:\tlearn: 0.2742335\ttotal: 2.2s\tremaining: 6.01s\n",
      "107:\tlearn: 0.2711559\ttotal: 2.22s\tremaining: 5.99s\n",
      "108:\tlearn: 0.2687158\ttotal: 2.23s\tremaining: 5.96s\n",
      "109:\tlearn: 0.2649575\ttotal: 2.25s\tremaining: 5.94s\n",
      "110:\tlearn: 0.2617146\ttotal: 2.27s\tremaining: 5.92s\n",
      "111:\tlearn: 0.2589010\ttotal: 2.29s\tremaining: 5.89s\n",
      "112:\tlearn: 0.2565163\ttotal: 2.31s\tremaining: 5.86s\n",
      "113:\tlearn: 0.2540353\ttotal: 2.33s\tremaining: 5.83s\n",
      "114:\tlearn: 0.2518414\ttotal: 2.34s\tremaining: 5.81s\n",
      "115:\tlearn: 0.2491933\ttotal: 2.36s\tremaining: 5.79s\n",
      "116:\tlearn: 0.2466153\ttotal: 2.38s\tremaining: 5.76s\n",
      "117:\tlearn: 0.2442349\ttotal: 2.4s\tremaining: 5.74s\n",
      "118:\tlearn: 0.2421800\ttotal: 2.42s\tremaining: 5.71s\n",
      "119:\tlearn: 0.2403954\ttotal: 2.44s\tremaining: 5.69s\n",
      "120:\tlearn: 0.2372647\ttotal: 2.46s\tremaining: 5.67s\n",
      "121:\tlearn: 0.2345694\ttotal: 2.48s\tremaining: 5.64s\n",
      "122:\tlearn: 0.2325911\ttotal: 2.5s\tremaining: 5.62s\n",
      "123:\tlearn: 0.2298886\ttotal: 2.52s\tremaining: 5.6s\n",
      "124:\tlearn: 0.2284529\ttotal: 2.54s\tremaining: 5.58s\n",
      "125:\tlearn: 0.2263268\ttotal: 2.55s\tremaining: 5.55s\n",
      "126:\tlearn: 0.2245414\ttotal: 2.57s\tremaining: 5.53s\n",
      "127:\tlearn: 0.2230170\ttotal: 2.59s\tremaining: 5.5s\n",
      "128:\tlearn: 0.2208970\ttotal: 2.61s\tremaining: 5.48s\n",
      "129:\tlearn: 0.2186598\ttotal: 2.63s\tremaining: 5.45s\n",
      "130:\tlearn: 0.2173428\ttotal: 2.64s\tremaining: 5.43s\n",
      "131:\tlearn: 0.2150005\ttotal: 2.66s\tremaining: 5.41s\n",
      "132:\tlearn: 0.2133167\ttotal: 2.68s\tremaining: 5.38s\n",
      "133:\tlearn: 0.2110383\ttotal: 2.7s\tremaining: 5.36s\n",
      "134:\tlearn: 0.2099272\ttotal: 2.71s\tremaining: 5.33s\n",
      "135:\tlearn: 0.2082592\ttotal: 2.73s\tremaining: 5.31s\n",
      "136:\tlearn: 0.2066058\ttotal: 2.75s\tremaining: 5.28s\n",
      "137:\tlearn: 0.2050414\ttotal: 2.77s\tremaining: 5.26s\n",
      "138:\tlearn: 0.2030872\ttotal: 2.79s\tremaining: 5.23s\n",
      "139:\tlearn: 0.2020165\ttotal: 2.8s\tremaining: 5.21s\n",
      "140:\tlearn: 0.2001405\ttotal: 2.82s\tremaining: 5.18s\n",
      "141:\tlearn: 0.1982069\ttotal: 2.84s\tremaining: 5.16s\n",
      "142:\tlearn: 0.1967525\ttotal: 2.86s\tremaining: 5.14s\n",
      "143:\tlearn: 0.1953756\ttotal: 2.88s\tremaining: 5.11s\n",
      "144:\tlearn: 0.1940662\ttotal: 2.89s\tremaining: 5.09s\n",
      "145:\tlearn: 0.1924060\ttotal: 2.91s\tremaining: 5.07s\n",
      "146:\tlearn: 0.1908448\ttotal: 2.93s\tremaining: 5.04s\n",
      "147:\tlearn: 0.1891449\ttotal: 2.95s\tremaining: 5.02s\n",
      "148:\tlearn: 0.1876357\ttotal: 2.97s\tremaining: 5s\n",
      "149:\tlearn: 0.1860379\ttotal: 2.99s\tremaining: 4.98s\n",
      "150:\tlearn: 0.1841348\ttotal: 3.01s\tremaining: 4.96s\n",
      "151:\tlearn: 0.1826380\ttotal: 3.02s\tremaining: 4.93s\n",
      "152:\tlearn: 0.1809202\ttotal: 3.04s\tremaining: 4.91s\n",
      "153:\tlearn: 0.1798490\ttotal: 3.06s\tremaining: 4.89s\n",
      "154:\tlearn: 0.1780784\ttotal: 3.08s\tremaining: 4.87s\n",
      "155:\tlearn: 0.1765820\ttotal: 3.1s\tremaining: 4.85s\n",
      "156:\tlearn: 0.1756014\ttotal: 3.12s\tremaining: 4.83s\n",
      "157:\tlearn: 0.1740530\ttotal: 3.13s\tremaining: 4.8s\n",
      "158:\tlearn: 0.1729071\ttotal: 3.15s\tremaining: 4.78s\n",
      "159:\tlearn: 0.1712562\ttotal: 3.17s\tremaining: 4.76s\n",
      "160:\tlearn: 0.1696873\ttotal: 3.19s\tremaining: 4.73s\n",
      "161:\tlearn: 0.1682620\ttotal: 3.21s\tremaining: 4.71s\n",
      "162:\tlearn: 0.1671060\ttotal: 3.22s\tremaining: 4.69s\n",
      "163:\tlearn: 0.1659965\ttotal: 3.24s\tremaining: 4.67s\n",
      "164:\tlearn: 0.1643670\ttotal: 3.26s\tremaining: 4.65s\n",
      "165:\tlearn: 0.1626753\ttotal: 3.28s\tremaining: 4.63s\n",
      "166:\tlearn: 0.1615152\ttotal: 3.31s\tremaining: 4.61s\n",
      "167:\tlearn: 0.1602209\ttotal: 3.32s\tremaining: 4.59s\n",
      "168:\tlearn: 0.1590537\ttotal: 3.34s\tremaining: 4.57s\n",
      "169:\tlearn: 0.1575855\ttotal: 3.36s\tremaining: 4.54s\n",
      "170:\tlearn: 0.1561717\ttotal: 3.38s\tremaining: 4.52s\n",
      "171:\tlearn: 0.1549893\ttotal: 3.4s\tremaining: 4.5s\n",
      "172:\tlearn: 0.1536382\ttotal: 3.41s\tremaining: 4.48s\n",
      "173:\tlearn: 0.1525569\ttotal: 3.43s\tremaining: 4.46s\n",
      "174:\tlearn: 0.1512807\ttotal: 3.45s\tremaining: 4.43s\n",
      "175:\tlearn: 0.1501450\ttotal: 3.47s\tremaining: 4.41s\n",
      "176:\tlearn: 0.1486485\ttotal: 3.49s\tremaining: 4.39s\n",
      "177:\tlearn: 0.1478137\ttotal: 3.5s\tremaining: 4.37s\n",
      "178:\tlearn: 0.1468782\ttotal: 3.52s\tremaining: 4.35s\n",
      "179:\tlearn: 0.1456580\ttotal: 3.54s\tremaining: 4.33s\n",
      "180:\tlearn: 0.1447441\ttotal: 3.56s\tremaining: 4.31s\n",
      "181:\tlearn: 0.1437960\ttotal: 3.58s\tremaining: 4.29s\n",
      "182:\tlearn: 0.1428354\ttotal: 3.6s\tremaining: 4.26s\n",
      "183:\tlearn: 0.1417032\ttotal: 3.61s\tremaining: 4.24s\n",
      "184:\tlearn: 0.1403624\ttotal: 3.63s\tremaining: 4.22s\n",
      "185:\tlearn: 0.1392091\ttotal: 3.65s\tremaining: 4.2s\n",
      "186:\tlearn: 0.1380842\ttotal: 3.67s\tremaining: 4.18s\n",
      "187:\tlearn: 0.1369947\ttotal: 3.7s\tremaining: 4.18s\n",
      "188:\tlearn: 0.1361261\ttotal: 3.72s\tremaining: 4.16s\n",
      "189:\tlearn: 0.1348728\ttotal: 3.74s\tremaining: 4.13s\n",
      "190:\tlearn: 0.1336363\ttotal: 3.76s\tremaining: 4.11s\n",
      "191:\tlearn: 0.1327732\ttotal: 3.78s\tremaining: 4.09s\n",
      "192:\tlearn: 0.1319016\ttotal: 3.79s\tremaining: 4.07s\n",
      "193:\tlearn: 0.1309549\ttotal: 3.81s\tremaining: 4.05s\n",
      "194:\tlearn: 0.1303814\ttotal: 3.83s\tremaining: 4.02s\n",
      "195:\tlearn: 0.1295490\ttotal: 3.85s\tremaining: 4s\n",
      "196:\tlearn: 0.1285690\ttotal: 3.86s\tremaining: 3.98s\n",
      "197:\tlearn: 0.1278798\ttotal: 3.88s\tremaining: 3.96s\n",
      "198:\tlearn: 0.1273912\ttotal: 3.9s\tremaining: 3.94s\n",
      "199:\tlearn: 0.1261979\ttotal: 3.92s\tremaining: 3.92s\n",
      "200:\tlearn: 0.1252520\ttotal: 3.94s\tremaining: 3.9s\n",
      "201:\tlearn: 0.1245635\ttotal: 3.95s\tremaining: 3.87s\n",
      "202:\tlearn: 0.1236760\ttotal: 3.97s\tremaining: 3.85s\n",
      "203:\tlearn: 0.1227569\ttotal: 3.99s\tremaining: 3.83s\n",
      "204:\tlearn: 0.1219795\ttotal: 4.01s\tremaining: 3.81s\n",
      "205:\tlearn: 0.1209417\ttotal: 4.03s\tremaining: 3.79s\n",
      "206:\tlearn: 0.1200357\ttotal: 4.05s\tremaining: 3.77s\n",
      "207:\tlearn: 0.1193566\ttotal: 4.07s\tremaining: 3.75s\n",
      "208:\tlearn: 0.1189938\ttotal: 4.08s\tremaining: 3.73s\n",
      "209:\tlearn: 0.1181642\ttotal: 4.1s\tremaining: 3.71s\n",
      "210:\tlearn: 0.1172938\ttotal: 4.12s\tremaining: 3.69s\n",
      "211:\tlearn: 0.1166091\ttotal: 4.14s\tremaining: 3.67s\n",
      "212:\tlearn: 0.1159043\ttotal: 4.16s\tremaining: 3.65s\n",
      "213:\tlearn: 0.1154858\ttotal: 4.17s\tremaining: 3.63s\n",
      "214:\tlearn: 0.1146418\ttotal: 4.19s\tremaining: 3.61s\n",
      "215:\tlearn: 0.1137043\ttotal: 4.21s\tremaining: 3.59s\n",
      "216:\tlearn: 0.1130603\ttotal: 4.23s\tremaining: 3.57s\n",
      "217:\tlearn: 0.1122573\ttotal: 4.25s\tremaining: 3.55s\n",
      "218:\tlearn: 0.1113487\ttotal: 4.27s\tremaining: 3.53s\n",
      "219:\tlearn: 0.1108876\ttotal: 4.29s\tremaining: 3.51s\n",
      "220:\tlearn: 0.1101933\ttotal: 4.3s\tremaining: 3.49s\n",
      "221:\tlearn: 0.1095278\ttotal: 4.32s\tremaining: 3.46s\n",
      "222:\tlearn: 0.1088585\ttotal: 4.34s\tremaining: 3.44s\n",
      "223:\tlearn: 0.1083156\ttotal: 4.36s\tremaining: 3.42s\n",
      "224:\tlearn: 0.1075402\ttotal: 4.38s\tremaining: 3.4s\n",
      "225:\tlearn: 0.1069617\ttotal: 4.39s\tremaining: 3.38s\n",
      "226:\tlearn: 0.1062581\ttotal: 4.41s\tremaining: 3.36s\n",
      "227:\tlearn: 0.1055452\ttotal: 4.43s\tremaining: 3.34s\n",
      "228:\tlearn: 0.1050078\ttotal: 4.45s\tremaining: 3.33s\n",
      "229:\tlearn: 0.1045148\ttotal: 4.47s\tremaining: 3.31s\n",
      "230:\tlearn: 0.1038775\ttotal: 4.49s\tremaining: 3.29s\n",
      "231:\tlearn: 0.1031312\ttotal: 4.51s\tremaining: 3.27s\n",
      "232:\tlearn: 0.1024587\ttotal: 4.53s\tremaining: 3.25s\n",
      "233:\tlearn: 0.1019067\ttotal: 4.55s\tremaining: 3.23s\n",
      "234:\tlearn: 0.1014303\ttotal: 4.57s\tremaining: 3.21s\n",
      "235:\tlearn: 0.1011078\ttotal: 4.59s\tremaining: 3.19s\n",
      "236:\tlearn: 0.1005027\ttotal: 4.61s\tremaining: 3.17s\n",
      "237:\tlearn: 0.0999983\ttotal: 4.62s\tremaining: 3.15s\n",
      "238:\tlearn: 0.0992581\ttotal: 4.65s\tremaining: 3.13s\n",
      "239:\tlearn: 0.0986960\ttotal: 4.66s\tremaining: 3.11s\n",
      "240:\tlearn: 0.0980405\ttotal: 4.68s\tremaining: 3.09s\n",
      "241:\tlearn: 0.0973821\ttotal: 4.7s\tremaining: 3.07s\n",
      "242:\tlearn: 0.0967629\ttotal: 4.72s\tremaining: 3.05s\n",
      "243:\tlearn: 0.0960422\ttotal: 4.74s\tremaining: 3.03s\n",
      "244:\tlearn: 0.0954735\ttotal: 4.76s\tremaining: 3.01s\n",
      "245:\tlearn: 0.0949145\ttotal: 4.78s\tremaining: 2.99s\n",
      "246:\tlearn: 0.0942966\ttotal: 4.79s\tremaining: 2.97s\n",
      "247:\tlearn: 0.0935964\ttotal: 4.81s\tremaining: 2.95s\n",
      "248:\tlearn: 0.0931840\ttotal: 4.84s\tremaining: 2.93s\n",
      "249:\tlearn: 0.0925083\ttotal: 4.86s\tremaining: 2.91s\n",
      "250:\tlearn: 0.0919600\ttotal: 4.87s\tremaining: 2.89s\n",
      "251:\tlearn: 0.0914836\ttotal: 4.89s\tremaining: 2.87s\n",
      "252:\tlearn: 0.0908727\ttotal: 4.91s\tremaining: 2.85s\n",
      "253:\tlearn: 0.0901999\ttotal: 4.93s\tremaining: 2.83s\n",
      "254:\tlearn: 0.0896865\ttotal: 4.95s\tremaining: 2.81s\n",
      "255:\tlearn: 0.0891651\ttotal: 4.97s\tremaining: 2.79s\n",
      "256:\tlearn: 0.0887197\ttotal: 4.99s\tremaining: 2.77s\n",
      "257:\tlearn: 0.0881337\ttotal: 5.01s\tremaining: 2.75s\n",
      "258:\tlearn: 0.0875722\ttotal: 5.03s\tremaining: 2.74s\n",
      "259:\tlearn: 0.0871017\ttotal: 5.04s\tremaining: 2.71s\n",
      "260:\tlearn: 0.0866601\ttotal: 5.06s\tremaining: 2.69s\n",
      "261:\tlearn: 0.0860262\ttotal: 5.08s\tremaining: 2.68s\n",
      "262:\tlearn: 0.0855928\ttotal: 5.1s\tremaining: 2.66s\n",
      "263:\tlearn: 0.0850932\ttotal: 5.12s\tremaining: 2.64s\n",
      "264:\tlearn: 0.0846493\ttotal: 5.14s\tremaining: 2.62s\n",
      "265:\tlearn: 0.0842235\ttotal: 5.15s\tremaining: 2.6s\n",
      "266:\tlearn: 0.0836395\ttotal: 5.17s\tremaining: 2.58s\n",
      "267:\tlearn: 0.0831542\ttotal: 5.19s\tremaining: 2.56s\n",
      "268:\tlearn: 0.0827229\ttotal: 5.21s\tremaining: 2.54s\n",
      "269:\tlearn: 0.0823706\ttotal: 5.23s\tremaining: 2.52s\n",
      "270:\tlearn: 0.0819368\ttotal: 5.25s\tremaining: 2.5s\n",
      "271:\tlearn: 0.0814313\ttotal: 5.27s\tremaining: 2.48s\n",
      "272:\tlearn: 0.0809061\ttotal: 5.29s\tremaining: 2.46s\n",
      "273:\tlearn: 0.0803651\ttotal: 5.31s\tremaining: 2.44s\n",
      "274:\tlearn: 0.0799672\ttotal: 5.32s\tremaining: 2.42s\n",
      "275:\tlearn: 0.0795507\ttotal: 5.34s\tremaining: 2.4s\n",
      "276:\tlearn: 0.0791653\ttotal: 5.36s\tremaining: 2.38s\n",
      "277:\tlearn: 0.0786663\ttotal: 5.38s\tremaining: 2.36s\n",
      "278:\tlearn: 0.0782065\ttotal: 5.39s\tremaining: 2.34s\n",
      "279:\tlearn: 0.0778696\ttotal: 5.41s\tremaining: 2.32s\n",
      "280:\tlearn: 0.0774773\ttotal: 5.43s\tremaining: 2.3s\n",
      "281:\tlearn: 0.0771669\ttotal: 5.45s\tremaining: 2.28s\n",
      "282:\tlearn: 0.0767590\ttotal: 5.47s\tremaining: 2.26s\n",
      "283:\tlearn: 0.0763746\ttotal: 5.49s\tremaining: 2.24s\n",
      "284:\tlearn: 0.0760756\ttotal: 5.5s\tremaining: 2.22s\n",
      "285:\tlearn: 0.0756730\ttotal: 5.52s\tremaining: 2.2s\n",
      "286:\tlearn: 0.0752272\ttotal: 5.54s\tremaining: 2.18s\n",
      "287:\tlearn: 0.0748248\ttotal: 5.56s\tremaining: 2.16s\n",
      "288:\tlearn: 0.0743724\ttotal: 5.58s\tremaining: 2.14s\n",
      "289:\tlearn: 0.0739885\ttotal: 5.59s\tremaining: 2.12s\n",
      "290:\tlearn: 0.0736957\ttotal: 5.61s\tremaining: 2.1s\n",
      "291:\tlearn: 0.0733962\ttotal: 5.63s\tremaining: 2.08s\n",
      "292:\tlearn: 0.0730896\ttotal: 5.65s\tremaining: 2.06s\n",
      "293:\tlearn: 0.0728686\ttotal: 5.67s\tremaining: 2.04s\n",
      "294:\tlearn: 0.0724281\ttotal: 5.69s\tremaining: 2.02s\n",
      "295:\tlearn: 0.0720621\ttotal: 5.71s\tremaining: 2.01s\n",
      "296:\tlearn: 0.0717157\ttotal: 5.73s\tremaining: 1.99s\n",
      "297:\tlearn: 0.0712965\ttotal: 5.75s\tremaining: 1.97s\n",
      "298:\tlearn: 0.0709153\ttotal: 5.76s\tremaining: 1.95s\n",
      "299:\tlearn: 0.0705704\ttotal: 5.78s\tremaining: 1.93s\n",
      "300:\tlearn: 0.0702679\ttotal: 5.8s\tremaining: 1.91s\n",
      "301:\tlearn: 0.0699442\ttotal: 5.82s\tremaining: 1.89s\n",
      "302:\tlearn: 0.0695005\ttotal: 5.84s\tremaining: 1.87s\n",
      "303:\tlearn: 0.0691620\ttotal: 5.85s\tremaining: 1.85s\n",
      "304:\tlearn: 0.0689299\ttotal: 5.87s\tremaining: 1.83s\n",
      "305:\tlearn: 0.0686079\ttotal: 5.89s\tremaining: 1.81s\n",
      "306:\tlearn: 0.0682780\ttotal: 5.91s\tremaining: 1.79s\n",
      "307:\tlearn: 0.0678827\ttotal: 5.93s\tremaining: 1.77s\n",
      "308:\tlearn: 0.0676655\ttotal: 5.94s\tremaining: 1.75s\n",
      "309:\tlearn: 0.0672929\ttotal: 5.96s\tremaining: 1.73s\n",
      "310:\tlearn: 0.0669605\ttotal: 5.98s\tremaining: 1.71s\n",
      "311:\tlearn: 0.0665860\ttotal: 6s\tremaining: 1.69s\n",
      "312:\tlearn: 0.0662704\ttotal: 6.02s\tremaining: 1.67s\n",
      "313:\tlearn: 0.0660391\ttotal: 6.04s\tremaining: 1.65s\n",
      "314:\tlearn: 0.0657424\ttotal: 6.06s\tremaining: 1.63s\n",
      "315:\tlearn: 0.0654357\ttotal: 6.08s\tremaining: 1.61s\n",
      "316:\tlearn: 0.0650592\ttotal: 6.09s\tremaining: 1.59s\n",
      "317:\tlearn: 0.0646848\ttotal: 6.11s\tremaining: 1.58s\n",
      "318:\tlearn: 0.0644017\ttotal: 6.13s\tremaining: 1.56s\n",
      "319:\tlearn: 0.0640659\ttotal: 6.15s\tremaining: 1.54s\n",
      "320:\tlearn: 0.0638688\ttotal: 6.17s\tremaining: 1.52s\n",
      "321:\tlearn: 0.0635795\ttotal: 6.18s\tremaining: 1.5s\n",
      "322:\tlearn: 0.0632025\ttotal: 6.2s\tremaining: 1.48s\n",
      "323:\tlearn: 0.0628822\ttotal: 6.22s\tremaining: 1.46s\n",
      "324:\tlearn: 0.0627068\ttotal: 6.24s\tremaining: 1.44s\n",
      "325:\tlearn: 0.0624865\ttotal: 6.25s\tremaining: 1.42s\n",
      "326:\tlearn: 0.0621532\ttotal: 6.28s\tremaining: 1.4s\n",
      "327:\tlearn: 0.0618522\ttotal: 6.29s\tremaining: 1.38s\n",
      "328:\tlearn: 0.0616013\ttotal: 6.31s\tremaining: 1.36s\n",
      "329:\tlearn: 0.0613426\ttotal: 6.33s\tremaining: 1.34s\n",
      "330:\tlearn: 0.0609836\ttotal: 6.35s\tremaining: 1.32s\n",
      "331:\tlearn: 0.0607033\ttotal: 6.37s\tremaining: 1.3s\n",
      "332:\tlearn: 0.0604291\ttotal: 6.39s\tremaining: 1.28s\n",
      "333:\tlearn: 0.0602229\ttotal: 6.41s\tremaining: 1.27s\n",
      "334:\tlearn: 0.0599353\ttotal: 6.42s\tremaining: 1.25s\n",
      "335:\tlearn: 0.0596420\ttotal: 6.44s\tremaining: 1.23s\n",
      "336:\tlearn: 0.0593491\ttotal: 6.46s\tremaining: 1.21s\n",
      "337:\tlearn: 0.0590343\ttotal: 6.48s\tremaining: 1.19s\n",
      "338:\tlearn: 0.0587601\ttotal: 6.5s\tremaining: 1.17s\n",
      "339:\tlearn: 0.0585145\ttotal: 6.52s\tremaining: 1.15s\n",
      "340:\tlearn: 0.0583883\ttotal: 6.54s\tremaining: 1.13s\n",
      "341:\tlearn: 0.0580927\ttotal: 6.56s\tremaining: 1.11s\n",
      "342:\tlearn: 0.0578626\ttotal: 6.58s\tremaining: 1.09s\n",
      "343:\tlearn: 0.0576059\ttotal: 6.59s\tremaining: 1.07s\n",
      "344:\tlearn: 0.0573296\ttotal: 6.61s\tremaining: 1.05s\n",
      "345:\tlearn: 0.0571000\ttotal: 6.63s\tremaining: 1.03s\n",
      "346:\tlearn: 0.0568941\ttotal: 6.65s\tremaining: 1.01s\n",
      "347:\tlearn: 0.0566131\ttotal: 6.67s\tremaining: 996ms\n",
      "348:\tlearn: 0.0564233\ttotal: 6.69s\tremaining: 977ms\n",
      "349:\tlearn: 0.0562073\ttotal: 6.7s\tremaining: 958ms\n",
      "350:\tlearn: 0.0559799\ttotal: 6.72s\tremaining: 938ms\n",
      "351:\tlearn: 0.0557481\ttotal: 6.74s\tremaining: 919ms\n",
      "352:\tlearn: 0.0555538\ttotal: 6.76s\tremaining: 900ms\n",
      "353:\tlearn: 0.0553367\ttotal: 6.78s\tremaining: 881ms\n",
      "354:\tlearn: 0.0551577\ttotal: 6.8s\tremaining: 861ms\n",
      "355:\tlearn: 0.0549297\ttotal: 6.81s\tremaining: 842ms\n",
      "356:\tlearn: 0.0546909\ttotal: 6.83s\tremaining: 823ms\n",
      "357:\tlearn: 0.0544781\ttotal: 6.85s\tremaining: 803ms\n",
      "358:\tlearn: 0.0542152\ttotal: 6.87s\tremaining: 784ms\n",
      "359:\tlearn: 0.0539168\ttotal: 6.88s\tremaining: 765ms\n",
      "360:\tlearn: 0.0536750\ttotal: 6.9s\tremaining: 746ms\n",
      "361:\tlearn: 0.0535401\ttotal: 6.92s\tremaining: 726ms\n",
      "362:\tlearn: 0.0533400\ttotal: 6.94s\tremaining: 707ms\n",
      "363:\tlearn: 0.0531060\ttotal: 6.96s\tremaining: 688ms\n",
      "364:\tlearn: 0.0528641\ttotal: 6.98s\tremaining: 669ms\n",
      "365:\tlearn: 0.0526575\ttotal: 7s\tremaining: 650ms\n",
      "366:\tlearn: 0.0524011\ttotal: 7.02s\tremaining: 631ms\n",
      "367:\tlearn: 0.0521789\ttotal: 7.03s\tremaining: 612ms\n",
      "368:\tlearn: 0.0519289\ttotal: 7.05s\tremaining: 592ms\n",
      "369:\tlearn: 0.0516724\ttotal: 7.07s\tremaining: 573ms\n",
      "370:\tlearn: 0.0514686\ttotal: 7.09s\tremaining: 554ms\n",
      "371:\tlearn: 0.0512040\ttotal: 7.1s\tremaining: 535ms\n",
      "372:\tlearn: 0.0509985\ttotal: 7.12s\tremaining: 515ms\n",
      "373:\tlearn: 0.0507985\ttotal: 7.14s\tremaining: 496ms\n",
      "374:\tlearn: 0.0505726\ttotal: 7.16s\tremaining: 477ms\n",
      "375:\tlearn: 0.0503493\ttotal: 7.17s\tremaining: 458ms\n",
      "376:\tlearn: 0.0501426\ttotal: 7.2s\tremaining: 439ms\n",
      "377:\tlearn: 0.0499607\ttotal: 7.21s\tremaining: 420ms\n",
      "378:\tlearn: 0.0497767\ttotal: 7.23s\tremaining: 401ms\n",
      "379:\tlearn: 0.0496260\ttotal: 7.25s\tremaining: 382ms\n",
      "380:\tlearn: 0.0494488\ttotal: 7.27s\tremaining: 362ms\n",
      "381:\tlearn: 0.0492234\ttotal: 7.29s\tremaining: 343ms\n",
      "382:\tlearn: 0.0490347\ttotal: 7.3s\tremaining: 324ms\n",
      "383:\tlearn: 0.0488405\ttotal: 7.32s\tremaining: 305ms\n",
      "384:\tlearn: 0.0486342\ttotal: 7.34s\tremaining: 286ms\n",
      "385:\tlearn: 0.0485161\ttotal: 7.36s\tremaining: 267ms\n",
      "386:\tlearn: 0.0483290\ttotal: 7.37s\tremaining: 248ms\n",
      "387:\tlearn: 0.0481349\ttotal: 7.39s\tremaining: 229ms\n",
      "388:\tlearn: 0.0479320\ttotal: 7.41s\tremaining: 210ms\n",
      "389:\tlearn: 0.0477085\ttotal: 7.43s\tremaining: 191ms\n",
      "390:\tlearn: 0.0475273\ttotal: 7.45s\tremaining: 171ms\n",
      "391:\tlearn: 0.0473450\ttotal: 7.47s\tremaining: 152ms\n",
      "392:\tlearn: 0.0471554\ttotal: 7.49s\tremaining: 133ms\n",
      "393:\tlearn: 0.0470044\ttotal: 7.5s\tremaining: 114ms\n",
      "394:\tlearn: 0.0468218\ttotal: 7.52s\tremaining: 95.2ms\n",
      "395:\tlearn: 0.0466728\ttotal: 7.54s\tremaining: 76.2ms\n",
      "396:\tlearn: 0.0464709\ttotal: 7.56s\tremaining: 57.1ms\n",
      "397:\tlearn: 0.0463061\ttotal: 7.58s\tremaining: 38.1ms\n",
      "398:\tlearn: 0.0461488\ttotal: 7.6s\tremaining: 19ms\n",
      "399:\tlearn: 0.0460201\ttotal: 7.62s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.62        43\n",
      "           1       0.75      0.68      0.71        31\n",
      "           2       0.72      0.68      0.70        34\n",
      "           3       0.57      0.62      0.59        26\n",
      "           4       0.55      0.59      0.57        27\n",
      "           5       0.69      0.73      0.70        51\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.65      0.65      0.65       212\n",
      "weighted avg       0.66      0.66      0.66       212\n"
     ]
    }
   ],
   "source": [
    "model = cb.CatBoostClassifier(iterations=400, task_type='GPU')\n",
    "model.fit(X_train, y_train)\n",
    "# Generate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:33:13.302839300Z",
     "start_time": "2024-02-24T13:33:04.815260800Z"
    }
   },
   "id": "c14f291177ba9793",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "Very interesting to note is that the Catboost model gave a score of 0.66, not better from the logistic regression,\n",
    "and from other models we have tried so far, \n",
    "meaning that the more complex models do not always outperform the simpler ones."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66b66ab411e286e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural Network\n",
    "\n",
    "While neural networks need a lot of data to perform well, let's try a simple neural network model to see how it performs.\n",
    "\n",
    "We will use the `keras` library to build the neural network model.\n",
    "\n",
    "Let's start by making the train and test splits from above into TensorFlow datasets.\n",
    "\n",
    "We will also define a validation dataset from the training data to monitor the model's performance during training.\n",
    "All the tensors will be batched and pre-fetched to improve performance and also cached to avoid loading the data from the disk during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be15e3c101722f61"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 600  # Adjust based on your dataset size\n",
    "VALIDATION_SPLIT = 0.2  # Fraction of training data to use for validation\n",
    "\n",
    "# Calculate the number of validation samples\n",
    "n_validation_samples = int(len(X_train) * VALIDATION_SPLIT)\n",
    "\n",
    "# Create and process the validation dataset from the training data\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_train[:n_validation_samples], y_train[:n_validation_samples]))\n",
    "val_ds = val_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Update the training dataset to exclude the validation data and process it\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train[n_validation_samples:], y_train[n_validation_samples:]))\n",
    "train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Create and process the test dataset\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_ds = test_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:23.924651300Z",
     "start_time": "2024-02-24T14:49:23.886779500Z"
    }
   },
   "id": "fac050077fcb120",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "With that done, let's have a look at the first batch of the training dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1bc0a932557566"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [[-0.02552795  0.00769043 -0.03106689 ...  0.02865601 -0.0552063\n",
      "  -0.01802063]\n",
      " [-0.01200104 -0.00301361 -0.03564453 ... -0.00743866 -0.04656982\n",
      "  -0.04006958]\n",
      " [-0.0017252  -0.02816772 -0.0214386  ...  0.04397583 -0.09735107\n",
      "   0.01378632]\n",
      " ...\n",
      " [-0.02601624  0.01105499 -0.02320862 ...  0.01963806 -0.0769043\n",
      "  -0.00473785]\n",
      " [-0.00162506  0.06921387 -0.03442383 ...  0.00345612 -0.02775574\n",
      "   0.00546646]\n",
      " [-0.01052856  0.02453613 -0.01599121 ...  0.00735855 -0.04873657\n",
      "  -0.02774048]], Target: [0 5 0 1 1 3 1 2 1 5 1 5 2 5 5 5 2 5 1 5 1 4 3 5 5 3 3 4 5 2 5 0]\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in train_ds.take(1):\n",
    "    print('Features: {}, Target: {}'.format(feat, targ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:24.445339500Z",
     "start_time": "2024-02-24T14:49:24.425787700Z"
    }
   },
   "id": "28b6cd6e52c06ff9",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the training dataset is structured as expected, with the features and the targets batched together with a size of 32."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2200f63d62e00072"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's define an early stopping callback to stop training the model when the validation loss does not improve after a certain number of epochs. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55faaf898903bf36"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=30,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:24.917544700Z",
     "start_time": "2024-02-24T14:49:24.911348600Z"
    }
   },
   "id": "a2a85456f6f0206a",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another useful callback method in TensorFlow is the ModelCheckpoint callback. This callback saves the model at regular intervals during training, allowing you to retain and load the best version of your model based on a certain monitored metric, such as validation loss or accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58e3c995a8f8d943"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model_{epoch:02d}-{val_loss:.2f}.keras',  # Change the extension to '.keras'\n",
    "    save_weights_only=False,  # Set to True to save only weights, False to save the entire model\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    mode='min',  # The model is saved when the monitored metric stops decreasing\n",
    "    save_best_only=True,  # Only the best model is saved\n",
    "    verbose=1  # Verbosity mode, 1 or 0\n",
    ")\n",
    "\n",
    "CALLBACKS = [\n",
    "    tfdocs.modeling.EpochDots(),\n",
    "    early_stopping_callback,\n",
    "    model_checkpoint_callback\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:25.214636800Z",
     "start_time": "2024-02-24T14:49:25.208492900Z"
    }
   },
   "id": "e99e3b0058d27c4b",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly, let's define a scheduler callback to adjust the learning rate during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e70949e4096c0a1f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = X_train.shape[0] // BATCH_SIZE\n",
    "lr_scheduler = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    initial_learning_rate=1e-3,  # Initial learning rate\n",
    "    decay_steps=STEPS_PER_EPOCH * 1000,  # Decay steps\n",
    "    decay_rate=0.9,  # Decay rate\n",
    "    staircase=True  # If True, decay the learning rate at discrete intervals\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:25.542543300Z",
     "start_time": "2024-02-24T14:49:25.540195Z"
    }
   },
   "id": "b24cce175aac2630",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "With all the callbacks and the learning rate scheduler defined, let's now build the neural network model.\n",
    "\n",
    "We will use a simple neural network with 3 dense layers, the first with 32 units and the second with 16, and a ReLU activation function.\n",
    "The last layer will have 6 units, one for each class, and a softmax activation function.\n",
    "\n",
    "Also, we will use the Adam optimizer and the SparseCategoricalCrossentropy loss function, as well as the accuracy metric.\n",
    "\n",
    "Lastly, we will add WeightRegularization to the model as well as DropoutLayers to prevent overfitting."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "396c45887ea4ddcd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n"
     ]
    }
   ],
   "source": [
    "weight_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=weight_regularizer),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=weight_regularizer),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(n_classes, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:26.771787200Z",
     "start_time": "2024-02-24T14:49:26.526417100Z"
    }
   },
   "id": "ed010b4c406e22d7",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the model created, let's compile it using the Adam optimizer, the SparseCategoricalCrossentropy loss function, and the accuracy metric."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9600efc4cd8cdafb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=(['accuracy',\n",
    "                        tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                            from_logits=False, name='sparse_categorical_crossentropy')]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:27.718339600Z",
     "start_time": "2024-02-24T14:49:27.700033200Z"
    }
   },
   "id": "3dc26bb0fade8741",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see now the model summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19eb4b55cb1da4d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                24608     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25238 (98.59 KB)\n",
      "Trainable params: 25238 (98.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:29.922275300Z",
     "start_time": "2024-02-24T14:49:29.880763200Z"
    }
   },
   "id": "7794956153aea89d",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the model has 25238 parameters to train, which are quite a lot for the small dataset we have.\n",
    "However, with the Dropout layers and the WeightRegularization, we hope to prevent excessive overfitting.\n",
    "\n",
    "Let's now train the model using the training dataset and the validation dataset we created earlier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "689f9ac49e7e4324"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      " 1/22 [>.............................] - ETA: 11s - loss: 1.8014 - accuracy: 0.1250 - sparse_categorical_crossentropy: 1.7932\n",
      "Epoch: 0, accuracy:0.1893,  loss:1.8007,  sparse_categorical_crossentropy:1.7928,  val_accuracy:0.2012,  val_loss:1.7934,  val_sparse_categorical_crossentropy:1.7875,  \n",
      ".\n",
      "Epoch 1: val_loss improved from inf to 1.79336, saving model to model_01-1.79.keras\n",
      "22/22 [==============================] - 1s 7ms/step - loss: 1.8007 - accuracy: 0.1893 - sparse_categorical_crossentropy: 1.7928 - val_loss: 1.7934 - val_accuracy: 0.2012 - val_sparse_categorical_crossentropy: 1.7875\n",
      "Epoch 2/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7793 - accuracy: 0.2812 - sparse_categorical_crossentropy: 1.7714.\n",
      "Epoch 2: val_loss improved from 1.79336 to 1.78310, saving model to model_02-1.78.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7882 - accuracy: 0.2115 - sparse_categorical_crossentropy: 1.7799 - val_loss: 1.7831 - val_accuracy: 0.2781 - val_sparse_categorical_crossentropy: 1.7776\n",
      "Epoch 3/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7598 - accuracy: 0.2500 - sparse_categorical_crossentropy: 1.7523.\n",
      "Epoch 3: val_loss improved from 1.78310 to 1.76999, saving model to model_03-1.77.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7751 - accuracy: 0.2322 - sparse_categorical_crossentropy: 1.7700 - val_loss: 1.7700 - val_accuracy: 0.2485 - val_sparse_categorical_crossentropy: 1.7655\n",
      "Epoch 4/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7551 - accuracy: 0.3125 - sparse_categorical_crossentropy: 1.7478.\n",
      "Epoch 4: val_loss improved from 1.76999 to 1.75659, saving model to model_04-1.76.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7602 - accuracy: 0.2396 - sparse_categorical_crossentropy: 1.7538 - val_loss: 1.7566 - val_accuracy: 0.2189 - val_sparse_categorical_crossentropy: 1.7529\n",
      "Epoch 5/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7048 - accuracy: 0.2812 - sparse_categorical_crossentropy: 1.6976.\n",
      "Epoch 5: val_loss improved from 1.75659 to 1.73466, saving model to model_05-1.73.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7361 - accuracy: 0.2648 - sparse_categorical_crossentropy: 1.7274 - val_loss: 1.7347 - val_accuracy: 0.2426 - val_sparse_categorical_crossentropy: 1.7314\n",
      "Epoch 6/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.6897 - accuracy: 0.3125 - sparse_categorical_crossentropy: 1.6825.\n",
      "Epoch 6: val_loss improved from 1.73466 to 1.71341, saving model to model_06-1.71.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7182 - accuracy: 0.2914 - sparse_categorical_crossentropy: 1.7140 - val_loss: 1.7134 - val_accuracy: 0.2722 - val_sparse_categorical_crossentropy: 1.7096\n",
      "Epoch 7/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7121 - accuracy: 0.3750 - sparse_categorical_crossentropy: 1.7048.\n",
      "Epoch 7: val_loss improved from 1.71341 to 1.68701, saving model to model_07-1.69.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6928 - accuracy: 0.3092 - sparse_categorical_crossentropy: 1.6855 - val_loss: 1.6870 - val_accuracy: 0.3195 - val_sparse_categorical_crossentropy: 1.6832\n",
      "Epoch 8/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.6181 - accuracy: 0.3438 - sparse_categorical_crossentropy: 1.6106.\n",
      "Epoch 8: val_loss improved from 1.68701 to 1.65317, saving model to model_08-1.65.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6443 - accuracy: 0.3565 - sparse_categorical_crossentropy: 1.6409 - val_loss: 1.6532 - val_accuracy: 0.3905 - val_sparse_categorical_crossentropy: 1.6479\n",
      "Epoch 9/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.5866 - accuracy: 0.4375 - sparse_categorical_crossentropy: 1.5788.\n",
      "Epoch 9: val_loss improved from 1.65317 to 1.62318, saving model to model_09-1.62.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6057 - accuracy: 0.4172 - sparse_categorical_crossentropy: 1.5959 - val_loss: 1.6232 - val_accuracy: 0.4083 - val_sparse_categorical_crossentropy: 1.6172\n",
      "Epoch 10/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.5235 - accuracy: 0.5312 - sparse_categorical_crossentropy: 1.5154.\n",
      "Epoch 10: val_loss improved from 1.62318 to 1.58291, saving model to model_10-1.58.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5632 - accuracy: 0.4112 - sparse_categorical_crossentropy: 1.5528 - val_loss: 1.5829 - val_accuracy: 0.4320 - val_sparse_categorical_crossentropy: 1.5734\n",
      "Epoch 11/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.5094 - accuracy: 0.4062 - sparse_categorical_crossentropy: 1.5009.\n",
      "Epoch 11: val_loss improved from 1.58291 to 1.54624, saving model to model_11-1.55.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5158 - accuracy: 0.4660 - sparse_categorical_crossentropy: 1.5050 - val_loss: 1.5462 - val_accuracy: 0.4497 - val_sparse_categorical_crossentropy: 1.5354\n",
      "Epoch 12/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.5358 - accuracy: 0.3125 - sparse_categorical_crossentropy: 1.5268.\n",
      "Epoch 12: val_loss improved from 1.54624 to 1.51832, saving model to model_12-1.52.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4917 - accuracy: 0.4734 - sparse_categorical_crossentropy: 1.4707 - val_loss: 1.5183 - val_accuracy: 0.4556 - val_sparse_categorical_crossentropy: 1.5058\n",
      "Epoch 13/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.4900 - accuracy: 0.5000 - sparse_categorical_crossentropy: 1.4805.\n",
      "Epoch 13: val_loss improved from 1.51832 to 1.48183, saving model to model_13-1.48.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4772 - accuracy: 0.4645 - sparse_categorical_crossentropy: 1.4662 - val_loss: 1.4818 - val_accuracy: 0.4793 - val_sparse_categorical_crossentropy: 1.4625\n",
      "Epoch 14/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.4005 - accuracy: 0.4688 - sparse_categorical_crossentropy: 1.3904.\n",
      "Epoch 14: val_loss improved from 1.48183 to 1.45613, saving model to model_14-1.46.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4053 - accuracy: 0.5325 - sparse_categorical_crossentropy: 1.3810 - val_loss: 1.4561 - val_accuracy: 0.4793 - val_sparse_categorical_crossentropy: 1.4391\n",
      "Epoch 15/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.3821 - accuracy: 0.4375 - sparse_categorical_crossentropy: 1.3715.\n",
      "Epoch 15: val_loss improved from 1.45613 to 1.41379, saving model to model_15-1.41.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3477 - accuracy: 0.5222 - sparse_categorical_crossentropy: 1.3223 - val_loss: 1.4138 - val_accuracy: 0.4852 - val_sparse_categorical_crossentropy: 1.3915\n",
      "Epoch 16/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.3359 - accuracy: 0.4375 - sparse_categorical_crossentropy: 1.3247.\n",
      "Epoch 16: val_loss improved from 1.41379 to 1.40127, saving model to model_16-1.40.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3680 - accuracy: 0.4970 - sparse_categorical_crossentropy: 1.3516 - val_loss: 1.4013 - val_accuracy: 0.4911 - val_sparse_categorical_crossentropy: 1.3794\n",
      "Epoch 17/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.2306 - accuracy: 0.5625 - sparse_categorical_crossentropy: 1.2187.\n",
      "Epoch 17: val_loss improved from 1.40127 to 1.37630, saving model to model_17-1.38.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3117 - accuracy: 0.5385 - sparse_categorical_crossentropy: 1.2913 - val_loss: 1.3763 - val_accuracy: 0.5030 - val_sparse_categorical_crossentropy: 1.3533\n",
      "Epoch 18/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.2207 - accuracy: 0.5000 - sparse_categorical_crossentropy: 1.2083.\n",
      "Epoch 18: val_loss improved from 1.37630 to 1.34928, saving model to model_18-1.35.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2717 - accuracy: 0.5562 - sparse_categorical_crossentropy: 1.2571 - val_loss: 1.3493 - val_accuracy: 0.5207 - val_sparse_categorical_crossentropy: 1.3239\n",
      "Epoch 19/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.2293 - accuracy: 0.4688 - sparse_categorical_crossentropy: 1.2163.\n",
      "Epoch 19: val_loss improved from 1.34928 to 1.33467, saving model to model_19-1.33.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2574 - accuracy: 0.5636 - sparse_categorical_crossentropy: 1.2331 - val_loss: 1.3347 - val_accuracy: 0.5148 - val_sparse_categorical_crossentropy: 1.3103\n",
      "Epoch 20/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.1664 - accuracy: 0.5625 - sparse_categorical_crossentropy: 1.1528.\n",
      "Epoch 20: val_loss improved from 1.33467 to 1.31436, saving model to model_20-1.31.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1911 - accuracy: 0.5754 - sparse_categorical_crossentropy: 1.1603 - val_loss: 1.3144 - val_accuracy: 0.5325 - val_sparse_categorical_crossentropy: 1.2915\n",
      "Epoch 21/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.1111 - accuracy: 0.6562 - sparse_categorical_crossentropy: 1.0969.\n",
      "Epoch 21: val_loss improved from 1.31436 to 1.29610, saving model to model_21-1.30.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1866 - accuracy: 0.5917 - sparse_categorical_crossentropy: 1.1732 - val_loss: 1.2961 - val_accuracy: 0.5562 - val_sparse_categorical_crossentropy: 1.2694\n",
      "Epoch 22/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.1144 - accuracy: 0.7188 - sparse_categorical_crossentropy: 1.0996.\n",
      "Epoch 22: val_loss did not improve from 1.29610\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1961 - accuracy: 0.5769 - sparse_categorical_crossentropy: 1.1623 - val_loss: 1.2977 - val_accuracy: 0.5325 - val_sparse_categorical_crossentropy: 1.2700\n",
      "Epoch 23/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.2279 - accuracy: 0.5000 - sparse_categorical_crossentropy: 1.2126.\n",
      "Epoch 23: val_loss improved from 1.29610 to 1.26484, saving model to model_23-1.26.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1572 - accuracy: 0.5917 - sparse_categorical_crossentropy: 1.1227 - val_loss: 1.2648 - val_accuracy: 0.5740 - val_sparse_categorical_crossentropy: 1.2360\n",
      "Epoch 24/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0962 - accuracy: 0.5938 - sparse_categorical_crossentropy: 1.0803.\n",
      "Epoch 24: val_loss did not improve from 1.26484\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1.1232 - accuracy: 0.6036 - sparse_categorical_crossentropy: 1.1008 - val_loss: 1.2665 - val_accuracy: 0.5385 - val_sparse_categorical_crossentropy: 1.2403\n",
      "Epoch 25/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0748 - accuracy: 0.5625 - sparse_categorical_crossentropy: 1.0584.\n",
      "Epoch 25: val_loss improved from 1.26484 to 1.25910, saving model to model_25-1.26.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0879 - accuracy: 0.6228 - sparse_categorical_crossentropy: 1.0517 - val_loss: 1.2591 - val_accuracy: 0.5503 - val_sparse_categorical_crossentropy: 1.2302\n",
      "Epoch 26/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9929 - accuracy: 0.5938 - sparse_categorical_crossentropy: 0.9760.\n",
      "Epoch 26: val_loss improved from 1.25910 to 1.24271, saving model to model_26-1.24.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0585 - accuracy: 0.6154 - sparse_categorical_crossentropy: 1.0169 - val_loss: 1.2427 - val_accuracy: 0.5680 - val_sparse_categorical_crossentropy: 1.2161\n",
      "Epoch 27/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9383 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.9209.\n",
      "Epoch 27: val_loss improved from 1.24271 to 1.23810, saving model to model_27-1.24.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0680 - accuracy: 0.6169 - sparse_categorical_crossentropy: 1.0408 - val_loss: 1.2381 - val_accuracy: 0.5917 - val_sparse_categorical_crossentropy: 1.2102\n",
      "Epoch 28/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.1167 - accuracy: 0.6250 - sparse_categorical_crossentropy: 1.0988.\n",
      "Epoch 28: val_loss improved from 1.23810 to 1.23276, saving model to model_28-1.23.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0470 - accuracy: 0.6479 - sparse_categorical_crossentropy: 1.0094 - val_loss: 1.2328 - val_accuracy: 0.5740 - val_sparse_categorical_crossentropy: 1.2052\n",
      "Epoch 29/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0631 - accuracy: 0.5938 - sparse_categorical_crossentropy: 1.0447.\n",
      "Epoch 29: val_loss improved from 1.23276 to 1.22795, saving model to model_29-1.23.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0014 - accuracy: 0.6746 - sparse_categorical_crossentropy: 0.9787 - val_loss: 1.2279 - val_accuracy: 0.5799 - val_sparse_categorical_crossentropy: 1.2015\n",
      "Epoch 30/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8617 - accuracy: 0.7188 - sparse_categorical_crossentropy: 0.8429.\n",
      "Epoch 30: val_loss did not improve from 1.22795\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9990 - accuracy: 0.6583 - sparse_categorical_crossentropy: 0.9685 - val_loss: 1.2336 - val_accuracy: 0.5621 - val_sparse_categorical_crossentropy: 1.2036\n",
      "Epoch 31/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0061 - accuracy: 0.5938 - sparse_categorical_crossentropy: 0.9867.\n",
      "Epoch 31: val_loss improved from 1.22795 to 1.21833, saving model to model_31-1.22.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9895 - accuracy: 0.6672 - sparse_categorical_crossentropy: 0.9578 - val_loss: 1.2183 - val_accuracy: 0.5858 - val_sparse_categorical_crossentropy: 1.1889\n",
      "Epoch 32/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9535 - accuracy: 0.6250 - sparse_categorical_crossentropy: 0.9337.\n",
      "Epoch 32: val_loss improved from 1.21833 to 1.21025, saving model to model_32-1.21.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0060 - accuracy: 0.6405 - sparse_categorical_crossentropy: 0.9629 - val_loss: 1.2103 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1850\n",
      "Epoch 33/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0404 - accuracy: 0.6250 - sparse_categorical_crossentropy: 1.0201.\n",
      "Epoch 33: val_loss improved from 1.21025 to 1.19953, saving model to model_33-1.20.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9150 - accuracy: 0.7012 - sparse_categorical_crossentropy: 0.8766 - val_loss: 1.1995 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.1723\n",
      "Epoch 34/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0284 - accuracy: 0.5938 - sparse_categorical_crossentropy: 1.0077.\n",
      "Epoch 34: val_loss did not improve from 1.19953\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.9483 - accuracy: 0.6672 - sparse_categorical_crossentropy: 0.9026 - val_loss: 1.1996 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.1769\n",
      "Epoch 35/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0435 - accuracy: 0.5938 - sparse_categorical_crossentropy: 1.0223.\n",
      "Epoch 35: val_loss improved from 1.19953 to 1.19731, saving model to model_35-1.20.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9517 - accuracy: 0.6805 - sparse_categorical_crossentropy: 0.9197 - val_loss: 1.1973 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1711\n",
      "Epoch 36/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9098 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.8883.\n",
      "Epoch 36: val_loss did not improve from 1.19731\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8718 - accuracy: 0.7115 - sparse_categorical_crossentropy: 0.8531 - val_loss: 1.2053 - val_accuracy: 0.5799 - val_sparse_categorical_crossentropy: 1.1865\n",
      "Epoch 37/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8974 - accuracy: 0.6250 - sparse_categorical_crossentropy: 0.8754.\n",
      "Epoch 37: val_loss did not improve from 1.19731\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8687 - accuracy: 0.6908 - sparse_categorical_crossentropy: 0.8227 - val_loss: 1.1989 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.1761\n",
      "Epoch 38/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0281 - accuracy: 0.5312 - sparse_categorical_crossentropy: 1.0057.\n",
      "Epoch 38: val_loss improved from 1.19731 to 1.18698, saving model to model_38-1.19.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8770 - accuracy: 0.6997 - sparse_categorical_crossentropy: 0.8364 - val_loss: 1.1870 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1583\n",
      "Epoch 39/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8886 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.8657.\n",
      "Epoch 39: val_loss did not improve from 1.18698\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9007 - accuracy: 0.6967 - sparse_categorical_crossentropy: 0.8594 - val_loss: 1.1947 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.1733\n",
      "Epoch 40/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8494 - accuracy: 0.6562 - sparse_categorical_crossentropy: 0.8261.\n",
      "Epoch 40: val_loss did not improve from 1.18698\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8463 - accuracy: 0.7249 - sparse_categorical_crossentropy: 0.8188 - val_loss: 1.1910 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1682\n",
      "Epoch 41/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8727 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.8490.\n",
      "Epoch 41: val_loss did not improve from 1.18698\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8456 - accuracy: 0.7189 - sparse_categorical_crossentropy: 0.8070 - val_loss: 1.1956 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.1745\n",
      "Epoch 42/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7546 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.7305.\n",
      "Epoch 42: val_loss improved from 1.18698 to 1.18626, saving model to model_42-1.19.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8286 - accuracy: 0.7263 - sparse_categorical_crossentropy: 0.7948 - val_loss: 1.1863 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1707\n",
      "Epoch 43/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6772 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.6527.\n",
      "Epoch 43: val_loss improved from 1.18626 to 1.18461, saving model to model_43-1.18.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.7352 - sparse_categorical_crossentropy: 0.7640 - val_loss: 1.1846 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.1652\n",
      "Epoch 44/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8478 - accuracy: 0.6250 - sparse_categorical_crossentropy: 0.8229.\n",
      "Epoch 44: val_loss did not improve from 1.18461\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8156 - accuracy: 0.7278 - sparse_categorical_crossentropy: 0.7688 - val_loss: 1.1982 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1874\n",
      "Epoch 45/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8403 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.8149.\n",
      "Epoch 45: val_loss did not improve from 1.18461\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7745 - accuracy: 0.7485 - sparse_categorical_crossentropy: 0.7238 - val_loss: 1.1858 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1648\n",
      "Epoch 46/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6706 - accuracy: 0.7188 - sparse_categorical_crossentropy: 0.6449.\n",
      "Epoch 46: val_loss did not improve from 1.18461\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7916 - accuracy: 0.7175 - sparse_categorical_crossentropy: 0.7552 - val_loss: 1.1862 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1633\n",
      "Epoch 47/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7991 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.7730.\n",
      "Epoch 47: val_loss did not improve from 1.18461\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7852 - accuracy: 0.7352 - sparse_categorical_crossentropy: 0.7418 - val_loss: 1.1985 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1838\n",
      "Epoch 48/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6328 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.6063.\n",
      "Epoch 48: val_loss improved from 1.18461 to 1.17996, saving model to model_48-1.18.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7596 - accuracy: 0.7441 - sparse_categorical_crossentropy: 0.7199 - val_loss: 1.1800 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1563\n",
      "Epoch 49/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6796 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.6527.\n",
      "Epoch 49: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7405 - accuracy: 0.7530 - sparse_categorical_crossentropy: 0.6904 - val_loss: 1.1970 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1843\n",
      "Epoch 50/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5770 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.5497.\n",
      "Epoch 50: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.7707 - sparse_categorical_crossentropy: 0.6853 - val_loss: 1.1965 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1800\n",
      "Epoch 51/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6773 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.6497.\n",
      "Epoch 51: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.7796 - sparse_categorical_crossentropy: 0.6784 - val_loss: 1.1849 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.1708\n",
      "Epoch 52/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7363 - accuracy: 0.7188 - sparse_categorical_crossentropy: 0.7083.\n",
      "Epoch 52: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.7648 - sparse_categorical_crossentropy: 0.6745 - val_loss: 1.1897 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1733\n",
      "Epoch 53/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6400 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.6116.\n",
      "Epoch 53: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.7574 - sparse_categorical_crossentropy: 0.6613 - val_loss: 1.1940 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1816\n",
      "Epoch 54/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6563 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.6276.\n",
      "Epoch 54: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.7781 - sparse_categorical_crossentropy: 0.6526 - val_loss: 1.1983 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1835\n",
      "Epoch 55/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6473 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.6182.\n",
      "Epoch 55: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.7885 - sparse_categorical_crossentropy: 0.6184 - val_loss: 1.1999 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1842\n",
      "Epoch 56/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5808 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.5513.\n",
      "Epoch 56: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.7899 - sparse_categorical_crossentropy: 0.6429 - val_loss: 1.2145 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1981\n",
      "Epoch 57/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6026 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.5728.\n",
      "Epoch 57: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.7707 - sparse_categorical_crossentropy: 0.6118 - val_loss: 1.1966 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1814\n",
      "Epoch 58/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7085 - accuracy: 0.7188 - sparse_categorical_crossentropy: 0.6784.\n",
      "Epoch 58: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.7840 - sparse_categorical_crossentropy: 0.6161 - val_loss: 1.2162 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.2050\n",
      "Epoch 59/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6377 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.6072.\n",
      "Epoch 59: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.8077 - sparse_categorical_crossentropy: 0.5981 - val_loss: 1.2208 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.2138\n",
      "Epoch 60/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6790 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.6482.\n",
      "Epoch 60: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6359 - accuracy: 0.7959 - sparse_categorical_crossentropy: 0.5864 - val_loss: 1.2307 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.2249\n",
      "Epoch 61/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6526 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.6215.\n",
      "Epoch 61: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6243 - accuracy: 0.7929 - sparse_categorical_crossentropy: 0.5730 - val_loss: 1.2179 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.2106\n",
      "Epoch 62/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5134 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.4819.\n",
      "Epoch 62: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.7988 - sparse_categorical_crossentropy: 0.5655 - val_loss: 1.2192 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.2111\n",
      "Epoch 63/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5333 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.5014.\n",
      "Epoch 63: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.8107 - sparse_categorical_crossentropy: 0.5844 - val_loss: 1.2332 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.2267\n",
      "Epoch 64/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6354 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.6033.\n",
      "Epoch 64: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.8003 - sparse_categorical_crossentropy: 0.5863 - val_loss: 1.2138 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1984\n",
      "Epoch 65/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6708 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.6383.\n",
      "Epoch 65: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.8225 - sparse_categorical_crossentropy: 0.5695 - val_loss: 1.2233 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.2032\n",
      "Epoch 66/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7146 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.6818.\n",
      "Epoch 66: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.8121 - sparse_categorical_crossentropy: 0.5639 - val_loss: 1.2433 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.2364\n",
      "Epoch 67/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6063 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.5731.\n",
      "Epoch 67: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.8314 - sparse_categorical_crossentropy: 0.5258 - val_loss: 1.2293 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.2135\n",
      "Epoch 68/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6843 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.6508.\n",
      "Epoch 68: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.8166 - sparse_categorical_crossentropy: 0.5536 - val_loss: 1.2336 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.2181\n",
      "Epoch 69/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.4883 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.4545.\n",
      "Epoch 69: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.8373 - sparse_categorical_crossentropy: 0.5263 - val_loss: 1.2502 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.2453\n",
      "Epoch 70/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6276 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.5935.\n",
      "Epoch 70: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.8402 - sparse_categorical_crossentropy: 0.4794 - val_loss: 1.2499 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.2402\n",
      "Epoch 71/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5546 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.5201.\n",
      "Epoch 71: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.8225 - sparse_categorical_crossentropy: 0.5198 - val_loss: 1.2649 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.2662\n",
      "Epoch 72/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5593 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.5246.\n",
      "Epoch 72: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.8343 - sparse_categorical_crossentropy: 0.4854 - val_loss: 1.2497 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.2427\n",
      "Epoch 73/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5292 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.4941.\n",
      "Epoch 73: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.8136 - sparse_categorical_crossentropy: 0.4991 - val_loss: 1.2738 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.2651\n",
      "Epoch 74/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5381 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.5027.\n",
      "Epoch 74: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.8343 - sparse_categorical_crossentropy: 0.4728 - val_loss: 1.2546 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.2401\n",
      "Epoch 75/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5450 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.5093.\n",
      "Epoch 75: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8595 - sparse_categorical_crossentropy: 0.4529 - val_loss: 1.2605 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.2370\n",
      "Epoch 76/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5324 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.4964.\n",
      "Epoch 76: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8491 - sparse_categorical_crossentropy: 0.4753 - val_loss: 1.2783 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.2702\n",
      "Epoch 77/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5755 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.5392.\n",
      "Epoch 77: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.8432 - sparse_categorical_crossentropy: 0.4817 - val_loss: 1.2731 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.2670\n",
      "Epoch 78/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5754 - accuracy: 0.9062 - sparse_categorical_crossentropy: 0.5388.\n",
      "Epoch 78: val_loss did not improve from 1.17996\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8609 - sparse_categorical_crossentropy: 0.4393 - val_loss: 1.3026 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.2983\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=CALLBACKS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:34.916989800Z",
     "start_time": "2024-02-24T14:49:30.727052700Z"
    }
   },
   "id": "18398cf390d74222",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 48\n"
     ]
    }
   ],
   "source": [
    "# Print the best epoch\n",
    "print(f\"Best epoch: {np.argmin(history.history['val_loss']) + 1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:34.920845900Z",
     "start_time": "2024-02-24T14:49:34.914844200Z"
    }
   },
   "id": "9e94b94dac4e6eeb",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now using tfdocs.plots.HistoryPlotter, we can visualize the training and validation loss and accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc642328f72f6966"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size_histories = {}\n",
    "size_histories['Baseline'] = history\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric='sparse_categorical_crossentropy', smoothing_std=10)\n",
    "plotter.plot(size_histories)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:35.032467600Z",
     "start_time": "2024-02-24T14:49:34.917845100Z"
    }
   },
   "id": "a7a2ea0769fdc279",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also plot the training and validation accuracy values, to see how the model performs throughout the epochs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e826876952f5fb0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x1b63017f3d0>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1400x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "history_data = history.history\n",
    "\n",
    "epochs = range(1, len(history_data['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history_data['accuracy'], label='Training Accuracy')\n",
    "plt.plot(epochs, history_data['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:49:35.129802700Z",
     "start_time": "2024-02-24T14:49:35.028467Z"
    }
   },
   "id": "2ef73d4bcd5566df",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the model the validation loss becomes stagnant after about 40 epochs.\n",
    "\n",
    "Let's now evaluate the model on the test dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a97fe8c00c1e28e0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0647 - accuracy: 0.6840 - sparse_categorical_crossentropy: 1.0440\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.0646954774856567, 0.6839622855186462, 1.0439884662628174]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, verbose=1, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:53:53.810373100Z",
     "start_time": "2024-02-24T10:53:53.783897Z"
    }
   },
   "id": "d52c2208aed74b8b",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also generate a classification report for the model along with the confusion matrix."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb4f229959c3287d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 833us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64        43\n",
      "           1       0.73      0.71      0.72        31\n",
      "           2       0.85      0.68      0.75        34\n",
      "           3       0.52      0.62      0.56        26\n",
      "           4       0.57      0.63      0.60        27\n",
      "           5       0.78      0.76      0.77        51\n",
      "\n",
      "    accuracy                           0.68       212\n",
      "   macro avg       0.68      0.67      0.67       212\n",
      "weighted avg       0.70      0.68      0.69       212\n",
      "\n",
      "[[28  0  2  6  2  5]\n",
      " [ 2 22  1  1  3  2]\n",
      " [ 3  4 23  2  1  1]\n",
      " [ 5  1  0 16  3  1]\n",
      " [ 2  1  0  5 17  2]\n",
      " [ 4  2  1  1  4 39]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:53:57.591156400Z",
     "start_time": "2024-02-24T10:53:57.526120700Z"
    }
   },
   "id": "73a947990a3f8705",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the model has an accuracy of 0.68, which is not bad considering the small dataset we have.\n",
    "\n",
    "However, we can see that the model is overfitting the training data, as the validation loss becomes higher than the training loss quickly,\n",
    "which makes sense given the small dataset we have.\n",
    "\n",
    "Ironically, the simpler models such as SVM and SGD outperformed the neural network model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ab41048404b3e7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Two-Level Classification\n",
    "\n",
    "As we saw from before, we got the best results using the SGD Classifier.\n",
    "\n",
    "Let's now try to perform a two-level classification, where we first classify the class of the word and then classify the division/section of the word based on the class it belongs to.\n",
    "\n",
    "Firstly, we will create a new column in the dataframe named division/section, \n",
    "where it has as value the division if the division is not 4 (meaning `N/A` in our case),\n",
    " otherwise it has the value of the section.\n",
    "\n",
    "Then we will split the data into training and testing sets, using 80% of the data for training and 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cece51585462464"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# For the cls_df dataframe create a new column named division/section where it has as value the division if the division is not 4, otherwise it has the value of the section\n",
    "cls_df['division/section'] = cls_df['division']\n",
    "\n",
    "# 4 Means No Division and this is evident if we take a look at the dataset\n",
    "cls_df.loc[cls_df['division'] == 4, 'division/section'] = cls_df['section']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:34:14.808145500Z",
     "start_time": "2024-02-24T13:34:14.792206100Z"
    }
   },
   "id": "a7f158c0df67a4a0",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's split the data into training and testing sets, using 80% of the data for training and 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2411460d85eb8e55"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get class and division/section\n",
    "y = cls_df[['class', 'division/section']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:34:15.047855600Z",
     "start_time": "2024-02-24T13:34:15.040314500Z"
    }
   },
   "id": "85fde21674eaec17",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having done that we can now approach the two-level classification using the SGD Classifier as before, but this\n",
    "time we will use the `MultiOutputClassifier` from sklearn to perform the multi-output classification.\n",
    "This will allow us to train a single model to predict multiple target variables, in our case the class and the division/section it belongs to.\n",
    "However, there is a drawback to this approach, because at present, no metric in sklearn.metrics supports the multiclass-multioutput classification task.\n",
    "This means that we will have to create our own custom accuracy metric for the multi-output classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25d67e79115b7dd8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-output Accuracy: 0.5377358490566038\n"
     ]
    }
   ],
   "source": [
    "# Create a multi-output classifier\n",
    "multi_output_model = MultiOutputClassifier(\n",
    "    sgd_model, n_jobs=-1)\n",
    "\n",
    "# Train the multi-output classifier\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = multi_output_model.predict(X_test)\n",
    "\n",
    "# Custom accuracy for multi-output\n",
    "def multioutput_accuracy(y_true, y_pred):\n",
    "    correct = np.all(y_true == y_pred, axis=1)\n",
    "    return np.mean(correct)\n",
    "\n",
    "accuracy = multioutput_accuracy(y_test, y_pred)\n",
    "print(f\"Multi-output Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:34:18.119601500Z",
     "start_time": "2024-02-24T13:34:15.590134400Z"
    }
   },
   "id": "79b2a49fecb749be",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the multi-output accuracy is 0.538 which is not bad considering the small dataset we have,\n",
    "however, it is not as good as the single-output classification we performed earlier.\n",
    "Also, the custom accuracy metric we created may not be the best way to evaluate the multi-output classification.\n",
    "\n",
    "For that reason, let's also look at the accuracy of each target separately."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7326f9175f93ceb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 0 accuracy: 0.7169811320754716\n",
      "Target 1 accuracy: 0.589622641509434\n"
     ]
    }
   ],
   "source": [
    "for i in range(y_test.shape[1]):\n",
    "    # Use .iloc to select all rows and the ith column for both Y_test and predictions\n",
    "    accuracy = metrics.accuracy_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    print(f\"Target {i} accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:35:39.651822300Z",
     "start_time": "2024-02-24T13:35:39.629788900Z"
    }
   },
   "id": "aad02505956f90b5",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the accuracy of the first target (class) is around 0.716, which is the same as the single-output classification we performed earlier,\n",
    "however, the accuracy of the second target (division/section) is around 0.589, which is not as good as the single-output classification we performed earlier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f28f8346f842146b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
