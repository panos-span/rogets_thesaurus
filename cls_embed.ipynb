{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "394fd2a47b379d55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Before we start\n",
    "\n",
    "We first need to go over the dependencies needed for this notebook to function properly."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "173a52054227e2f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use the following libraries:\n",
    "\n",
    "- `pandas` for data manipulation\n",
    "- `numpy` for numerical operations\n",
    "- `matplotlib` for visualization\n",
    "---\n",
    "- `json` for JSON manipulation\n",
    "---\n",
    "- `sklearn` for the Machine Learning algorithms, metrics and useful visualization tools such as t-SNE\n",
    "- `optuna` for hyperparameter tuning\n",
    "- `tensorflow` for the neural network model\n",
    "- `keras` for the neural network model\n",
    "- `tensorflow_docs` for the visualization tools used in the neural network model\n",
    "- `catboost` for the CatBoost model\n",
    "---\n",
    "- `chromadb` to retrieve the embeddings to a vector database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed0bdb4629e22923"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import catboost as cb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:49:58.282850100Z",
     "start_time": "2024-02-24T13:49:43.808159400Z"
    }
   },
   "id": "fa234cafe136d166",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Let's now retrieve the classification embeddings from the chromadb vector database and perform classification on them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb007503dc588dee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = client.get_collection(\"nomic_classification_v1\")"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:49:58.387823500Z",
     "start_time": "2024-02-24T13:49:58.283849500Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let us get the words along with their classes and division and sections from the json file we created earlier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84452ecc48ce9511"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"hierarchy.json\", \"r\") as f:\n",
    "    categories = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:49:58.390937200Z",
     "start_time": "2024-02-24T13:49:58.387823500Z"
    }
   },
   "id": "6185d3b32070a313",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's retrieve the embeddings and the words along with the class, division, and section from the chromadb and create a dataframe with them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d5ef59ed70ec91"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                   word                                          embedding  \\\n0             Existence  [-0.029754638671875, -0.0263671875, -0.0127792...   \n1           Inexistence  [-0.01029205322265625, 0.019256591796875, -0.0...   \n2         Consanguinity  [0.0386962890625, -0.01026153564453125, -0.013...   \n3            Trisection  [0.007350921630859375, -0.001903533935546875, ...   \n4             Innocence  [0.0338134765625, 0.0139923095703125, -0.03097...   \n...                 ...                                                ...   \n1052              Knave  [0.0032215118408203125, 0.01201629638671875, -...   \n1053  Disinterestedness  [-0.01776123046875, 0.020965576171875, -0.0221...   \n1054        Selfishness  [0.01071929931640625, 0.049468994140625, -0.03...   \n1055             Virtue  [0.0201416015625, 0.006626129150390625, -0.035...   \n1056               Vice  [0.0035228729248046875, -0.028533935546875, -0...   \n\n                                                class division  \\\n0                 WORDS EXPRESSING ABSTRACT RELATIONS      N/A   \n1                 WORDS EXPRESSING ABSTRACT RELATIONS      N/A   \n2                 WORDS EXPRESSING ABSTRACT RELATIONS      N/A   \n3                 WORDS EXPRESSING ABSTRACT RELATIONS      N/A   \n4     WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n...                                               ...      ...   \n1052  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n1053  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n1054  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n1055  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n1056  WORDS RELATING TO THE SENTIENT AND MORAL POWERS      N/A   \n\n               section  \n0            EXISTENCE  \n1            EXISTENCE  \n2             RELATION  \n3               NUMBER  \n4     MORAL AFFECTIONS  \n...                ...  \n1052  MORAL AFFECTIONS  \n1053  MORAL AFFECTIONS  \n1054  MORAL AFFECTIONS  \n1055  MORAL AFFECTIONS  \n1056  MORAL AFFECTIONS  \n\n[1057 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>embedding</th>\n      <th>class</th>\n      <th>division</th>\n      <th>section</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Existence</td>\n      <td>[-0.029754638671875, -0.0263671875, -0.0127792...</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Inexistence</td>\n      <td>[-0.01029205322265625, 0.019256591796875, -0.0...</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Consanguinity</td>\n      <td>[0.0386962890625, -0.01026153564453125, -0.013...</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>RELATION</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trisection</td>\n      <td>[0.007350921630859375, -0.001903533935546875, ...</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>NUMBER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Innocence</td>\n      <td>[0.0338134765625, 0.0139923095703125, -0.03097...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>Knave</td>\n      <td>[0.0032215118408203125, 0.01201629638671875, -...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>Disinterestedness</td>\n      <td>[-0.01776123046875, 0.020965576171875, -0.0221...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>Selfishness</td>\n      <td>[0.01071929931640625, 0.049468994140625, -0.03...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>Virtue</td>\n      <td>[0.0201416015625, 0.006626129150390625, -0.035...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>Vice</td>\n      <td>[0.0035228729248046875, -0.028533935546875, -0...</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>MORAL AFFECTIONS</td>\n    </tr>\n  </tbody>\n</table>\n<p>1057 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the embeddings, words, and metadata\n",
    "words = collection.get(include=[\"embeddings\", \"documents\"])['documents']\n",
    "embeddings = collection.get(include=[\"embeddings\", \"documents\"])['embeddings']\n",
    "metadata = collection.get(include=[\"embeddings\", \"documents\", \"metadatas\"])['metadatas']\n",
    "\n",
    "# Create a dataframe with the embeddings and the words\n",
    "cls_df = pd.DataFrame({'word': words, 'embedding': embeddings})\n",
    "\n",
    "# Add the class, division, and section from metadata to the dataframe\n",
    "cls_df['class'] = [md['class'] for md in metadata]\n",
    "cls_df['division'] = [md['division'] for md in metadata]\n",
    "cls_df['section'] = [md['section'] for md in metadata]\n",
    "\n",
    "cls_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:49:58.493249300Z",
     "start_time": "2024-02-24T13:49:58.390937200Z"
    }
   },
   "id": "b09af619c5292133",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the number of classes\n",
    "n_classes = cls_df['class'].nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:49:58.499558900Z",
     "start_time": "2024-02-24T13:49:58.493249300Z"
    }
   },
   "id": "cd0630a75478e058",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's prepare the data for classification by converting the class, division, and section to numerical values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3501a068561a6136"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                   word                                          embedding  \\\n0             Existence  [-0.029754638671875, -0.0263671875, -0.0127792...   \n1           Inexistence  [-0.01029205322265625, 0.019256591796875, -0.0...   \n2         Consanguinity  [0.0386962890625, -0.01026153564453125, -0.013...   \n3            Trisection  [0.007350921630859375, -0.001903533935546875, ...   \n4             Innocence  [0.0338134765625, 0.0139923095703125, -0.03097...   \n...                 ...                                                ...   \n1052              Knave  [0.0032215118408203125, 0.01201629638671875, -...   \n1053  Disinterestedness  [-0.01776123046875, 0.020965576171875, -0.0221...   \n1054        Selfishness  [0.01071929931640625, 0.049468994140625, -0.03...   \n1055             Virtue  [0.0201416015625, 0.006626129150390625, -0.035...   \n1056               Vice  [0.0035228729248046875, -0.028533935546875, -0...   \n\n      class  division  section  \n0         0         4        7  \n1         0         4        7  \n2         0         4       29  \n3         0         4       19  \n4         4         4       16  \n...     ...       ...      ...  \n1052      4         4       16  \n1053      4         4       16  \n1054      4         4       16  \n1055      4         4       16  \n1056      4         4       16  \n\n[1057 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>embedding</th>\n      <th>class</th>\n      <th>division</th>\n      <th>section</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Existence</td>\n      <td>[-0.029754638671875, -0.0263671875, -0.0127792...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Inexistence</td>\n      <td>[-0.01029205322265625, 0.019256591796875, -0.0...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Consanguinity</td>\n      <td>[0.0386962890625, -0.01026153564453125, -0.013...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trisection</td>\n      <td>[0.007350921630859375, -0.001903533935546875, ...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Innocence</td>\n      <td>[0.0338134765625, 0.0139923095703125, -0.03097...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>Knave</td>\n      <td>[0.0032215118408203125, 0.01201629638671875, -...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>Disinterestedness</td>\n      <td>[-0.01776123046875, 0.020965576171875, -0.0221...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>Selfishness</td>\n      <td>[0.01071929931640625, 0.049468994140625, -0.03...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>Virtue</td>\n      <td>[0.0201416015625, 0.006626129150390625, -0.035...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>Vice</td>\n      <td>[0.0035228729248046875, -0.028533935546875, -0...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n<p>1057 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make all classes and divisions/sections as numerical values\n",
    "cls_df['class'] = pd.Categorical(cls_df['class'])\n",
    "cls_df['division'] = pd.Categorical(cls_df['division'])\n",
    "cls_df['section'] = pd.Categorical(cls_df['section'])\n",
    "\n",
    "cls_df['class'] = cls_df['class'].cat.codes\n",
    "cls_df['division'] = cls_df['division'].cat.codes\n",
    "cls_df['section'] = cls_df['section'].cat.codes\n",
    "cls_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:49:58.509849200Z",
     "start_time": "2024-02-24T13:49:58.497558300Z"
    }
   },
   "id": "516a1edf25fbdd15",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Easy to notice is that when the class has no division, the division is 4, which means `N/A` in our case.\n",
    "This will become important later when we perform the two-level classification.\n",
    "\n",
    "Let's also prepare the embeddings for classification by converting them to a numpy array."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "891ef0bbf5ddeecc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = np.vstack(cls_df['embedding'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:49:58.574033900Z",
     "start_time": "2024-02-24T13:49:58.509849200Z"
    }
   },
   "id": "1d2b8c0fca50cf83",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class logistic regression\n",
    "\n",
    "Let us start by training a multi-class logistic regression model on the embeddings and the class.\n",
    "\n",
    "Before we do that, however, let's split the data into training and testing sets, using 80% of the data for training and 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0da1d957a8e1533"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y = cls_df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:49:58.603035Z",
     "start_time": "2024-02-24T13:49:58.531838600Z"
    }
   },
   "id": "e541551066686048",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's train a logistic regression model on the training data and evaluate it on the testing data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b8a7c1f9edc9e63"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=1000, multi_class='ovr', n_jobs=-1, random_state=42)",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;ovr&#x27;, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;ovr&#x27;, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, multi_class='ovr' , n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:50:01.441312500Z",
     "start_time": "2024-02-24T13:49:58.538035200Z"
    }
   },
   "id": "2a20c0e4ce5e28ab",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65        43\n",
      "           1       0.73      0.61      0.67        31\n",
      "           2       0.79      0.56      0.66        34\n",
      "           3       0.70      0.73      0.72        26\n",
      "           4       0.55      0.63      0.59        27\n",
      "           5       0.66      0.75      0.70        51\n",
      "\n",
      "    accuracy                           0.67       212\n",
      "   macro avg       0.68      0.66      0.66       212\n",
      "weighted avg       0.68      0.67      0.67       212\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:50:01.448686100Z",
     "start_time": "2024-02-24T13:50:01.441312500Z"
    }
   },
   "id": "8caa5ddbc9c9df03",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having trained and evaluated the model, we can see that the model has an accuracy of 0.67, \n",
    "which is not bad considering the previous results we got from the clustering of the embeddings.\n",
    "\n",
    "However, let's use a hyperparameter tuning library such as `optuna` to find the best hyperparameters for the model.\n",
    "\n",
    "We will use the `cross_val_score` function from `sklearn` to evaluate the model using cross-validation and the `optuna` library to find the best hyperparameters for the model based on the maximization of the accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f52da790af8442a3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:37:35,745] A new study created in memory with name: no-name-a6545a54-782a-4c8b-bd82-204da2c722dd\n",
      "[W 2024-02-24 15:37:37,844] Trial 0 failed with parameters: {'multi_class': 'ovr', 'C': 1.035041618345576} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Temp\\ipykernel_32352\\3733145933.py\", line 9, in objective\n",
      "    score = cross_val_score(model, X, y, scoring='accuracy')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 714, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 425, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1296, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1952, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1595, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"C:\\Users\\panagiotis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1707, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2024-02-24 15:37:37,860] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Create a study object and specify the optimization direction\u001B[39;00m\n\u001B[0;32m     14\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# You can adjust the number of trials\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Output the best hyperparameters\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest trial:\u001B[39m\u001B[38;5;124m'\u001B[39m, study\u001B[38;5;241m.\u001B[39mbest_trial\u001B[38;5;241m.\u001B[39mparams)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:451\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    350\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    357\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    358\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    250\u001B[0m ):\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[42], line 9\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m LogisticRegression(C\u001B[38;5;241m=\u001B[39mC, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, multi_class\u001B[38;5;241m=\u001B[39mmulti_class , n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Perform cross-validation and return the mean score\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maccuracy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m score\u001B[38;5;241m.\u001B[39mmean()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:714\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[0;32m    712\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 714\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    723\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    724\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    725\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    726\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    727\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    728\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    424\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 425\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    426\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    435\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    436\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscore_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscorer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    439\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    440\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    441\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    442\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    447\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1861\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1862\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[0;32m   1865\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1866\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1867\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1868\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1869\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1870\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1790\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1791\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1792\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1793\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1794\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:890\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    888\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    889\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 890\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    893\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[0;32m    894\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1351\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1344\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1347\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1348\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1349\u001B[0m     )\n\u001B[0;32m   1350\u001B[0m ):\n\u001B[1;32m-> 1351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1294\u001B[0m     n_threads \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1296\u001B[0m fold_coefs_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprefer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1298\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1299\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1300\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1301\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mC_\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1302\u001B[0m \u001B[43m        \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ml1_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1303\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1306\u001B[0m \u001B[43m        \u001B[49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoef\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1315\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_threads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1317\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1318\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mclasses_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1319\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1321\u001B[0m fold_coefs_, _, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mfold_coefs_)\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(n_iter_, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint32)[:, \u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    multi_class = trial.suggest_categorical('multi_class', ['ovr', 'multinomial'])\n",
    "    C = trial.suggest_float('C', 1e-4, 1e4, log=True)\n",
    "\n",
    "    # Create logistic regression model with suggested hyperparameters\n",
    "    model = LogisticRegression(C=C, random_state=42, max_iter=1000, multi_class=multi_class , n_jobs=-1)\n",
    "    # Perform cross-validation and return the mean score\n",
    "    score = cross_val_score(model, X, y, scoring='accuracy')\n",
    "    return score.mean()\n",
    "\n",
    "\n",
    "# Create a study object and specify the optimization direction\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print('Best trial:', study.best_trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:38.119889900Z",
     "start_time": "2024-02-24T13:37:35.745813500Z"
    }
   },
   "id": "9e76682b23c63239",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class SVM\n",
    "\n",
    "Let's now train a multi-class SVM model on the embeddings and the class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e86e3dc9de132389"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(random_state=22)",
      "text/html": "<style>#sk-container-id-6 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-6 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-6 pre {\n  padding: 0;\n}\n\n#sk-container-id-6 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-6 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-6 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-6 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-6 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-6 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-6 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-6 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-6 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-6 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-6 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-6 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-6 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-6 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n#sk-container-id-6 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-6 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-6 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-6 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-6 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-6 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-6 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-6 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-6 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=22)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(random_state=22)</pre></div> </div></div></div></div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=22)\n",
    "svm_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:41.567936200Z",
     "start_time": "2024-02-24T13:37:41.483041400Z"
    }
   },
   "id": "2c66c7edab0d64",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65        43\n",
      "           1       0.78      0.68      0.72        31\n",
      "           2       0.77      0.68      0.72        34\n",
      "           3       0.69      0.77      0.73        26\n",
      "           4       0.58      0.56      0.57        27\n",
      "           5       0.70      0.78      0.74        51\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.69      0.69      0.69       212\n",
      "weighted avg       0.70      0.69      0.69       212\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:41.699568600Z",
     "start_time": "2024-02-24T13:37:41.657120800Z"
    }
   },
   "id": "62835de5722c9451",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use the `optuna` library to find the best hyperparameters for the model based on the maximization of the accuracy.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a87564b264fa6a83"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:21:53,815] A new study created in memory with name: no-name-fbb0df03-3332-4ee6-88b9-63dab539915d\n",
      "[I 2024-02-24 15:21:54,150] Trial 0 finished with value: 0.4844272556559063 and parameters: {'C': 7.601359404948779, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.4844272556559063.\n",
      "[I 2024-02-24 15:21:54,670] Trial 1 finished with value: 0.21570240543682373 and parameters: {'C': 0.001925613168034482, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 0 with value: 0.4844272556559063.\n",
      "[I 2024-02-24 15:21:55,067] Trial 2 finished with value: 0.46643566127157293 and parameters: {'C': 24.637615145321337, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.4844272556559063.\n",
      "[I 2024-02-24 15:21:55,604] Trial 3 finished with value: 0.425744433515157 and parameters: {'C': 6832.795980529893, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.4844272556559063.\n",
      "[I 2024-02-24 15:21:56,014] Trial 4 finished with value: 0.5317401412858803 and parameters: {'C': 1.4379973680508373, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:56,618] Trial 5 finished with value: 0.21570240543682373 and parameters: {'C': 0.000217696136663899, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:57,206] Trial 6 finished with value: 0.21570240543682373 and parameters: {'C': 0.06706648734553318, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:57,771] Trial 7 finished with value: 0.21570240543682373 and parameters: {'C': 0.0003486572030786427, 'kernel': 'poly', 'gamma': 'scale', 'degree': 9}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:58,274] Trial 8 finished with value: 0.21570240543682373 and parameters: {'C': 0.00019261412167823918, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 4 with value: 0.5317401412858803.\n",
      "[I 2024-02-24 15:21:58,703] Trial 9 finished with value: 0.5345748010372887 and parameters: {'C': 1349.686937395348, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:21:59,136] Trial 10 finished with value: 0.4626263077886078 and parameters: {'C': 44898.19741475613, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:00,089] Trial 11 finished with value: 0.5109049450058124 and parameters: {'C': 362.64192955214537, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:00,800] Trial 12 finished with value: 0.21665027273540197 and parameters: {'C': 0.16166637889362026, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:01,631] Trial 13 finished with value: 0.5109049450058124 and parameters: {'C': 457.7325417452622, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:02,233] Trial 14 finished with value: 0.21570240543682373 and parameters: {'C': 2.6596456078573207, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:02,836] Trial 15 finished with value: 0.21570240543682373 and parameters: {'C': 0.013186305784828524, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:03,275] Trial 16 finished with value: 0.42193508003219177 and parameters: {'C': 173.5294969190992, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:03,884] Trial 17 finished with value: 0.4711660556201377 and parameters: {'C': 5308.8213445462225, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:04,311] Trial 18 finished with value: 0.4607395153357775 and parameters: {'C': 35.01917464112912, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:04,974] Trial 19 finished with value: 0.21570240543682373 and parameters: {'C': 0.6164190668102112, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:05,393] Trial 20 finished with value: 0.4626263077886078 and parameters: {'C': 79144.72132756445, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:06,085] Trial 21 finished with value: 0.5109049450058124 and parameters: {'C': 736.8500821551859, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:06,747] Trial 22 finished with value: 0.5109049450058124 and parameters: {'C': 2094.8480298218074, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:07,406] Trial 23 finished with value: 0.5109049450058124 and parameters: {'C': 71.13359417171642, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.5345748010372887.\n",
      "[I 2024-02-24 15:22:07,970] Trial 24 finished with value: 0.5364839488509345 and parameters: {'C': 1.2898399952483892, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 24 with value: 0.5364839488509345.\n",
      "[I 2024-02-24 15:22:08,554] Trial 25 finished with value: 0.5374139318608602 and parameters: {'C': 0.7230932292213924, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:09,184] Trial 26 finished with value: 0.21570240543682373 and parameters: {'C': 1.4471352501689741e-05, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:09,849] Trial 27 finished with value: 0.21570240543682373 and parameters: {'C': 0.018144029431884836, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:10,488] Trial 28 finished with value: 0.21570240543682373 and parameters: {'C': 0.24751487521293652, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:11,141] Trial 29 finished with value: 0.21570240543682373 and parameters: {'C': 10.378344769194756, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:11,497] Trial 30 finished with value: 0.5043101135652329 and parameters: {'C': 7.710235543437327, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 25 with value: 0.5374139318608602.\n",
      "[I 2024-02-24 15:22:11,893] Trial 31 finished with value: 0.5393051953858536 and parameters: {'C': 0.9821176466487772, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:12,420] Trial 32 finished with value: 0.21570240543682373 and parameters: {'C': 0.023957248284480558, 'kernel': 'poly', 'gamma': 'scale', 'degree': 10}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:12,973] Trial 33 finished with value: 0.5307788607708128 and parameters: {'C': 2.007292432436496, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:13,419] Trial 34 finished with value: 0.5222659393722615 and parameters: {'C': 0.428706656618169, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:13,938] Trial 35 finished with value: 0.21570240543682373 and parameters: {'C': 0.003076987031322429, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:14,424] Trial 36 finished with value: 0.21570240543682373 and parameters: {'C': 3.2099247266279747, 'kernel': 'poly', 'gamma': 'auto', 'degree': 1}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:14,905] Trial 37 finished with value: 0.21570240543682373 and parameters: {'C': 0.07169969401820692, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:15,552] Trial 38 finished with value: 0.21570240543682373 and parameters: {'C': 16.025041858118353, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:16,069] Trial 39 finished with value: 0.21570240543682373 and parameters: {'C': 0.0037381167878459557, 'kernel': 'poly', 'gamma': 'scale', 'degree': 7}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:16,434] Trial 40 finished with value: 0.4626263077886078 and parameters: {'C': 21593.214598857678, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:16,820] Trial 41 finished with value: 0.5364705356344451 and parameters: {'C': 1.1698150360061574, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 31 with value: 0.5393051953858536.\n",
      "[I 2024-02-24 15:22:17,221] Trial 42 finished with value: 0.5421398551372618 and parameters: {'C': 0.8233556021830791, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 42 with value: 0.5421398551372618.\n",
      "[I 2024-02-24 15:22:17,630] Trial 43 finished with value: 0.5459357954037378 and parameters: {'C': 0.751796233971926, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:18,116] Trial 44 finished with value: 0.21665027273540197 and parameters: {'C': 0.10817776622138571, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:18,543] Trial 45 finished with value: 0.5374273450773496 and parameters: {'C': 0.5448644436372487, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:18,900] Trial 46 finished with value: 0.5071268890279889 and parameters: {'C': 4.255075471261124, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:19,336] Trial 47 finished with value: 0.5364794777787714 and parameters: {'C': 0.5422385226700206, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:19,818] Trial 48 finished with value: 0.21570240543682373 and parameters: {'C': 0.04948907568078755, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:20,184] Trial 49 finished with value: 0.4616873826343557 and parameters: {'C': 42.58697250850883, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:20,652] Trial 50 finished with value: 0.46735223106500945 and parameters: {'C': 0.3004121182515278, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:21,038] Trial 51 finished with value: 0.541205401055173 and parameters: {'C': 1.1347945577487542, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:21,437] Trial 52 finished with value: 0.5411964589108468 and parameters: {'C': 0.8860052238966536, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:21,917] Trial 53 finished with value: 0.2904274344987928 and parameters: {'C': 0.17204781345243164, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:22,263] Trial 54 finished with value: 0.5137619601180363 and parameters: {'C': 3.4011581200321803, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:22,605] Trial 55 finished with value: 0.48726638647947773 and parameters: {'C': 6.432656089682004, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:22,960] Trial 56 finished with value: 0.4645533398909058 and parameters: {'C': 20.406183611007563, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:23,444] Trial 57 finished with value: 0.21570240543682373 and parameters: {'C': 0.04157224783572025, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:23,809] Trial 58 finished with value: 0.4626263077886078 and parameters: {'C': 95.90704161792591, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:24,294] Trial 59 finished with value: 0.21570240543682373 and parameters: {'C': 0.006704431105845286, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:24,682] Trial 60 finished with value: 0.5345748010372888 and parameters: {'C': 1.236608983033544, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:25,096] Trial 61 finished with value: 0.5431011356523293 and parameters: {'C': 0.7190603593664717, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:25,578] Trial 62 finished with value: 0.22704104444245732 and parameters: {'C': 0.1320401009237171, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:26,036] Trial 63 finished with value: 0.4929044084771529 and parameters: {'C': 0.3634492134956047, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:26,400] Trial 64 finished with value: 0.5345748010372887 and parameters: {'C': 1.8450902275469931, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:26,794] Trial 65 finished with value: 0.5440400608065815 and parameters: {'C': 1.0153308599928903, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:27,135] Trial 66 finished with value: 0.4825136367700974 and parameters: {'C': 9.814389807499674, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:27,529] Trial 67 finished with value: 0.5431011356523294 and parameters: {'C': 1.033051130805212, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:28,006] Trial 68 finished with value: 0.38408745417151036 and parameters: {'C': 0.21803648360561836, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:28,477] Trial 69 finished with value: 0.21570240543682373 and parameters: {'C': 0.0004999350391905135, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:29,028] Trial 70 finished with value: 0.5336358758830367 and parameters: {'C': 2.232089419195453, 'kernel': 'poly', 'gamma': 'scale', 'degree': 7}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:29,434] Trial 71 finished with value: 0.542144326209425 and parameters: {'C': 0.8000766304187258, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:29,847] Trial 72 finished with value: 0.5449923991773227 and parameters: {'C': 0.7327553642642187, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:30,202] Trial 73 finished with value: 0.5071492443888044 and parameters: {'C': 4.910351842357012, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:30,692] Trial 74 finished with value: 0.21570240543682373 and parameters: {'C': 0.06835665082698622, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:31,157] Trial 75 finished with value: 0.471134758114996 and parameters: {'C': 0.327076276738437, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:31,644] Trial 76 finished with value: 0.21570240543682373 and parameters: {'C': 0.03302706149767862, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:32,019] Trial 77 finished with value: 0.5345748010372887 and parameters: {'C': 1.75688732122823, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:32,525] Trial 78 finished with value: 0.21570240543682373 and parameters: {'C': 0.08460924014026831, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:32,876] Trial 79 finished with value: 0.47020924617723325 and parameters: {'C': 15.592646875269537, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:33,301] Trial 80 finished with value: 0.5440490029509075 and parameters: {'C': 0.711073742609546, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:33,709] Trial 81 finished with value: 0.5421398551372618 and parameters: {'C': 0.8964628292134403, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:34,138] Trial 82 finished with value: 0.5431011356523294 and parameters: {'C': 0.6520191273530229, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:34,636] Trial 83 finished with value: 0.44369131717785926 and parameters: {'C': 0.1978114966062945, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:35,073] Trial 84 finished with value: 0.5383707413037646 and parameters: {'C': 0.557726303171182, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:35,579] Trial 85 finished with value: 0.5232227488151658 and parameters: {'C': 2.988764946775258, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:36,062] Trial 86 finished with value: 0.519431279620853 and parameters: {'C': 0.4322847775280805, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:36,560] Trial 87 finished with value: 0.5014396852365197 and parameters: {'C': 6.843422616226855, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:37,078] Trial 88 finished with value: 0.21570240543682373 and parameters: {'C': 0.012122349937956727, 'kernel': 'poly', 'gamma': 'scale', 'degree': 6}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:37,548] Trial 89 finished with value: 0.21570240543682373 and parameters: {'C': 0.11950824827629233, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:38,028] Trial 90 finished with value: 0.5392962532415273 and parameters: {'C': 0.6683908109340915, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:38,410] Trial 91 finished with value: 0.5336314048108737 and parameters: {'C': 1.4834634070191286, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:38,818] Trial 92 finished with value: 0.540266475900921 and parameters: {'C': 0.8055984278138975, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:39,300] Trial 93 finished with value: 0.4597961191093624 and parameters: {'C': 0.28599700246719006, 'kernel': 'poly', 'gamma': 'scale', 'degree': 1}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:39,692] Trial 94 finished with value: 0.5222614683000983 and parameters: {'C': 2.7146086036731907, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:40,136] Trial 95 finished with value: 0.5449879281051596 and parameters: {'C': 1.003831959485295, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:40,492] Trial 96 finished with value: 0.5099704909237235 and parameters: {'C': 5.500791921280731, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:40,835] Trial 97 finished with value: 0.4967227041044442 and parameters: {'C': 11.772657150834235, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:41,353] Trial 98 finished with value: 0.21665027273540197 and parameters: {'C': 0.16566131148520663, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n",
      "[I 2024-02-24 15:22:41,709] Trial 99 finished with value: 0.4531834033801306 and parameters: {'C': 32.66110696578537, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 43 with value: 0.5459357954037378.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'C': 0.751796233971926, 'kernel': 'linear', 'gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    C = trial.suggest_float('C', 1e-5, 1e5, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "\n",
    "    # If kernel is 'poly', we also tune degree\n",
    "    if kernel == 'poly':\n",
    "        degree = trial.suggest_int('degree', 1, 10)\n",
    "\n",
    "    # Create and train the SVM model\n",
    "    if kernel == 'poly':\n",
    "        model = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, random_state=22)\n",
    "    else:\n",
    "        model = SVC(C=C, kernel=kernel, gamma=gamma, random_state=22)\n",
    "\n",
    "    score = cross_val_score(model, X, y, scoring='accuracy')\n",
    "    return score.mean()\n",
    "\n",
    "\n",
    "# Create a study object and specify the optimization direction\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print('Best trial:', study.best_trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:22:41.713803300Z",
     "start_time": "2024-02-24T13:21:53.816564400Z"
    }
   },
   "id": "3352fe02bac0f7c4",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class SGD\n",
    "\n",
    "Let's now train a multi-class SGD model on the embeddings and the class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78bd39336c8fa4c1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SGDClassifier(alpha=2.6545371602330262e-06, eta0=0.007698135990041223,\n              learning_rate='adaptive', loss='squared_hinge', n_jobs=-1,\n              random_state=42)",
      "text/html": "<style>#sk-container-id-7 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-7 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-7 pre {\n  padding: 0;\n}\n\n#sk-container-id-7 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-7 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-7 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-7 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-7 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-7 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-7 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-7 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-7 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-7 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-7 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-7 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-7 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-7 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n#sk-container-id-7 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-7 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-7 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-7 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-7 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-7 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-7 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-7 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=2.6545371602330262e-06, eta0=0.007698135990041223,\n              learning_rate=&#x27;adaptive&#x27;, loss=&#x27;squared_hinge&#x27;, n_jobs=-1,\n              random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(alpha=2.6545371602330262e-06, eta0=0.007698135990041223,\n              learning_rate=&#x27;adaptive&#x27;, loss=&#x27;squared_hinge&#x27;, n_jobs=-1,\n              random_state=42)</pre></div> </div></div></div></div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model = SGDClassifier(loss='squared_hinge', max_iter=1000, n_jobs=-1, random_state=42,\n",
    "                          penalty='l2', alpha=2.6545371602330262e-06,\n",
    "                          learning_rate='adaptive', eta0=0.007698135990041223)\n",
    "sgd_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:47.218605400Z",
     "start_time": "2024-02-24T13:37:47.065594200Z"
    }
   },
   "id": "52c78921d9b40eea",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73        43\n",
      "           1       0.73      0.71      0.72        31\n",
      "           2       0.76      0.74      0.75        34\n",
      "           3       0.67      0.69      0.68        26\n",
      "           4       0.62      0.67      0.64        27\n",
      "           5       0.72      0.76      0.74        51\n",
      "\n",
      "    accuracy                           0.72       212\n",
      "   macro avg       0.71      0.71      0.71       212\n",
      "weighted avg       0.72      0.72      0.72       212\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:37:47.428834600Z",
     "start_time": "2024-02-24T13:37:47.419665Z"
    }
   },
   "id": "fe95d6f1c77a888d",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use the `optuna` library to find the best hyperparameters for the model based on the maximization of the accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc1256b67572c199"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:24:16,607] A new study created in memory with name: no-name-92fe01f2-11bc-4229-83df-456aa2fb7503\n",
      "[I 2024-02-24 15:24:17,084] Trial 0 finished with value: 0.6047337278106509 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'alpha': 5.849013687796652e-06, 'learning_rate': 'adaptive', 'eta0': 0.0013475657567535645}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:17,609] Trial 1 finished with value: 0.4958579881656805 and parameters: {'loss': 'squared_hinge', 'penalty': 'l2', 'alpha': 0.02749692429366791, 'learning_rate': 'constant', 'eta0': 0.02176202623344909}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:18,008] Trial 2 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.997101470441552e-05, 'learning_rate': 'invscaling', 'eta0': 0.00022191668819864202}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:20,501] Trial 3 finished with value: 0.5396449704142012 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 0.0027546216060563697, 'learning_rate': 'optimal', 'eta0': 0.018066274256286548}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:21,326] Trial 4 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.02074583715225828, 'learning_rate': 'constant', 'eta0': 0.0003352475325948246}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:21,547] Trial 5 finished with value: 0.2201183431952663 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.05143432818927347, 'learning_rate': 'optimal', 'eta0': 0.00012016007598521636}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:22,919] Trial 6 finished with value: 0.5893491124260355 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 3.622916129577757e-06, 'learning_rate': 'optimal', 'eta0': 5.1519238307542115e-05}. Best is trial 0 with value: 0.6047337278106509.\n",
      "[I 2024-02-24 15:24:29,176] Trial 7 finished with value: 0.6142011834319527 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 2.4658544456124004e-06, 'learning_rate': 'adaptive', 'eta0': 0.041784241447272046}. Best is trial 7 with value: 0.6142011834319527.\n",
      "[I 2024-02-24 15:24:38,191] Trial 8 finished with value: 0.20946745562130178 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 0.01089458426470588, 'learning_rate': 'invscaling', 'eta0': 0.0003731696632510087}. Best is trial 7 with value: 0.6142011834319527.\n",
      "[I 2024-02-24 15:24:38,972] Trial 9 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 2.9232576203632103e-06, 'learning_rate': 'constant', 'eta0': 0.0015070036355670194}. Best is trial 7 with value: 0.6142011834319527.\n",
      "[I 2024-02-24 15:24:43,898] Trial 10 finished with value: 0.6390532544378698 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 6.589324727664278e-05, 'learning_rate': 'adaptive', 'eta0': 0.08356603976765953}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:24:48,910] Trial 11 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.00015472275939682194, 'learning_rate': 'adaptive', 'eta0': 0.07214098202895726}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:24:50,617] Trial 12 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.00013082160055436523, 'learning_rate': 'adaptive', 'eta0': 0.006157260960841587}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:24:55,857] Trial 13 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.00022018770025387775, 'learning_rate': 'adaptive', 'eta0': 0.08714171846882023}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:01,245] Trial 14 finished with value: 0.5207100591715975 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 4.17909630361708e-05, 'learning_rate': 'adaptive', 'eta0': 1.3261119506900109e-05}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:03,856] Trial 15 finished with value: 0.6082840236686391 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.0009466504317401401, 'learning_rate': 'adaptive', 'eta0': 0.006781869493491628}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:08,408] Trial 16 finished with value: 0.5644970414201185 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.0009254901771484319, 'learning_rate': 'adaptive', 'eta0': 0.07813984729698077}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:09,761] Trial 17 finished with value: 0.5988165680473372 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 4.461737082127643e-05, 'learning_rate': 'adaptive', 'eta0': 0.005397831626914724}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:10,106] Trial 18 finished with value: 0.5680473372781065 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.0005269081311306156, 'learning_rate': 'invscaling', 'eta0': 0.01847177863689828}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:11,404] Trial 19 finished with value: 0.6319526627218934 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.368260880751569e-05, 'learning_rate': 'adaptive', 'eta0': 0.002339578979223399}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:12,710] Trial 20 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.1656724363060256e-05, 'learning_rate': 'adaptive', 'eta0': 0.0023451391210514974}. Best is trial 10 with value: 0.6390532544378698.\n",
      "[I 2024-02-24 15:25:18,284] Trial 21 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 9.129068390023895e-05, 'learning_rate': 'adaptive', 'eta0': 0.03833904395068281}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:23,936] Trial 22 finished with value: 0.6390532544378699 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 6.094233103368964e-05, 'learning_rate': 'adaptive', 'eta0': 0.03109242239810391}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:29,518] Trial 23 finished with value: 0.6366863905325444 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.0077028865768343e-06, 'learning_rate': 'adaptive', 'eta0': 0.03027255997202756}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:30,875] Trial 24 finished with value: 0.6106508875739645 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 6.298287413893196e-05, 'learning_rate': 'adaptive', 'eta0': 0.010208342086710027}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:36,649] Trial 25 finished with value: 0.6378698224852072 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 9.333890637054054e-05, 'learning_rate': 'adaptive', 'eta0': 0.03271768553364727}. Best is trial 21 with value: 0.6402366863905326.\n",
      "[I 2024-02-24 15:25:40,416] Trial 26 finished with value: 0.6402366863905327 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 2.4517122913654277e-05, 'learning_rate': 'constant', 'eta0': 0.051398377365923134}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:40,980] Trial 27 finished with value: 0.1668639053254438 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.003040172537221823, 'learning_rate': 'constant', 'eta0': 0.011143504220698161}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:42,578] Trial 28 finished with value: 0.6307692307692307 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 3.368863594442148e-05, 'learning_rate': 'constant', 'eta0': 0.044670007113525256}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:42,867] Trial 29 finished with value: 0.5218934911242603 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 6.131674963415057e-06, 'learning_rate': 'constant', 'eta0': 0.0029964481147388596}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:42,985] Trial 30 finished with value: 0.5171597633136095 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'alpha': 0.0004042595929359824, 'learning_rate': 'constant', 'eta0': 0.01331598840483221}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:48,276] Trial 31 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 2.2626975368050612e-05, 'learning_rate': 'adaptive', 'eta0': 0.05078285892294987}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:48,603] Trial 32 finished with value: 0.6047337278106509 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 8.48230027257953e-05, 'learning_rate': 'invscaling', 'eta0': 0.09505167605303566}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:49,992] Trial 33 finished with value: 0.6118343195266271 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 9.162039909506961e-06, 'learning_rate': 'optimal', 'eta0': 0.026192826582771528}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:25:54,082] Trial 34 finished with value: 0.6343195266272189 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 0.0002365930290977371, 'learning_rate': 'constant', 'eta0': 0.05231901036370639}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:00,077] Trial 35 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.143420229730486e-05, 'learning_rate': 'adaptive', 'eta0': 0.020428283199518556}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:04,008] Trial 36 finished with value: 0.6224852071005917 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 2.6099381430023626e-05, 'learning_rate': 'constant', 'eta0': 0.01950741511716031}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:05,758] Trial 37 finished with value: 0.6082840236686391 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.961410920515086e-05, 'learning_rate': 'optimal', 'eta0': 0.0006325547775143147}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:06,717] Trial 38 finished with value: 0.527810650887574 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 6.520491994011774e-06, 'learning_rate': 'invscaling', 'eta0': 0.0047027675379338624}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:11,757] Trial 39 finished with value: 0.6295857988165681 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 0.0008312018683092522, 'learning_rate': 'adaptive', 'eta0': 0.012902186487012749}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:12,397] Trial 40 finished with value: 0.629585798816568 and parameters: {'loss': 'log_loss', 'penalty': 'l2', 'alpha': 0.0001442648624306383, 'learning_rate': 'optimal', 'eta0': 0.023642247680951686}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:17,206] Trial 41 finished with value: 0.6355029585798817 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 6.108223589075113e-05, 'learning_rate': 'adaptive', 'eta0': 0.05905816590017775}. Best is trial 26 with value: 0.6402366863905327.\n",
      "[I 2024-02-24 15:26:22,452] Trial 42 finished with value: 0.6449704142011834 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.729800114837331e-05, 'learning_rate': 'adaptive', 'eta0': 0.033509293980144975}. Best is trial 42 with value: 0.6449704142011834.\n",
      "[I 2024-02-24 15:26:27,804] Trial 43 finished with value: 0.6461538461538462 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.7499949023290976e-05, 'learning_rate': 'adaptive', 'eta0': 0.03319923042456373}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:31,454] Trial 44 finished with value: 0.5609467455621302 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.7621278758057134e-06, 'learning_rate': 'adaptive', 'eta0': 0.00880784824834428}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:37,542] Trial 45 finished with value: 0.6426035502958581 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.7440042741295888e-06, 'learning_rate': 'adaptive', 'eta0': 0.017623850473962473}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:41,304] Trial 46 finished with value: 0.6142011834319526 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 1.4423096221857117e-06, 'learning_rate': 'constant', 'eta0': 0.034002953946884}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:46,941] Trial 47 finished with value: 0.6142011834319527 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.593211858817286e-06, 'learning_rate': 'adaptive', 'eta0': 0.014988404944759112}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:47,259] Trial 48 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.9173757848567267e-06, 'learning_rate': 'invscaling', 'eta0': 7.023619819020812e-05}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:48,591] Trial 49 finished with value: 0.6153846153846153 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.3074713151045884e-05, 'learning_rate': 'adaptive', 'eta0': 0.0010075540222191607}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:26:53,889] Trial 50 finished with value: 0.6390532544378699 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 7.742939554346577e-06, 'learning_rate': 'adaptive', 'eta0': 0.0439092946727205}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:00,130] Trial 51 finished with value: 0.6402366863905324 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.756650371494326e-05, 'learning_rate': 'adaptive', 'eta0': 0.01725164367434085}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:05,012] Trial 52 finished with value: 0.6272189349112426 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.080318847179081e-05, 'learning_rate': 'adaptive', 'eta0': 0.06868712243602494}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:10,698] Trial 53 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.5139324229184716e-06, 'learning_rate': 'adaptive', 'eta0': 0.022755423722794578}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:15,950] Trial 54 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.1349372544940304e-05, 'learning_rate': 'adaptive', 'eta0': 0.0406391196291012}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:17,472] Trial 55 finished with value: 0.6307692307692309 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 0.00010879128576158248, 'learning_rate': 'adaptive', 'eta0': 0.003801484093519012}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:18,999] Trial 56 finished with value: 0.6153846153846154 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 0.00021438572253088046, 'learning_rate': 'optimal', 'eta0': 0.008107910827243379}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:19,253] Trial 57 finished with value: 0.6047337278106509 and parameters: {'loss': 'perceptron', 'penalty': 'l2', 'alpha': 1.0349142361786697e-05, 'learning_rate': 'adaptive', 'eta0': 1.5894750858133533e-05}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:24,160] Trial 58 finished with value: 0.6201183431952663 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.8339055783562057e-05, 'learning_rate': 'adaptive', 'eta0': 0.09418321880152757}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:27,741] Trial 59 finished with value: 0.6366863905325444 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.612901291256103e-05, 'learning_rate': 'constant', 'eta0': 0.06042658452201947}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:29,979] Trial 60 finished with value: 0.3266272189349112 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 4.222195503637995e-06, 'learning_rate': 'adaptive', 'eta0': 0.0002209500955097753}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:35,543] Trial 61 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.6175731446975987e-06, 'learning_rate': 'adaptive', 'eta0': 0.023740258123560534}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:41,233] Trial 62 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.0317760235238744e-06, 'learning_rate': 'adaptive', 'eta0': 0.02136314822286426}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:46,600] Trial 63 finished with value: 0.6331360946745562 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.540962524625386e-06, 'learning_rate': 'adaptive', 'eta0': 0.03690411791753403}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:52,677] Trial 64 finished with value: 0.6260355029585799 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 5.26171863566028e-06, 'learning_rate': 'adaptive', 'eta0': 0.01598755568285184}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:53,544] Trial 65 finished with value: 0.6390532544378699 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 0.014164119490744293, 'learning_rate': 'adaptive', 'eta0': 0.028181530778404625}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:27:56,284] Trial 66 finished with value: 0.18224852071005918 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 0.050569739746178774, 'learning_rate': 'adaptive', 'eta0': 0.007230384154053116}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:00,535] Trial 67 finished with value: 0.6071005917159763 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 1.4364807854786401e-05, 'learning_rate': 'constant', 'eta0': 0.012313921642563681}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:00,804] Trial 68 finished with value: 0.5384615384615385 and parameters: {'loss': 'perceptron', 'penalty': 'l1', 'alpha': 1.7327964392623613e-06, 'learning_rate': 'invscaling', 'eta0': 0.07236881796373945}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:05,953] Trial 69 finished with value: 0.6366863905325444 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 8.122723961897233e-05, 'learning_rate': 'adaptive', 'eta0': 0.04597295428927044}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:11,736] Trial 70 finished with value: 0.6366863905325444 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 2.881835059095232e-05, 'learning_rate': 'adaptive', 'eta0': 0.02733796761417704}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:17,485] Trial 71 finished with value: 0.6390532544378699 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.1348685796616186e-06, 'learning_rate': 'adaptive', 'eta0': 0.02281236536068055}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:23,530] Trial 72 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 7.934722287542843e-06, 'learning_rate': 'adaptive', 'eta0': 0.02027568566039753}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:28,137] Trial 73 finished with value: 0.5633136094674557 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.0181553918743127e-06, 'learning_rate': 'adaptive', 'eta0': 0.010083061150161705}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:33,871] Trial 74 finished with value: 0.6355029585798817 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.2858028497333426e-06, 'learning_rate': 'adaptive', 'eta0': 0.031373631761620856}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:37,567] Trial 75 finished with value: 0.6355029585798817 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.383630875530443e-05, 'learning_rate': 'constant', 'eta0': 0.05719417373653118}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:43,721] Trial 76 finished with value: 0.6331360946745562 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.98513114866299e-06, 'learning_rate': 'adaptive', 'eta0': 0.016537481341585433}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:44,032] Trial 77 finished with value: 0.6248520710059171 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 0.003872411961116476, 'learning_rate': 'optimal', 'eta0': 0.02706755209776727}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:49,390] Trial 78 finished with value: 0.6414201183431952 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.1317787288624247e-05, 'learning_rate': 'adaptive', 'eta0': 0.03792404261143385}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:54,758] Trial 79 finished with value: 0.6142011834319527 and parameters: {'loss': 'squared_hinge', 'penalty': 'l1', 'alpha': 1.111629341915845e-05, 'learning_rate': 'adaptive', 'eta0': 0.042097302347849405}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:28:55,309] Trial 80 finished with value: 0.20946745562130178 and parameters: {'loss': 'log_loss', 'penalty': 'elasticnet', 'alpha': 2.39577120875724e-05, 'learning_rate': 'invscaling', 'eta0': 0.07867622985011734}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:00,875] Trial 81 finished with value: 0.6426035502958579 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 6.0603723744988215e-06, 'learning_rate': 'adaptive', 'eta0': 0.03250384817821399}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:06,445] Trial 82 finished with value: 0.6402366863905324 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 6.133728148303729e-06, 'learning_rate': 'adaptive', 'eta0': 0.03604613772705587}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:11,610] Trial 83 finished with value: 0.6319526627218934 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.6519577301724026e-05, 'learning_rate': 'adaptive', 'eta0': 0.05230894739829345}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:17,301] Trial 84 finished with value: 0.6414201183431952 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 8.152398768953956e-06, 'learning_rate': 'adaptive', 'eta0': 0.03612362602656391}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:20,829] Trial 85 finished with value: 0.621301775147929 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 9.324509642630837e-06, 'learning_rate': 'constant', 'eta0': 0.09801696771656891}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:28,705] Trial 86 finished with value: 0.6295857988165681 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 1.312578783182247e-05, 'learning_rate': 'adaptive', 'eta0': 0.06560105052700987}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:30,371] Trial 87 finished with value: 0.6082840236686391 and parameters: {'loss': 'perceptron', 'penalty': 'elasticnet', 'alpha': 3.596316541720573e-05, 'learning_rate': 'adaptive', 'eta0': 0.0380677037021714}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:32,648] Trial 88 finished with value: 0.6272189349112426 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.4041182862169785e-05, 'learning_rate': 'adaptive', 'eta0': 0.001825738121680838}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:41,807] Trial 89 finished with value: 0.6011834319526628 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 7.268343629978522e-06, 'learning_rate': 'adaptive', 'eta0': 0.013217401165933477}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:43,561] Trial 90 finished with value: 0.5928994082840237 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.877475500937537e-06, 'learning_rate': 'optimal', 'eta0': 0.04712126042135343}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:49,660] Trial 91 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 3.632998727978862e-06, 'learning_rate': 'adaptive', 'eta0': 0.03192419064252167}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:29:55,711] Trial 92 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.064220540824863e-05, 'learning_rate': 'adaptive', 'eta0': 0.018577702171666956}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:01,372] Trial 93 finished with value: 0.6402366863905326 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.0087416452567715e-05, 'learning_rate': 'adaptive', 'eta0': 0.023155230359199735}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:06,537] Trial 94 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 4.90458921367411e-05, 'learning_rate': 'adaptive', 'eta0': 0.05462757278666812}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:11,843] Trial 95 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.480110009535194e-05, 'learning_rate': 'adaptive', 'eta0': 0.03515945949812483}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:13,290] Trial 96 finished with value: 0.5455621301775148 and parameters: {'loss': 'hinge', 'penalty': 'l2', 'alpha': 5.21180559585955e-06, 'learning_rate': 'constant', 'eta0': 0.009875472269278235}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:18,860] Trial 97 finished with value: 0.6378698224852071 and parameters: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 2.1270292862131553e-06, 'learning_rate': 'adaptive', 'eta0': 0.026803505699946262}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:24,199] Trial 98 finished with value: 0.6272189349112426 and parameters: {'loss': 'squared_hinge', 'penalty': 'elasticnet', 'alpha': 6.688330585800623e-05, 'learning_rate': 'adaptive', 'eta0': 0.015511386799331539}. Best is trial 43 with value: 0.6461538461538462.\n",
      "[I 2024-02-24 15:30:29,355] Trial 99 finished with value: 0.6236686390532544 and parameters: {'loss': 'hinge', 'penalty': 'l1', 'alpha': 8.205474790778455e-06, 'learning_rate': 'adaptive', 'eta0': 0.07998705012365065}. Best is trial 43 with value: 0.6461538461538462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'loss': 'hinge', 'penalty': 'elasticnet', 'alpha': 1.7499949023290976e-05, 'learning_rate': 'adaptive', 'eta0': 0.03319923042456373}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    loss = trial.suggest_categorical('loss', ['hinge', 'log_loss', 'squared_hinge', 'perceptron'])\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'l1', 'elasticnet'])\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1e-1, log=True)\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive'])\n",
    "    eta0 = trial.suggest_float('eta0', 1e-5, 1e-1, log=True)  # Only relevant for certain learning rates\n",
    "\n",
    "    # Create and train the SGD Classifier\n",
    "    model = SGDClassifier(loss=loss, penalty=penalty, alpha=alpha, learning_rate=learning_rate, eta0=eta0,\n",
    "                          random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Perform cross-validation and return the mean score\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)  # cv=5 for 5-fold cross-validation\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "# Create a study object and specify the optimization direction\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # Adjust the number of trials as needed\n",
    "\n",
    "# Best hyperparameters\n",
    "print('Best trial:', study.best_trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:30:29.359516Z",
     "start_time": "2024-02-24T13:24:16.607724900Z"
    }
   },
   "id": "4477cdb859019617",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "We notice that the SGD model gave the best accuracy of 0.72, which is the highest among the models we have tried so far.\n",
    "\n",
    "So, we will get the best hyperparameters for the model and use them to train the model again, for later use."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68f9ee6d9062ffe6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SGDClassifier(alpha=1.7499949023290976e-05, eta0=0.03319923042456373,\n              learning_rate='adaptive', penalty='elasticnet', random_state=42)",
      "text/html": "<style>#sk-container-id-12 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-12 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-12 pre {\n  padding: 0;\n}\n\n#sk-container-id-12 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-12 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-12 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-12 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-12 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-12 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-12 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-12 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-12 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-12 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-12 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-12 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-12 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-12 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-12 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-12 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n#sk-container-id-12 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-12 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-12 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-12 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-12 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-12 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-12 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-12 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-12 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-12 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=1.7499949023290976e-05, eta0=0.03319923042456373,\n              learning_rate=&#x27;adaptive&#x27;, penalty=&#x27;elasticnet&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(alpha=1.7499949023290976e-05, eta0=0.03319923042456373,\n              learning_rate=&#x27;adaptive&#x27;, penalty=&#x27;elasticnet&#x27;, random_state=42)</pre></div> </div></div></div></div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "sgd_model = SGDClassifier(**best_params, random_state=42)\n",
    "sgd_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:31:30.169150200Z",
     "start_time": "2024-02-24T13:31:28.113148500Z"
    }
   },
   "id": "114f2bb29b45ae2d",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class Naive Bayes\n",
    "\n",
    "It is known that Naive Bayes is a simple and effective algorithm for classification for NLP tasks. \n",
    "Let's now train a multi-class Naive Bayes model on the embeddings and the class, to see how it performs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fab4ff2e2e09606"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        43\n",
      "           1       0.64      0.68      0.66        31\n",
      "           2       0.71      0.71      0.71        34\n",
      "           3       0.65      0.77      0.70        26\n",
      "           4       0.48      0.48      0.48        27\n",
      "           5       0.67      0.65      0.66        51\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.64      0.65      0.65       212\n",
      "weighted avg       0.65      0.65      0.65       212\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:32:25.746345800Z",
     "start_time": "2024-02-24T13:32:25.733285500Z"
    }
   },
   "id": "fa13a14098b3636c",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the Naive Bayes model has an accuracy of 0.65, which does not differ much from the logistic regression model.\n",
    "So there is no need to use `optuna` to find the best hyperparameters for the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e859bc93b6dcd506"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class Random Forest\n",
    "\n",
    "Let's now train a multi-class Random Forest model on the embeddings and the class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c9e62a3e6912a48"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61        43\n",
      "           1       0.86      0.61      0.72        31\n",
      "           2       0.90      0.56      0.69        34\n",
      "           3       0.71      0.65      0.68        26\n",
      "           4       0.55      0.67      0.60        27\n",
      "           5       0.59      0.73      0.65        51\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.70      0.64      0.66       212\n",
      "weighted avg       0.68      0.65      0.66       212\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=15,\n",
    "                               max_depth=100, min_samples_split=2, min_samples_leaf=1, max_features='sqrt')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:32:40.117971900Z",
     "start_time": "2024-02-24T13:32:36.844346100Z"
    }
   },
   "id": "a8fc25a6a41a309b",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-class CatBoost\n",
    "\n",
    "Having tried the above models, let us now proceed to more advanced models such as CatBoost, \n",
    "which is a gradient boosting library that is known to perform well on tabular data, to see how it performs \n",
    "and if it can outperform the other models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28cda8d8bf460600"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.134538\n",
      "0:\tlearn: 1.7254025\ttotal: 26.8ms\tremaining: 10.7s\n",
      "1:\tlearn: 1.6695749\ttotal: 51.8ms\tremaining: 10.3s\n",
      "2:\tlearn: 1.6175593\ttotal: 76ms\tremaining: 10.1s\n",
      "3:\tlearn: 1.5654316\ttotal: 98.7ms\tremaining: 9.77s\n",
      "4:\tlearn: 1.5203243\ttotal: 123ms\tremaining: 9.69s\n",
      "5:\tlearn: 1.4711252\ttotal: 147ms\tremaining: 9.65s\n",
      "6:\tlearn: 1.4305325\ttotal: 172ms\tremaining: 9.68s\n",
      "7:\tlearn: 1.3919494\ttotal: 197ms\tremaining: 9.66s\n",
      "8:\tlearn: 1.3552363\ttotal: 221ms\tremaining: 9.62s\n",
      "9:\tlearn: 1.3184468\ttotal: 245ms\tremaining: 9.55s\n",
      "10:\tlearn: 1.2855703\ttotal: 267ms\tremaining: 9.43s\n",
      "11:\tlearn: 1.2561113\ttotal: 289ms\tremaining: 9.34s\n",
      "12:\tlearn: 1.2270124\ttotal: 310ms\tremaining: 9.22s\n",
      "13:\tlearn: 1.1986041\ttotal: 331ms\tremaining: 9.13s\n",
      "14:\tlearn: 1.1696553\ttotal: 352ms\tremaining: 9.04s\n",
      "15:\tlearn: 1.1413859\ttotal: 374ms\tremaining: 8.98s\n",
      "16:\tlearn: 1.1152895\ttotal: 395ms\tremaining: 8.91s\n",
      "17:\tlearn: 1.0871917\ttotal: 417ms\tremaining: 8.86s\n",
      "18:\tlearn: 1.0641851\ttotal: 438ms\tremaining: 8.79s\n",
      "19:\tlearn: 1.0398989\ttotal: 460ms\tremaining: 8.74s\n",
      "20:\tlearn: 1.0156924\ttotal: 482ms\tremaining: 8.7s\n",
      "21:\tlearn: 0.9948616\ttotal: 503ms\tremaining: 8.65s\n",
      "22:\tlearn: 0.9726854\ttotal: 525ms\tremaining: 8.6s\n",
      "23:\tlearn: 0.9536191\ttotal: 545ms\tremaining: 8.54s\n",
      "24:\tlearn: 0.9316483\ttotal: 566ms\tremaining: 8.49s\n",
      "25:\tlearn: 0.9129895\ttotal: 587ms\tremaining: 8.45s\n",
      "26:\tlearn: 0.8971149\ttotal: 609ms\tremaining: 8.41s\n",
      "27:\tlearn: 0.8806011\ttotal: 629ms\tremaining: 8.36s\n",
      "28:\tlearn: 0.8645505\ttotal: 650ms\tremaining: 8.31s\n",
      "29:\tlearn: 0.8487692\ttotal: 671ms\tremaining: 8.27s\n",
      "30:\tlearn: 0.8300379\ttotal: 692ms\tremaining: 8.24s\n",
      "31:\tlearn: 0.8133141\ttotal: 714ms\tremaining: 8.21s\n",
      "32:\tlearn: 0.7992926\ttotal: 734ms\tremaining: 8.16s\n",
      "33:\tlearn: 0.7830541\ttotal: 755ms\tremaining: 8.13s\n",
      "34:\tlearn: 0.7664586\ttotal: 776ms\tremaining: 8.09s\n",
      "35:\tlearn: 0.7521716\ttotal: 796ms\tremaining: 8.05s\n",
      "36:\tlearn: 0.7375230\ttotal: 816ms\tremaining: 8.01s\n",
      "37:\tlearn: 0.7250831\ttotal: 836ms\tremaining: 7.96s\n",
      "38:\tlearn: 0.7111226\ttotal: 855ms\tremaining: 7.91s\n",
      "39:\tlearn: 0.6979888\ttotal: 876ms\tremaining: 7.88s\n",
      "40:\tlearn: 0.6836488\ttotal: 896ms\tremaining: 7.84s\n",
      "41:\tlearn: 0.6741129\ttotal: 917ms\tremaining: 7.81s\n",
      "42:\tlearn: 0.6623060\ttotal: 937ms\tremaining: 7.78s\n",
      "43:\tlearn: 0.6509261\ttotal: 956ms\tremaining: 7.74s\n",
      "44:\tlearn: 0.6388545\ttotal: 977ms\tremaining: 7.71s\n",
      "45:\tlearn: 0.6299115\ttotal: 998ms\tremaining: 7.68s\n",
      "46:\tlearn: 0.6196012\ttotal: 1.02s\tremaining: 7.64s\n",
      "47:\tlearn: 0.6076836\ttotal: 1.04s\tremaining: 7.62s\n",
      "48:\tlearn: 0.5962132\ttotal: 1.06s\tremaining: 7.58s\n",
      "49:\tlearn: 0.5865849\ttotal: 1.08s\tremaining: 7.56s\n",
      "50:\tlearn: 0.5775476\ttotal: 1.1s\tremaining: 7.52s\n",
      "51:\tlearn: 0.5676391\ttotal: 1.12s\tremaining: 7.49s\n",
      "52:\tlearn: 0.5593348\ttotal: 1.14s\tremaining: 7.46s\n",
      "53:\tlearn: 0.5495879\ttotal: 1.16s\tremaining: 7.44s\n",
      "54:\tlearn: 0.5405557\ttotal: 1.18s\tremaining: 7.4s\n",
      "55:\tlearn: 0.5314888\ttotal: 1.2s\tremaining: 7.37s\n",
      "56:\tlearn: 0.5242776\ttotal: 1.22s\tremaining: 7.34s\n",
      "57:\tlearn: 0.5157721\ttotal: 1.24s\tremaining: 7.32s\n",
      "58:\tlearn: 0.5075079\ttotal: 1.26s\tremaining: 7.3s\n",
      "59:\tlearn: 0.4993940\ttotal: 1.28s\tremaining: 7.27s\n",
      "60:\tlearn: 0.4916620\ttotal: 1.3s\tremaining: 7.25s\n",
      "61:\tlearn: 0.4846284\ttotal: 1.32s\tremaining: 7.22s\n",
      "62:\tlearn: 0.4762148\ttotal: 1.34s\tremaining: 7.2s\n",
      "63:\tlearn: 0.4691315\ttotal: 1.37s\tremaining: 7.17s\n",
      "64:\tlearn: 0.4607116\ttotal: 1.39s\tremaining: 7.15s\n",
      "65:\tlearn: 0.4554044\ttotal: 1.41s\tremaining: 7.12s\n",
      "66:\tlearn: 0.4496414\ttotal: 1.43s\tremaining: 7.08s\n",
      "67:\tlearn: 0.4431803\ttotal: 1.44s\tremaining: 7.05s\n",
      "68:\tlearn: 0.4369143\ttotal: 1.47s\tremaining: 7.03s\n",
      "69:\tlearn: 0.4324129\ttotal: 1.48s\tremaining: 6.99s\n",
      "70:\tlearn: 0.4276288\ttotal: 1.5s\tremaining: 6.95s\n",
      "71:\tlearn: 0.4227143\ttotal: 1.52s\tremaining: 6.92s\n",
      "72:\tlearn: 0.4170892\ttotal: 1.54s\tremaining: 6.89s\n",
      "73:\tlearn: 0.4118747\ttotal: 1.56s\tremaining: 6.86s\n",
      "74:\tlearn: 0.4058334\ttotal: 1.58s\tremaining: 6.83s\n",
      "75:\tlearn: 0.4014829\ttotal: 1.6s\tremaining: 6.8s\n",
      "76:\tlearn: 0.3961519\ttotal: 1.62s\tremaining: 6.78s\n",
      "77:\tlearn: 0.3919467\ttotal: 1.63s\tremaining: 6.75s\n",
      "78:\tlearn: 0.3861807\ttotal: 1.65s\tremaining: 6.72s\n",
      "79:\tlearn: 0.3808253\ttotal: 1.68s\tremaining: 6.7s\n",
      "80:\tlearn: 0.3744535\ttotal: 1.69s\tremaining: 6.67s\n",
      "81:\tlearn: 0.3696623\ttotal: 1.71s\tremaining: 6.64s\n",
      "82:\tlearn: 0.3644553\ttotal: 1.73s\tremaining: 6.62s\n",
      "83:\tlearn: 0.3601316\ttotal: 1.75s\tremaining: 6.59s\n",
      "84:\tlearn: 0.3565833\ttotal: 1.77s\tremaining: 6.56s\n",
      "85:\tlearn: 0.3524690\ttotal: 1.79s\tremaining: 6.54s\n",
      "86:\tlearn: 0.3485837\ttotal: 1.81s\tremaining: 6.51s\n",
      "87:\tlearn: 0.3442450\ttotal: 1.83s\tremaining: 6.48s\n",
      "88:\tlearn: 0.3396056\ttotal: 1.85s\tremaining: 6.46s\n",
      "89:\tlearn: 0.3355214\ttotal: 1.87s\tremaining: 6.43s\n",
      "90:\tlearn: 0.3313087\ttotal: 1.89s\tremaining: 6.41s\n",
      "91:\tlearn: 0.3266425\ttotal: 1.91s\tremaining: 6.38s\n",
      "92:\tlearn: 0.3243103\ttotal: 1.92s\tremaining: 6.35s\n",
      "93:\tlearn: 0.3205719\ttotal: 1.94s\tremaining: 6.32s\n",
      "94:\tlearn: 0.3165374\ttotal: 1.96s\tremaining: 6.3s\n",
      "95:\tlearn: 0.3123869\ttotal: 1.98s\tremaining: 6.28s\n",
      "96:\tlearn: 0.3087995\ttotal: 2s\tremaining: 6.26s\n",
      "97:\tlearn: 0.3049524\ttotal: 2.02s\tremaining: 6.24s\n",
      "98:\tlearn: 0.3012952\ttotal: 2.04s\tremaining: 6.21s\n",
      "99:\tlearn: 0.2981261\ttotal: 2.06s\tremaining: 6.18s\n",
      "100:\tlearn: 0.2947523\ttotal: 2.08s\tremaining: 6.16s\n",
      "101:\tlearn: 0.2906915\ttotal: 2.1s\tremaining: 6.14s\n",
      "102:\tlearn: 0.2874717\ttotal: 2.12s\tremaining: 6.11s\n",
      "103:\tlearn: 0.2841607\ttotal: 2.14s\tremaining: 6.09s\n",
      "104:\tlearn: 0.2805698\ttotal: 2.16s\tremaining: 6.07s\n",
      "105:\tlearn: 0.2774673\ttotal: 2.18s\tremaining: 6.04s\n",
      "106:\tlearn: 0.2742335\ttotal: 2.2s\tremaining: 6.01s\n",
      "107:\tlearn: 0.2711559\ttotal: 2.22s\tremaining: 5.99s\n",
      "108:\tlearn: 0.2687158\ttotal: 2.23s\tremaining: 5.96s\n",
      "109:\tlearn: 0.2649575\ttotal: 2.25s\tremaining: 5.94s\n",
      "110:\tlearn: 0.2617146\ttotal: 2.27s\tremaining: 5.92s\n",
      "111:\tlearn: 0.2589010\ttotal: 2.29s\tremaining: 5.89s\n",
      "112:\tlearn: 0.2565163\ttotal: 2.31s\tremaining: 5.86s\n",
      "113:\tlearn: 0.2540353\ttotal: 2.33s\tremaining: 5.83s\n",
      "114:\tlearn: 0.2518414\ttotal: 2.34s\tremaining: 5.81s\n",
      "115:\tlearn: 0.2491933\ttotal: 2.36s\tremaining: 5.79s\n",
      "116:\tlearn: 0.2466153\ttotal: 2.38s\tremaining: 5.76s\n",
      "117:\tlearn: 0.2442349\ttotal: 2.4s\tremaining: 5.74s\n",
      "118:\tlearn: 0.2421800\ttotal: 2.42s\tremaining: 5.71s\n",
      "119:\tlearn: 0.2403954\ttotal: 2.44s\tremaining: 5.69s\n",
      "120:\tlearn: 0.2372647\ttotal: 2.46s\tremaining: 5.67s\n",
      "121:\tlearn: 0.2345694\ttotal: 2.48s\tremaining: 5.64s\n",
      "122:\tlearn: 0.2325911\ttotal: 2.5s\tremaining: 5.62s\n",
      "123:\tlearn: 0.2298886\ttotal: 2.52s\tremaining: 5.6s\n",
      "124:\tlearn: 0.2284529\ttotal: 2.54s\tremaining: 5.58s\n",
      "125:\tlearn: 0.2263268\ttotal: 2.55s\tremaining: 5.55s\n",
      "126:\tlearn: 0.2245414\ttotal: 2.57s\tremaining: 5.53s\n",
      "127:\tlearn: 0.2230170\ttotal: 2.59s\tremaining: 5.5s\n",
      "128:\tlearn: 0.2208970\ttotal: 2.61s\tremaining: 5.48s\n",
      "129:\tlearn: 0.2186598\ttotal: 2.63s\tremaining: 5.45s\n",
      "130:\tlearn: 0.2173428\ttotal: 2.64s\tremaining: 5.43s\n",
      "131:\tlearn: 0.2150005\ttotal: 2.66s\tremaining: 5.41s\n",
      "132:\tlearn: 0.2133167\ttotal: 2.68s\tremaining: 5.38s\n",
      "133:\tlearn: 0.2110383\ttotal: 2.7s\tremaining: 5.36s\n",
      "134:\tlearn: 0.2099272\ttotal: 2.71s\tremaining: 5.33s\n",
      "135:\tlearn: 0.2082592\ttotal: 2.73s\tremaining: 5.31s\n",
      "136:\tlearn: 0.2066058\ttotal: 2.75s\tremaining: 5.28s\n",
      "137:\tlearn: 0.2050414\ttotal: 2.77s\tremaining: 5.26s\n",
      "138:\tlearn: 0.2030872\ttotal: 2.79s\tremaining: 5.23s\n",
      "139:\tlearn: 0.2020165\ttotal: 2.8s\tremaining: 5.21s\n",
      "140:\tlearn: 0.2001405\ttotal: 2.82s\tremaining: 5.18s\n",
      "141:\tlearn: 0.1982069\ttotal: 2.84s\tremaining: 5.16s\n",
      "142:\tlearn: 0.1967525\ttotal: 2.86s\tremaining: 5.14s\n",
      "143:\tlearn: 0.1953756\ttotal: 2.88s\tremaining: 5.11s\n",
      "144:\tlearn: 0.1940662\ttotal: 2.89s\tremaining: 5.09s\n",
      "145:\tlearn: 0.1924060\ttotal: 2.91s\tremaining: 5.07s\n",
      "146:\tlearn: 0.1908448\ttotal: 2.93s\tremaining: 5.04s\n",
      "147:\tlearn: 0.1891449\ttotal: 2.95s\tremaining: 5.02s\n",
      "148:\tlearn: 0.1876357\ttotal: 2.97s\tremaining: 5s\n",
      "149:\tlearn: 0.1860379\ttotal: 2.99s\tremaining: 4.98s\n",
      "150:\tlearn: 0.1841348\ttotal: 3.01s\tremaining: 4.96s\n",
      "151:\tlearn: 0.1826380\ttotal: 3.02s\tremaining: 4.93s\n",
      "152:\tlearn: 0.1809202\ttotal: 3.04s\tremaining: 4.91s\n",
      "153:\tlearn: 0.1798490\ttotal: 3.06s\tremaining: 4.89s\n",
      "154:\tlearn: 0.1780784\ttotal: 3.08s\tremaining: 4.87s\n",
      "155:\tlearn: 0.1765820\ttotal: 3.1s\tremaining: 4.85s\n",
      "156:\tlearn: 0.1756014\ttotal: 3.12s\tremaining: 4.83s\n",
      "157:\tlearn: 0.1740530\ttotal: 3.13s\tremaining: 4.8s\n",
      "158:\tlearn: 0.1729071\ttotal: 3.15s\tremaining: 4.78s\n",
      "159:\tlearn: 0.1712562\ttotal: 3.17s\tremaining: 4.76s\n",
      "160:\tlearn: 0.1696873\ttotal: 3.19s\tremaining: 4.73s\n",
      "161:\tlearn: 0.1682620\ttotal: 3.21s\tremaining: 4.71s\n",
      "162:\tlearn: 0.1671060\ttotal: 3.22s\tremaining: 4.69s\n",
      "163:\tlearn: 0.1659965\ttotal: 3.24s\tremaining: 4.67s\n",
      "164:\tlearn: 0.1643670\ttotal: 3.26s\tremaining: 4.65s\n",
      "165:\tlearn: 0.1626753\ttotal: 3.28s\tremaining: 4.63s\n",
      "166:\tlearn: 0.1615152\ttotal: 3.31s\tremaining: 4.61s\n",
      "167:\tlearn: 0.1602209\ttotal: 3.32s\tremaining: 4.59s\n",
      "168:\tlearn: 0.1590537\ttotal: 3.34s\tremaining: 4.57s\n",
      "169:\tlearn: 0.1575855\ttotal: 3.36s\tremaining: 4.54s\n",
      "170:\tlearn: 0.1561717\ttotal: 3.38s\tremaining: 4.52s\n",
      "171:\tlearn: 0.1549893\ttotal: 3.4s\tremaining: 4.5s\n",
      "172:\tlearn: 0.1536382\ttotal: 3.41s\tremaining: 4.48s\n",
      "173:\tlearn: 0.1525569\ttotal: 3.43s\tremaining: 4.46s\n",
      "174:\tlearn: 0.1512807\ttotal: 3.45s\tremaining: 4.43s\n",
      "175:\tlearn: 0.1501450\ttotal: 3.47s\tremaining: 4.41s\n",
      "176:\tlearn: 0.1486485\ttotal: 3.49s\tremaining: 4.39s\n",
      "177:\tlearn: 0.1478137\ttotal: 3.5s\tremaining: 4.37s\n",
      "178:\tlearn: 0.1468782\ttotal: 3.52s\tremaining: 4.35s\n",
      "179:\tlearn: 0.1456580\ttotal: 3.54s\tremaining: 4.33s\n",
      "180:\tlearn: 0.1447441\ttotal: 3.56s\tremaining: 4.31s\n",
      "181:\tlearn: 0.1437960\ttotal: 3.58s\tremaining: 4.29s\n",
      "182:\tlearn: 0.1428354\ttotal: 3.6s\tremaining: 4.26s\n",
      "183:\tlearn: 0.1417032\ttotal: 3.61s\tremaining: 4.24s\n",
      "184:\tlearn: 0.1403624\ttotal: 3.63s\tremaining: 4.22s\n",
      "185:\tlearn: 0.1392091\ttotal: 3.65s\tremaining: 4.2s\n",
      "186:\tlearn: 0.1380842\ttotal: 3.67s\tremaining: 4.18s\n",
      "187:\tlearn: 0.1369947\ttotal: 3.7s\tremaining: 4.18s\n",
      "188:\tlearn: 0.1361261\ttotal: 3.72s\tremaining: 4.16s\n",
      "189:\tlearn: 0.1348728\ttotal: 3.74s\tremaining: 4.13s\n",
      "190:\tlearn: 0.1336363\ttotal: 3.76s\tremaining: 4.11s\n",
      "191:\tlearn: 0.1327732\ttotal: 3.78s\tremaining: 4.09s\n",
      "192:\tlearn: 0.1319016\ttotal: 3.79s\tremaining: 4.07s\n",
      "193:\tlearn: 0.1309549\ttotal: 3.81s\tremaining: 4.05s\n",
      "194:\tlearn: 0.1303814\ttotal: 3.83s\tremaining: 4.02s\n",
      "195:\tlearn: 0.1295490\ttotal: 3.85s\tremaining: 4s\n",
      "196:\tlearn: 0.1285690\ttotal: 3.86s\tremaining: 3.98s\n",
      "197:\tlearn: 0.1278798\ttotal: 3.88s\tremaining: 3.96s\n",
      "198:\tlearn: 0.1273912\ttotal: 3.9s\tremaining: 3.94s\n",
      "199:\tlearn: 0.1261979\ttotal: 3.92s\tremaining: 3.92s\n",
      "200:\tlearn: 0.1252520\ttotal: 3.94s\tremaining: 3.9s\n",
      "201:\tlearn: 0.1245635\ttotal: 3.95s\tremaining: 3.87s\n",
      "202:\tlearn: 0.1236760\ttotal: 3.97s\tremaining: 3.85s\n",
      "203:\tlearn: 0.1227569\ttotal: 3.99s\tremaining: 3.83s\n",
      "204:\tlearn: 0.1219795\ttotal: 4.01s\tremaining: 3.81s\n",
      "205:\tlearn: 0.1209417\ttotal: 4.03s\tremaining: 3.79s\n",
      "206:\tlearn: 0.1200357\ttotal: 4.05s\tremaining: 3.77s\n",
      "207:\tlearn: 0.1193566\ttotal: 4.07s\tremaining: 3.75s\n",
      "208:\tlearn: 0.1189938\ttotal: 4.08s\tremaining: 3.73s\n",
      "209:\tlearn: 0.1181642\ttotal: 4.1s\tremaining: 3.71s\n",
      "210:\tlearn: 0.1172938\ttotal: 4.12s\tremaining: 3.69s\n",
      "211:\tlearn: 0.1166091\ttotal: 4.14s\tremaining: 3.67s\n",
      "212:\tlearn: 0.1159043\ttotal: 4.16s\tremaining: 3.65s\n",
      "213:\tlearn: 0.1154858\ttotal: 4.17s\tremaining: 3.63s\n",
      "214:\tlearn: 0.1146418\ttotal: 4.19s\tremaining: 3.61s\n",
      "215:\tlearn: 0.1137043\ttotal: 4.21s\tremaining: 3.59s\n",
      "216:\tlearn: 0.1130603\ttotal: 4.23s\tremaining: 3.57s\n",
      "217:\tlearn: 0.1122573\ttotal: 4.25s\tremaining: 3.55s\n",
      "218:\tlearn: 0.1113487\ttotal: 4.27s\tremaining: 3.53s\n",
      "219:\tlearn: 0.1108876\ttotal: 4.29s\tremaining: 3.51s\n",
      "220:\tlearn: 0.1101933\ttotal: 4.3s\tremaining: 3.49s\n",
      "221:\tlearn: 0.1095278\ttotal: 4.32s\tremaining: 3.46s\n",
      "222:\tlearn: 0.1088585\ttotal: 4.34s\tremaining: 3.44s\n",
      "223:\tlearn: 0.1083156\ttotal: 4.36s\tremaining: 3.42s\n",
      "224:\tlearn: 0.1075402\ttotal: 4.38s\tremaining: 3.4s\n",
      "225:\tlearn: 0.1069617\ttotal: 4.39s\tremaining: 3.38s\n",
      "226:\tlearn: 0.1062581\ttotal: 4.41s\tremaining: 3.36s\n",
      "227:\tlearn: 0.1055452\ttotal: 4.43s\tremaining: 3.34s\n",
      "228:\tlearn: 0.1050078\ttotal: 4.45s\tremaining: 3.33s\n",
      "229:\tlearn: 0.1045148\ttotal: 4.47s\tremaining: 3.31s\n",
      "230:\tlearn: 0.1038775\ttotal: 4.49s\tremaining: 3.29s\n",
      "231:\tlearn: 0.1031312\ttotal: 4.51s\tremaining: 3.27s\n",
      "232:\tlearn: 0.1024587\ttotal: 4.53s\tremaining: 3.25s\n",
      "233:\tlearn: 0.1019067\ttotal: 4.55s\tremaining: 3.23s\n",
      "234:\tlearn: 0.1014303\ttotal: 4.57s\tremaining: 3.21s\n",
      "235:\tlearn: 0.1011078\ttotal: 4.59s\tremaining: 3.19s\n",
      "236:\tlearn: 0.1005027\ttotal: 4.61s\tremaining: 3.17s\n",
      "237:\tlearn: 0.0999983\ttotal: 4.62s\tremaining: 3.15s\n",
      "238:\tlearn: 0.0992581\ttotal: 4.65s\tremaining: 3.13s\n",
      "239:\tlearn: 0.0986960\ttotal: 4.66s\tremaining: 3.11s\n",
      "240:\tlearn: 0.0980405\ttotal: 4.68s\tremaining: 3.09s\n",
      "241:\tlearn: 0.0973821\ttotal: 4.7s\tremaining: 3.07s\n",
      "242:\tlearn: 0.0967629\ttotal: 4.72s\tremaining: 3.05s\n",
      "243:\tlearn: 0.0960422\ttotal: 4.74s\tremaining: 3.03s\n",
      "244:\tlearn: 0.0954735\ttotal: 4.76s\tremaining: 3.01s\n",
      "245:\tlearn: 0.0949145\ttotal: 4.78s\tremaining: 2.99s\n",
      "246:\tlearn: 0.0942966\ttotal: 4.79s\tremaining: 2.97s\n",
      "247:\tlearn: 0.0935964\ttotal: 4.81s\tremaining: 2.95s\n",
      "248:\tlearn: 0.0931840\ttotal: 4.84s\tremaining: 2.93s\n",
      "249:\tlearn: 0.0925083\ttotal: 4.86s\tremaining: 2.91s\n",
      "250:\tlearn: 0.0919600\ttotal: 4.87s\tremaining: 2.89s\n",
      "251:\tlearn: 0.0914836\ttotal: 4.89s\tremaining: 2.87s\n",
      "252:\tlearn: 0.0908727\ttotal: 4.91s\tremaining: 2.85s\n",
      "253:\tlearn: 0.0901999\ttotal: 4.93s\tremaining: 2.83s\n",
      "254:\tlearn: 0.0896865\ttotal: 4.95s\tremaining: 2.81s\n",
      "255:\tlearn: 0.0891651\ttotal: 4.97s\tremaining: 2.79s\n",
      "256:\tlearn: 0.0887197\ttotal: 4.99s\tremaining: 2.77s\n",
      "257:\tlearn: 0.0881337\ttotal: 5.01s\tremaining: 2.75s\n",
      "258:\tlearn: 0.0875722\ttotal: 5.03s\tremaining: 2.74s\n",
      "259:\tlearn: 0.0871017\ttotal: 5.04s\tremaining: 2.71s\n",
      "260:\tlearn: 0.0866601\ttotal: 5.06s\tremaining: 2.69s\n",
      "261:\tlearn: 0.0860262\ttotal: 5.08s\tremaining: 2.68s\n",
      "262:\tlearn: 0.0855928\ttotal: 5.1s\tremaining: 2.66s\n",
      "263:\tlearn: 0.0850932\ttotal: 5.12s\tremaining: 2.64s\n",
      "264:\tlearn: 0.0846493\ttotal: 5.14s\tremaining: 2.62s\n",
      "265:\tlearn: 0.0842235\ttotal: 5.15s\tremaining: 2.6s\n",
      "266:\tlearn: 0.0836395\ttotal: 5.17s\tremaining: 2.58s\n",
      "267:\tlearn: 0.0831542\ttotal: 5.19s\tremaining: 2.56s\n",
      "268:\tlearn: 0.0827229\ttotal: 5.21s\tremaining: 2.54s\n",
      "269:\tlearn: 0.0823706\ttotal: 5.23s\tremaining: 2.52s\n",
      "270:\tlearn: 0.0819368\ttotal: 5.25s\tremaining: 2.5s\n",
      "271:\tlearn: 0.0814313\ttotal: 5.27s\tremaining: 2.48s\n",
      "272:\tlearn: 0.0809061\ttotal: 5.29s\tremaining: 2.46s\n",
      "273:\tlearn: 0.0803651\ttotal: 5.31s\tremaining: 2.44s\n",
      "274:\tlearn: 0.0799672\ttotal: 5.32s\tremaining: 2.42s\n",
      "275:\tlearn: 0.0795507\ttotal: 5.34s\tremaining: 2.4s\n",
      "276:\tlearn: 0.0791653\ttotal: 5.36s\tremaining: 2.38s\n",
      "277:\tlearn: 0.0786663\ttotal: 5.38s\tremaining: 2.36s\n",
      "278:\tlearn: 0.0782065\ttotal: 5.39s\tremaining: 2.34s\n",
      "279:\tlearn: 0.0778696\ttotal: 5.41s\tremaining: 2.32s\n",
      "280:\tlearn: 0.0774773\ttotal: 5.43s\tremaining: 2.3s\n",
      "281:\tlearn: 0.0771669\ttotal: 5.45s\tremaining: 2.28s\n",
      "282:\tlearn: 0.0767590\ttotal: 5.47s\tremaining: 2.26s\n",
      "283:\tlearn: 0.0763746\ttotal: 5.49s\tremaining: 2.24s\n",
      "284:\tlearn: 0.0760756\ttotal: 5.5s\tremaining: 2.22s\n",
      "285:\tlearn: 0.0756730\ttotal: 5.52s\tremaining: 2.2s\n",
      "286:\tlearn: 0.0752272\ttotal: 5.54s\tremaining: 2.18s\n",
      "287:\tlearn: 0.0748248\ttotal: 5.56s\tremaining: 2.16s\n",
      "288:\tlearn: 0.0743724\ttotal: 5.58s\tremaining: 2.14s\n",
      "289:\tlearn: 0.0739885\ttotal: 5.59s\tremaining: 2.12s\n",
      "290:\tlearn: 0.0736957\ttotal: 5.61s\tremaining: 2.1s\n",
      "291:\tlearn: 0.0733962\ttotal: 5.63s\tremaining: 2.08s\n",
      "292:\tlearn: 0.0730896\ttotal: 5.65s\tremaining: 2.06s\n",
      "293:\tlearn: 0.0728686\ttotal: 5.67s\tremaining: 2.04s\n",
      "294:\tlearn: 0.0724281\ttotal: 5.69s\tremaining: 2.02s\n",
      "295:\tlearn: 0.0720621\ttotal: 5.71s\tremaining: 2.01s\n",
      "296:\tlearn: 0.0717157\ttotal: 5.73s\tremaining: 1.99s\n",
      "297:\tlearn: 0.0712965\ttotal: 5.75s\tremaining: 1.97s\n",
      "298:\tlearn: 0.0709153\ttotal: 5.76s\tremaining: 1.95s\n",
      "299:\tlearn: 0.0705704\ttotal: 5.78s\tremaining: 1.93s\n",
      "300:\tlearn: 0.0702679\ttotal: 5.8s\tremaining: 1.91s\n",
      "301:\tlearn: 0.0699442\ttotal: 5.82s\tremaining: 1.89s\n",
      "302:\tlearn: 0.0695005\ttotal: 5.84s\tremaining: 1.87s\n",
      "303:\tlearn: 0.0691620\ttotal: 5.85s\tremaining: 1.85s\n",
      "304:\tlearn: 0.0689299\ttotal: 5.87s\tremaining: 1.83s\n",
      "305:\tlearn: 0.0686079\ttotal: 5.89s\tremaining: 1.81s\n",
      "306:\tlearn: 0.0682780\ttotal: 5.91s\tremaining: 1.79s\n",
      "307:\tlearn: 0.0678827\ttotal: 5.93s\tremaining: 1.77s\n",
      "308:\tlearn: 0.0676655\ttotal: 5.94s\tremaining: 1.75s\n",
      "309:\tlearn: 0.0672929\ttotal: 5.96s\tremaining: 1.73s\n",
      "310:\tlearn: 0.0669605\ttotal: 5.98s\tremaining: 1.71s\n",
      "311:\tlearn: 0.0665860\ttotal: 6s\tremaining: 1.69s\n",
      "312:\tlearn: 0.0662704\ttotal: 6.02s\tremaining: 1.67s\n",
      "313:\tlearn: 0.0660391\ttotal: 6.04s\tremaining: 1.65s\n",
      "314:\tlearn: 0.0657424\ttotal: 6.06s\tremaining: 1.63s\n",
      "315:\tlearn: 0.0654357\ttotal: 6.08s\tremaining: 1.61s\n",
      "316:\tlearn: 0.0650592\ttotal: 6.09s\tremaining: 1.59s\n",
      "317:\tlearn: 0.0646848\ttotal: 6.11s\tremaining: 1.58s\n",
      "318:\tlearn: 0.0644017\ttotal: 6.13s\tremaining: 1.56s\n",
      "319:\tlearn: 0.0640659\ttotal: 6.15s\tremaining: 1.54s\n",
      "320:\tlearn: 0.0638688\ttotal: 6.17s\tremaining: 1.52s\n",
      "321:\tlearn: 0.0635795\ttotal: 6.18s\tremaining: 1.5s\n",
      "322:\tlearn: 0.0632025\ttotal: 6.2s\tremaining: 1.48s\n",
      "323:\tlearn: 0.0628822\ttotal: 6.22s\tremaining: 1.46s\n",
      "324:\tlearn: 0.0627068\ttotal: 6.24s\tremaining: 1.44s\n",
      "325:\tlearn: 0.0624865\ttotal: 6.25s\tremaining: 1.42s\n",
      "326:\tlearn: 0.0621532\ttotal: 6.28s\tremaining: 1.4s\n",
      "327:\tlearn: 0.0618522\ttotal: 6.29s\tremaining: 1.38s\n",
      "328:\tlearn: 0.0616013\ttotal: 6.31s\tremaining: 1.36s\n",
      "329:\tlearn: 0.0613426\ttotal: 6.33s\tremaining: 1.34s\n",
      "330:\tlearn: 0.0609836\ttotal: 6.35s\tremaining: 1.32s\n",
      "331:\tlearn: 0.0607033\ttotal: 6.37s\tremaining: 1.3s\n",
      "332:\tlearn: 0.0604291\ttotal: 6.39s\tremaining: 1.28s\n",
      "333:\tlearn: 0.0602229\ttotal: 6.41s\tremaining: 1.27s\n",
      "334:\tlearn: 0.0599353\ttotal: 6.42s\tremaining: 1.25s\n",
      "335:\tlearn: 0.0596420\ttotal: 6.44s\tremaining: 1.23s\n",
      "336:\tlearn: 0.0593491\ttotal: 6.46s\tremaining: 1.21s\n",
      "337:\tlearn: 0.0590343\ttotal: 6.48s\tremaining: 1.19s\n",
      "338:\tlearn: 0.0587601\ttotal: 6.5s\tremaining: 1.17s\n",
      "339:\tlearn: 0.0585145\ttotal: 6.52s\tremaining: 1.15s\n",
      "340:\tlearn: 0.0583883\ttotal: 6.54s\tremaining: 1.13s\n",
      "341:\tlearn: 0.0580927\ttotal: 6.56s\tremaining: 1.11s\n",
      "342:\tlearn: 0.0578626\ttotal: 6.58s\tremaining: 1.09s\n",
      "343:\tlearn: 0.0576059\ttotal: 6.59s\tremaining: 1.07s\n",
      "344:\tlearn: 0.0573296\ttotal: 6.61s\tremaining: 1.05s\n",
      "345:\tlearn: 0.0571000\ttotal: 6.63s\tremaining: 1.03s\n",
      "346:\tlearn: 0.0568941\ttotal: 6.65s\tremaining: 1.01s\n",
      "347:\tlearn: 0.0566131\ttotal: 6.67s\tremaining: 996ms\n",
      "348:\tlearn: 0.0564233\ttotal: 6.69s\tremaining: 977ms\n",
      "349:\tlearn: 0.0562073\ttotal: 6.7s\tremaining: 958ms\n",
      "350:\tlearn: 0.0559799\ttotal: 6.72s\tremaining: 938ms\n",
      "351:\tlearn: 0.0557481\ttotal: 6.74s\tremaining: 919ms\n",
      "352:\tlearn: 0.0555538\ttotal: 6.76s\tremaining: 900ms\n",
      "353:\tlearn: 0.0553367\ttotal: 6.78s\tremaining: 881ms\n",
      "354:\tlearn: 0.0551577\ttotal: 6.8s\tremaining: 861ms\n",
      "355:\tlearn: 0.0549297\ttotal: 6.81s\tremaining: 842ms\n",
      "356:\tlearn: 0.0546909\ttotal: 6.83s\tremaining: 823ms\n",
      "357:\tlearn: 0.0544781\ttotal: 6.85s\tremaining: 803ms\n",
      "358:\tlearn: 0.0542152\ttotal: 6.87s\tremaining: 784ms\n",
      "359:\tlearn: 0.0539168\ttotal: 6.88s\tremaining: 765ms\n",
      "360:\tlearn: 0.0536750\ttotal: 6.9s\tremaining: 746ms\n",
      "361:\tlearn: 0.0535401\ttotal: 6.92s\tremaining: 726ms\n",
      "362:\tlearn: 0.0533400\ttotal: 6.94s\tremaining: 707ms\n",
      "363:\tlearn: 0.0531060\ttotal: 6.96s\tremaining: 688ms\n",
      "364:\tlearn: 0.0528641\ttotal: 6.98s\tremaining: 669ms\n",
      "365:\tlearn: 0.0526575\ttotal: 7s\tremaining: 650ms\n",
      "366:\tlearn: 0.0524011\ttotal: 7.02s\tremaining: 631ms\n",
      "367:\tlearn: 0.0521789\ttotal: 7.03s\tremaining: 612ms\n",
      "368:\tlearn: 0.0519289\ttotal: 7.05s\tremaining: 592ms\n",
      "369:\tlearn: 0.0516724\ttotal: 7.07s\tremaining: 573ms\n",
      "370:\tlearn: 0.0514686\ttotal: 7.09s\tremaining: 554ms\n",
      "371:\tlearn: 0.0512040\ttotal: 7.1s\tremaining: 535ms\n",
      "372:\tlearn: 0.0509985\ttotal: 7.12s\tremaining: 515ms\n",
      "373:\tlearn: 0.0507985\ttotal: 7.14s\tremaining: 496ms\n",
      "374:\tlearn: 0.0505726\ttotal: 7.16s\tremaining: 477ms\n",
      "375:\tlearn: 0.0503493\ttotal: 7.17s\tremaining: 458ms\n",
      "376:\tlearn: 0.0501426\ttotal: 7.2s\tremaining: 439ms\n",
      "377:\tlearn: 0.0499607\ttotal: 7.21s\tremaining: 420ms\n",
      "378:\tlearn: 0.0497767\ttotal: 7.23s\tremaining: 401ms\n",
      "379:\tlearn: 0.0496260\ttotal: 7.25s\tremaining: 382ms\n",
      "380:\tlearn: 0.0494488\ttotal: 7.27s\tremaining: 362ms\n",
      "381:\tlearn: 0.0492234\ttotal: 7.29s\tremaining: 343ms\n",
      "382:\tlearn: 0.0490347\ttotal: 7.3s\tremaining: 324ms\n",
      "383:\tlearn: 0.0488405\ttotal: 7.32s\tremaining: 305ms\n",
      "384:\tlearn: 0.0486342\ttotal: 7.34s\tremaining: 286ms\n",
      "385:\tlearn: 0.0485161\ttotal: 7.36s\tremaining: 267ms\n",
      "386:\tlearn: 0.0483290\ttotal: 7.37s\tremaining: 248ms\n",
      "387:\tlearn: 0.0481349\ttotal: 7.39s\tremaining: 229ms\n",
      "388:\tlearn: 0.0479320\ttotal: 7.41s\tremaining: 210ms\n",
      "389:\tlearn: 0.0477085\ttotal: 7.43s\tremaining: 191ms\n",
      "390:\tlearn: 0.0475273\ttotal: 7.45s\tremaining: 171ms\n",
      "391:\tlearn: 0.0473450\ttotal: 7.47s\tremaining: 152ms\n",
      "392:\tlearn: 0.0471554\ttotal: 7.49s\tremaining: 133ms\n",
      "393:\tlearn: 0.0470044\ttotal: 7.5s\tremaining: 114ms\n",
      "394:\tlearn: 0.0468218\ttotal: 7.52s\tremaining: 95.2ms\n",
      "395:\tlearn: 0.0466728\ttotal: 7.54s\tremaining: 76.2ms\n",
      "396:\tlearn: 0.0464709\ttotal: 7.56s\tremaining: 57.1ms\n",
      "397:\tlearn: 0.0463061\ttotal: 7.58s\tremaining: 38.1ms\n",
      "398:\tlearn: 0.0461488\ttotal: 7.6s\tremaining: 19ms\n",
      "399:\tlearn: 0.0460201\ttotal: 7.62s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.62        43\n",
      "           1       0.75      0.68      0.71        31\n",
      "           2       0.72      0.68      0.70        34\n",
      "           3       0.57      0.62      0.59        26\n",
      "           4       0.55      0.59      0.57        27\n",
      "           5       0.69      0.73      0.70        51\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.65      0.65      0.65       212\n",
      "weighted avg       0.66      0.66      0.66       212\n"
     ]
    }
   ],
   "source": [
    "model = cb.CatBoostClassifier(iterations=400, task_type='GPU')\n",
    "model.fit(X_train, y_train)\n",
    "# Generate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:33:13.302839300Z",
     "start_time": "2024-02-24T13:33:04.815260800Z"
    }
   },
   "id": "c14f291177ba9793",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "Very interesting to note is that the Catboost model gave a score of 0.66, not better from the logistic regression,\n",
    "and from other models we have tried so far, \n",
    "meaning that the more complex models do not always outperform the simpler ones."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66b66ab411e286e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural Network\n",
    "\n",
    "While neural networks need a lot of data to perform well, let's try a simple neural network model to see how it performs.\n",
    "\n",
    "We will use the `keras` library to build the neural network model.\n",
    "\n",
    "Let's start by making the train and test splits from above into TensorFlow datasets.\n",
    "\n",
    "We will also define a validation dataset from the training data to monitor the model's performance during training.\n",
    "All the tensors will be batched and pre-fetched to improve performance and also cached to avoid loading the data from the disk during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be15e3c101722f61"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 600  # Adjust based on your dataset size\n",
    "VALIDATION_SPLIT = 0.2  # Fraction of training data to use for validation\n",
    "\n",
    "# Calculate the number of validation samples\n",
    "n_validation_samples = int(len(X_train) * VALIDATION_SPLIT)\n",
    "\n",
    "# Create and process the validation dataset from the training data\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_train[:n_validation_samples], y_train[:n_validation_samples]))\n",
    "val_ds = val_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Update the training dataset to exclude the validation data and process it\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train[n_validation_samples:], y_train[n_validation_samples:]))\n",
    "train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Create and process the test dataset\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_ds = test_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:22.285466400Z",
     "start_time": "2024-02-24T13:52:22.249102400Z"
    }
   },
   "id": "fac050077fcb120",
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "With that done, let's have a look at the first batch of the training dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1bc0a932557566"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [[ 0.0134964   0.0063858  -0.01190186 ... -0.02804565 -0.06958008\n",
      "  -0.003479  ]\n",
      " [-0.02084351 -0.02166748 -0.00558472 ...  0.03881836 -0.05783081\n",
      "  -0.00146484]\n",
      " [ 0.02546692 -0.00386047 -0.01843262 ...  0.03790283 -0.04391479\n",
      "  -0.0231781 ]\n",
      " ...\n",
      " [ 0.02223206 -0.0027256  -0.01734924 ...  0.02944946 -0.0213623\n",
      "  -0.03393555]\n",
      " [ 0.02932739  0.03114319 -0.03488159 ... -0.00068331 -0.0161438\n",
      "  -0.00129414]\n",
      " [ 0.01000977  0.0178833  -0.02072144 ...  0.0010643  -0.06463623\n",
      "   0.0123291 ]], Target: [4 0 5 5 3 0 5 3 1 3 0 3 3 0 0 3 3 5 4 3 5 3 3 5 0 1 0 2 5 1 3 5]\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in train_ds.take(1):\n",
    "    print('Features: {}, Target: {}'.format(feat, targ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:22.548918600Z",
     "start_time": "2024-02-24T13:52:22.536833500Z"
    }
   },
   "id": "28b6cd6e52c06ff9",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the training dataset is structured as expected, with the features and the targets batched together with a size of 32."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2200f63d62e00072"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's define an early stopping callback to stop training the model when the validation loss does not improve after a certain number of epochs. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55faaf898903bf36"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=30,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:23.033607100Z",
     "start_time": "2024-02-24T13:52:23.024722900Z"
    }
   },
   "id": "a2a85456f6f0206a",
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another useful callback method in TensorFlow is the ModelCheckpoint callback. This callback saves the model at regular intervals during training, allowing you to retain and load the best version of your model based on a certain monitored metric, such as validation loss or accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58e3c995a8f8d943"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model_{epoch:02d}-{val_loss:.2f}.keras',  # Change the extension to '.keras'\n",
    "    save_weights_only=False,  # Set to True to save only weights, False to save the entire model\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    mode='min',  # The model is saved when the monitored metric stops decreasing\n",
    "    save_best_only=True,  # Only the best model is saved\n",
    "    verbose=1  # Verbosity mode, 1 or 0\n",
    ")\n",
    "\n",
    "CALLBACKS = [\n",
    "    tfdocs.modeling.EpochDots(),\n",
    "    early_stopping_callback,\n",
    "    model_checkpoint_callback\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:23.595363100Z",
     "start_time": "2024-02-24T13:52:23.588277800Z"
    }
   },
   "id": "e99e3b0058d27c4b",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly, let's define a scheduler callback to adjust the learning rate during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e70949e4096c0a1f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = X_train.shape[0] // BATCH_SIZE\n",
    "lr_scheduler = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    initial_learning_rate=1e-3,  # Initial learning rate\n",
    "    decay_steps=STEPS_PER_EPOCH * 1000,  # Decay steps\n",
    "    decay_rate=0.9,  # Decay rate\n",
    "    staircase=True  # If True, decay the learning rate at discrete intervals\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:24.037393700Z",
     "start_time": "2024-02-24T13:52:24.031370200Z"
    }
   },
   "id": "b24cce175aac2630",
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "source": [
    "With all the callbacks and the learning rate scheduler defined, let's now build the neural network model.\n",
    "\n",
    "We will use a simple neural network with 3 dense layers, the first with 32 units and the second with 16, and a ReLU activation function.\n",
    "The last layer will have 6 units, one for each class, and a softmax activation function.\n",
    "\n",
    "Also, we will use the Adam optimizer and the SparseCategoricalCrossentropy loss function, as well as the accuracy metric.\n",
    "\n",
    "Lastly, we will add WeightRegularization to the model as well as DropoutLayers to prevent overfitting."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "396c45887ea4ddcd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "weight_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=weight_regularizer),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=weight_regularizer),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(n_classes, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:24.399629700Z",
     "start_time": "2024-02-24T13:52:24.371662300Z"
    }
   },
   "id": "ed010b4c406e22d7",
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the model created, let's compile it using the Adam optimizer, the SparseCategoricalCrossentropy loss function, and the accuracy metric."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9600efc4cd8cdafb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=(['accuracy',\n",
    "                        tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                            from_logits=False, name='sparse_categorical_crossentropy')]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:25.491265200Z",
     "start_time": "2024-02-24T13:52:25.483276600Z"
    }
   },
   "id": "3dc26bb0fade8741",
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see now the model summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19eb4b55cb1da4d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 32)                24608     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25238 (98.59 KB)\n",
      "Trainable params: 25238 (98.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:26.076270700Z",
     "start_time": "2024-02-24T13:52:26.040637900Z"
    }
   },
   "id": "7794956153aea89d",
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the model has 25238 parameters to train, which are quite a lot for the small dataset we have.\n",
    "However, with the Dropout layers and the WeightRegularization, we hope to prevent excessive overfitting.\n",
    "\n",
    "Let's now train the model using the training dataset and the validation dataset we created earlier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "689f9ac49e7e4324"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/22 [>.............................] - ETA: 7s - loss: 1.8055 - accuracy: 0.0625 - sparse_categorical_crossentropy: 1.7972\n",
      "Epoch: 0, accuracy:0.1820,  loss:1.7972,  sparse_categorical_crossentropy:1.7882,  val_accuracy:0.2012,  val_loss:1.7907,  val_sparse_categorical_crossentropy:1.7829,  \n",
      ".\n",
      "Epoch 1: val_loss improved from inf to 1.79069, saving model to model_01-1.79.keras\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1.7972 - accuracy: 0.1820 - sparse_categorical_crossentropy: 1.7882 - val_loss: 1.7907 - val_accuracy: 0.2012 - val_sparse_categorical_crossentropy: 1.7829\n",
      "Epoch 2/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7894 - accuracy: 0.2188 - sparse_categorical_crossentropy: 1.7817.\n",
      "Epoch 2: val_loss improved from 1.79069 to 1.78117, saving model to model_02-1.78.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7890 - accuracy: 0.2160 - sparse_categorical_crossentropy: 1.7795 - val_loss: 1.7812 - val_accuracy: 0.2130 - val_sparse_categorical_crossentropy: 1.7754\n",
      "Epoch 3/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7726 - accuracy: 0.2812 - sparse_categorical_crossentropy: 1.7653.\n",
      "Epoch 3: val_loss improved from 1.78117 to 1.76914, saving model to model_03-1.77.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7711 - accuracy: 0.2308 - sparse_categorical_crossentropy: 1.7596 - val_loss: 1.7691 - val_accuracy: 0.2012 - val_sparse_categorical_crossentropy: 1.7657\n",
      "Epoch 4/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7471 - accuracy: 0.2188 - sparse_categorical_crossentropy: 1.7401.\n",
      "Epoch 4: val_loss improved from 1.76914 to 1.75572, saving model to model_04-1.76.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7523 - accuracy: 0.2470 - sparse_categorical_crossentropy: 1.7404 - val_loss: 1.7557 - val_accuracy: 0.2367 - val_sparse_categorical_crossentropy: 1.7526\n",
      "Epoch 5/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7305 - accuracy: 0.2188 - sparse_categorical_crossentropy: 1.7238.\n",
      "Epoch 5: val_loss improved from 1.75572 to 1.73186, saving model to model_05-1.73.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7360 - accuracy: 0.2796 - sparse_categorical_crossentropy: 1.7186 - val_loss: 1.7319 - val_accuracy: 0.2604 - val_sparse_categorical_crossentropy: 1.7308\n",
      "Epoch 6/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7159 - accuracy: 0.1875 - sparse_categorical_crossentropy: 1.7091.\n",
      "Epoch 6: val_loss improved from 1.73186 to 1.70813, saving model to model_06-1.71.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6983 - accuracy: 0.3077 - sparse_categorical_crossentropy: 1.6863 - val_loss: 1.7081 - val_accuracy: 0.2663 - val_sparse_categorical_crossentropy: 1.7090\n",
      "Epoch 7/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.7262 - accuracy: 0.2188 - sparse_categorical_crossentropy: 1.7193.\n",
      "Epoch 7: val_loss improved from 1.70813 to 1.68530, saving model to model_07-1.69.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6800 - accuracy: 0.3299 - sparse_categorical_crossentropy: 1.6555 - val_loss: 1.6853 - val_accuracy: 0.2899 - val_sparse_categorical_crossentropy: 1.6872\n",
      "Epoch 8/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.6322 - accuracy: 0.3438 - sparse_categorical_crossentropy: 1.6251.\n",
      "Epoch 8: val_loss improved from 1.68530 to 1.65181, saving model to model_08-1.65.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6477 - accuracy: 0.3491 - sparse_categorical_crossentropy: 1.6267 - val_loss: 1.6518 - val_accuracy: 0.2959 - val_sparse_categorical_crossentropy: 1.6544\n",
      "Epoch 9/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.6636 - accuracy: 0.3750 - sparse_categorical_crossentropy: 1.6561.\n",
      "Epoch 9: val_loss improved from 1.65181 to 1.63069, saving model to model_09-1.63.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6067 - accuracy: 0.3817 - sparse_categorical_crossentropy: 1.5863 - val_loss: 1.6307 - val_accuracy: 0.3077 - val_sparse_categorical_crossentropy: 1.6356\n",
      "Epoch 10/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.6079 - accuracy: 0.4375 - sparse_categorical_crossentropy: 1.5999.\n",
      "Epoch 10: val_loss improved from 1.63069 to 1.58601, saving model to model_10-1.59.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5623 - accuracy: 0.4172 - sparse_categorical_crossentropy: 1.5353 - val_loss: 1.5860 - val_accuracy: 0.3964 - val_sparse_categorical_crossentropy: 1.5891\n",
      "Epoch 11/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.5608 - accuracy: 0.3750 - sparse_categorical_crossentropy: 1.5523.\n",
      "Epoch 11: val_loss improved from 1.58601 to 1.54522, saving model to model_11-1.55.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5260 - accuracy: 0.4364 - sparse_categorical_crossentropy: 1.4916 - val_loss: 1.5452 - val_accuracy: 0.3964 - val_sparse_categorical_crossentropy: 1.5515\n",
      "Epoch 12/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.5063 - accuracy: 0.3750 - sparse_categorical_crossentropy: 1.4973.\n",
      "Epoch 12: val_loss improved from 1.54522 to 1.51295, saving model to model_12-1.51.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4901 - accuracy: 0.4615 - sparse_categorical_crossentropy: 1.4615 - val_loss: 1.5129 - val_accuracy: 0.4083 - val_sparse_categorical_crossentropy: 1.5190\n",
      "Epoch 13/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.4287 - accuracy: 0.4688 - sparse_categorical_crossentropy: 1.4190.\n",
      "Epoch 13: val_loss improved from 1.51295 to 1.47155, saving model to model_13-1.47.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4375 - accuracy: 0.4512 - sparse_categorical_crossentropy: 1.4002 - val_loss: 1.4716 - val_accuracy: 0.4497 - val_sparse_categorical_crossentropy: 1.4782\n",
      "Epoch 14/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.4074 - accuracy: 0.4688 - sparse_categorical_crossentropy: 1.3970.\n",
      "Epoch 14: val_loss improved from 1.47155 to 1.43399, saving model to model_14-1.43.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3936 - accuracy: 0.4985 - sparse_categorical_crossentropy: 1.3567 - val_loss: 1.4340 - val_accuracy: 0.4615 - val_sparse_categorical_crossentropy: 1.4392\n",
      "Epoch 15/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.3436 - accuracy: 0.5312 - sparse_categorical_crossentropy: 1.3326.\n",
      "Epoch 15: val_loss improved from 1.43399 to 1.40588, saving model to model_15-1.41.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3604 - accuracy: 0.5030 - sparse_categorical_crossentropy: 1.3167 - val_loss: 1.4059 - val_accuracy: 0.4675 - val_sparse_categorical_crossentropy: 1.4122\n",
      "Epoch 16/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.3585 - accuracy: 0.5000 - sparse_categorical_crossentropy: 1.3469.\n",
      "Epoch 16: val_loss improved from 1.40588 to 1.37776, saving model to model_16-1.38.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3156 - accuracy: 0.5222 - sparse_categorical_crossentropy: 1.2755 - val_loss: 1.3778 - val_accuracy: 0.4615 - val_sparse_categorical_crossentropy: 1.3824\n",
      "Epoch 17/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.3430 - accuracy: 0.5000 - sparse_categorical_crossentropy: 1.3306.\n",
      "Epoch 17: val_loss improved from 1.37776 to 1.34474, saving model to model_17-1.34.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2967 - accuracy: 0.5399 - sparse_categorical_crossentropy: 1.2690 - val_loss: 1.3447 - val_accuracy: 0.5148 - val_sparse_categorical_crossentropy: 1.3470\n",
      "Epoch 18/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.3263 - accuracy: 0.5000 - sparse_categorical_crossentropy: 1.3132.\n",
      "Epoch 18: val_loss improved from 1.34474 to 1.31953, saving model to model_18-1.32.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2432 - accuracy: 0.5577 - sparse_categorical_crossentropy: 1.1981 - val_loss: 1.3195 - val_accuracy: 0.5089 - val_sparse_categorical_crossentropy: 1.3226\n",
      "Epoch 19/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.3051 - accuracy: 0.3750 - sparse_categorical_crossentropy: 1.2914.\n",
      "Epoch 19: val_loss improved from 1.31953 to 1.30287, saving model to model_19-1.30.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2311 - accuracy: 0.5414 - sparse_categorical_crossentropy: 1.1845 - val_loss: 1.3029 - val_accuracy: 0.5148 - val_sparse_categorical_crossentropy: 1.3021\n",
      "Epoch 20/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.2849 - accuracy: 0.4375 - sparse_categorical_crossentropy: 1.2706.\n",
      "Epoch 20: val_loss improved from 1.30287 to 1.26689, saving model to model_20-1.27.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1759 - accuracy: 0.5695 - sparse_categorical_crossentropy: 1.1358 - val_loss: 1.2669 - val_accuracy: 0.5562 - val_sparse_categorical_crossentropy: 1.2677\n",
      "Epoch 21/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.2025 - accuracy: 0.5312 - sparse_categorical_crossentropy: 1.1874.\n",
      "Epoch 21: val_loss improved from 1.26689 to 1.26505, saving model to model_21-1.27.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1632 - accuracy: 0.5695 - sparse_categorical_crossentropy: 1.1114 - val_loss: 1.2651 - val_accuracy: 0.5148 - val_sparse_categorical_crossentropy: 1.2614\n",
      "Epoch 22/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0960 - accuracy: 0.6562 - sparse_categorical_crossentropy: 1.0803.\n",
      "Epoch 22: val_loss improved from 1.26505 to 1.23552, saving model to model_22-1.24.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1208 - accuracy: 0.5902 - sparse_categorical_crossentropy: 1.0894 - val_loss: 1.2355 - val_accuracy: 0.5680 - val_sparse_categorical_crossentropy: 1.2313\n",
      "Epoch 23/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.1903 - accuracy: 0.5938 - sparse_categorical_crossentropy: 1.1740.\n",
      "Epoch 23: val_loss improved from 1.23552 to 1.21454, saving model to model_23-1.21.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1116 - accuracy: 0.6050 - sparse_categorical_crossentropy: 1.0743 - val_loss: 1.2145 - val_accuracy: 0.6036 - val_sparse_categorical_crossentropy: 1.2111\n",
      "Epoch 24/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0502 - accuracy: 0.5938 - sparse_categorical_crossentropy: 1.0333.\n",
      "Epoch 24: val_loss improved from 1.21454 to 1.21104, saving model to model_24-1.21.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0883 - accuracy: 0.6302 - sparse_categorical_crossentropy: 1.0371 - val_loss: 1.2110 - val_accuracy: 0.5680 - val_sparse_categorical_crossentropy: 1.2086\n",
      "Epoch 25/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9654 - accuracy: 0.6562 - sparse_categorical_crossentropy: 0.9480.\n",
      "Epoch 25: val_loss improved from 1.21104 to 1.19836, saving model to model_25-1.20.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0564 - accuracy: 0.6257 - sparse_categorical_crossentropy: 1.0162 - val_loss: 1.1984 - val_accuracy: 0.5799 - val_sparse_categorical_crossentropy: 1.1928\n",
      "Epoch 26/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.1452 - accuracy: 0.4688 - sparse_categorical_crossentropy: 1.1272.\n",
      "Epoch 26: val_loss improved from 1.19836 to 1.18997, saving model to model_26-1.19.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.6420 - sparse_categorical_crossentropy: 1.0067 - val_loss: 1.1900 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.1839\n",
      "Epoch 27/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0022 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.9836.\n",
      "Epoch 27: val_loss improved from 1.18997 to 1.17420, saving model to model_27-1.17.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0218 - accuracy: 0.6553 - sparse_categorical_crossentropy: 0.9729 - val_loss: 1.1742 - val_accuracy: 0.5917 - val_sparse_categorical_crossentropy: 1.1681\n",
      "Epoch 28/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0145 - accuracy: 0.6250 - sparse_categorical_crossentropy: 0.9953.\n",
      "Epoch 28: val_loss did not improve from 1.17420\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1.0015 - accuracy: 0.6538 - sparse_categorical_crossentropy: 0.9638 - val_loss: 1.1768 - val_accuracy: 0.5917 - val_sparse_categorical_crossentropy: 1.1711\n",
      "Epoch 29/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9520 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.9323.\n",
      "Epoch 29: val_loss improved from 1.17420 to 1.15834, saving model to model_29-1.16.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9580 - accuracy: 0.6820 - sparse_categorical_crossentropy: 0.9082 - val_loss: 1.1583 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1501\n",
      "Epoch 30/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 1.0607 - accuracy: 0.6875 - sparse_categorical_crossentropy: 1.0405.\n",
      "Epoch 30: val_loss improved from 1.15834 to 1.14732, saving model to model_30-1.15.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9437 - accuracy: 0.6967 - sparse_categorical_crossentropy: 0.9111 - val_loss: 1.1473 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1411\n",
      "Epoch 31/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8820 - accuracy: 0.6562 - sparse_categorical_crossentropy: 0.8612.\n",
      "Epoch 31: val_loss improved from 1.14732 to 1.14128, saving model to model_31-1.14.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9337 - accuracy: 0.6672 - sparse_categorical_crossentropy: 0.8789 - val_loss: 1.1413 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1376\n",
      "Epoch 32/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9384 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.9171.\n",
      "Epoch 32: val_loss did not improve from 1.14128\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.9349 - accuracy: 0.6923 - sparse_categorical_crossentropy: 0.8865 - val_loss: 1.1492 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.1397\n",
      "Epoch 33/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9479 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.9261.\n",
      "Epoch 33: val_loss improved from 1.14128 to 1.13338, saving model to model_33-1.13.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9033 - accuracy: 0.7189 - sparse_categorical_crossentropy: 0.8575 - val_loss: 1.1334 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1267\n",
      "Epoch 34/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7287 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.7065.\n",
      "Epoch 34: val_loss did not improve from 1.13338\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8952 - accuracy: 0.6923 - sparse_categorical_crossentropy: 0.8447 - val_loss: 1.1395 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1301\n",
      "Epoch 35/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.9263 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.9036.\n",
      "Epoch 35: val_loss improved from 1.13338 to 1.12907, saving model to model_35-1.13.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9311 - accuracy: 0.6760 - sparse_categorical_crossentropy: 0.8850 - val_loss: 1.1291 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1195\n",
      "Epoch 36/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8549 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.8317.\n",
      "Epoch 36: val_loss improved from 1.12907 to 1.12107, saving model to model_36-1.12.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8649 - accuracy: 0.7263 - sparse_categorical_crossentropy: 0.8144 - val_loss: 1.1211 - val_accuracy: 0.6331 - val_sparse_categorical_crossentropy: 1.1107\n",
      "Epoch 37/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7489 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.7252.\n",
      "Epoch 37: val_loss did not improve from 1.12107\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8682 - accuracy: 0.7219 - sparse_categorical_crossentropy: 0.8194 - val_loss: 1.1215 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1100\n",
      "Epoch 38/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7768 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.7527.\n",
      "Epoch 38: val_loss did not improve from 1.12107\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8571 - accuracy: 0.7352 - sparse_categorical_crossentropy: 0.8066 - val_loss: 1.1232 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1168\n",
      "Epoch 39/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7510 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.7265.\n",
      "Epoch 39: val_loss improved from 1.12107 to 1.11792, saving model to model_39-1.12.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8121 - accuracy: 0.7322 - sparse_categorical_crossentropy: 0.7591 - val_loss: 1.1179 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1116\n",
      "Epoch 40/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6948 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.6699.\n",
      "Epoch 40: val_loss did not improve from 1.11792\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8348 - accuracy: 0.7189 - sparse_categorical_crossentropy: 0.7825 - val_loss: 1.1248 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1177\n",
      "Epoch 41/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.8099 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.7844.\n",
      "Epoch 41: val_loss did not improve from 1.11792\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8149 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.7607 - val_loss: 1.1296 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1206\n",
      "Epoch 42/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6577 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.6319.\n",
      "Epoch 42: val_loss did not improve from 1.11792\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8187 - accuracy: 0.7352 - sparse_categorical_crossentropy: 0.7727 - val_loss: 1.1211 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1109\n",
      "Epoch 43/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7420 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.7158.\n",
      "Epoch 43: val_loss improved from 1.11792 to 1.10995, saving model to model_43-1.11.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8047 - accuracy: 0.7145 - sparse_categorical_crossentropy: 0.7587 - val_loss: 1.1100 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1029\n",
      "Epoch 44/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5854 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.5588.\n",
      "Epoch 44: val_loss did not improve from 1.10995\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7649 - accuracy: 0.7559 - sparse_categorical_crossentropy: 0.7096 - val_loss: 1.1179 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1117\n",
      "Epoch 45/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7234 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.6963.\n",
      "Epoch 45: val_loss did not improve from 1.10995\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7622 - accuracy: 0.7544 - sparse_categorical_crossentropy: 0.7167 - val_loss: 1.1343 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1273\n",
      "Epoch 46/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7005 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.6730.\n",
      "Epoch 46: val_loss improved from 1.10995 to 1.10698, saving model to model_46-1.11.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.7485 - sparse_categorical_crossentropy: 0.7274 - val_loss: 1.1070 - val_accuracy: 0.6331 - val_sparse_categorical_crossentropy: 1.0970\n",
      "Epoch 47/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6790 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.6512.\n",
      "Epoch 47: val_loss did not improve from 1.10698\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.7663 - sparse_categorical_crossentropy: 0.6769 - val_loss: 1.1154 - val_accuracy: 0.6391 - val_sparse_categorical_crossentropy: 1.1102\n",
      "Epoch 48/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5791 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.5508.\n",
      "Epoch 48: val_loss improved from 1.10698 to 1.10516, saving model to model_48-1.11.keras\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7514 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.6984 - val_loss: 1.1052 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.0956\n",
      "Epoch 49/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5974 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.5688.\n",
      "Epoch 49: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.7811 - sparse_categorical_crossentropy: 0.6561 - val_loss: 1.1285 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1253\n",
      "Epoch 50/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6924 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.6633.\n",
      "Epoch 50: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.7574 - sparse_categorical_crossentropy: 0.6778 - val_loss: 1.1184 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1109\n",
      "Epoch 51/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7107 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.6813.\n",
      "Epoch 51: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.7840 - sparse_categorical_crossentropy: 0.6411 - val_loss: 1.1206 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1130\n",
      "Epoch 52/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6500 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.6202.\n",
      "Epoch 52: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.7485 - sparse_categorical_crossentropy: 0.6594 - val_loss: 1.1322 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1256\n",
      "Epoch 53/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6539 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.6238.\n",
      "Epoch 53: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.8018 - sparse_categorical_crossentropy: 0.6121 - val_loss: 1.1282 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1197\n",
      "Epoch 54/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5416 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.5111.\n",
      "Epoch 54: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.7722 - sparse_categorical_crossentropy: 0.6089 - val_loss: 1.1270 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1241\n",
      "Epoch 55/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6854 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.6545.\n",
      "Epoch 55: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.8107 - sparse_categorical_crossentropy: 0.5902 - val_loss: 1.1314 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1259\n",
      "Epoch 56/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6480 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.6167.\n",
      "Epoch 56: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.7914 - sparse_categorical_crossentropy: 0.6058 - val_loss: 1.1303 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1232\n",
      "Epoch 57/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5174 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.4858.\n",
      "Epoch 57: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6155 - accuracy: 0.8107 - sparse_categorical_crossentropy: 0.5614 - val_loss: 1.1542 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1508\n",
      "Epoch 58/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6471 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.6151.\n",
      "Epoch 58: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.7929 - sparse_categorical_crossentropy: 0.5913 - val_loss: 1.1499 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1491\n",
      "Epoch 59/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.4128 - accuracy: 0.9375 - sparse_categorical_crossentropy: 0.3805.\n",
      "Epoch 59: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.7973 - sparse_categorical_crossentropy: 0.5869 - val_loss: 1.1437 - val_accuracy: 0.5917 - val_sparse_categorical_crossentropy: 1.1404\n",
      "Epoch 60/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5270 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.4943.\n",
      "Epoch 60: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.8018 - sparse_categorical_crossentropy: 0.5847 - val_loss: 1.1437 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1394\n",
      "Epoch 61/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5782 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.5452.\n",
      "Epoch 61: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.8195 - sparse_categorical_crossentropy: 0.5371 - val_loss: 1.1654 - val_accuracy: 0.5976 - val_sparse_categorical_crossentropy: 1.1633\n",
      "Epoch 62/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7184 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.6850.\n",
      "Epoch 62: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.8358 - sparse_categorical_crossentropy: 0.5294 - val_loss: 1.1657 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1658\n",
      "Epoch 63/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7317 - accuracy: 0.6875 - sparse_categorical_crossentropy: 0.6980.\n",
      "Epoch 63: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.8151 - sparse_categorical_crossentropy: 0.5389 - val_loss: 1.1623 - val_accuracy: 0.6331 - val_sparse_categorical_crossentropy: 1.1539\n",
      "Epoch 64/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6406 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.6064.\n",
      "Epoch 64: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.8240 - sparse_categorical_crossentropy: 0.5216 - val_loss: 1.1706 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.1669\n",
      "Epoch 65/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5839 - accuracy: 0.9062 - sparse_categorical_crossentropy: 0.5494.\n",
      "Epoch 65: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.8269 - sparse_categorical_crossentropy: 0.5437 - val_loss: 1.1696 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.1682\n",
      "Epoch 66/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5990 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.5642.\n",
      "Epoch 66: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.8225 - sparse_categorical_crossentropy: 0.5081 - val_loss: 1.1708 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1698\n",
      "Epoch 67/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6331 - accuracy: 0.7500 - sparse_categorical_crossentropy: 0.5979.\n",
      "Epoch 67: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.8447 - sparse_categorical_crossentropy: 0.4885 - val_loss: 1.1829 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1826\n",
      "Epoch 68/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5781 - accuracy: 0.8125 - sparse_categorical_crossentropy: 0.5426.\n",
      "Epoch 68: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.8195 - sparse_categorical_crossentropy: 0.5062 - val_loss: 1.1871 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.1847\n",
      "Epoch 69/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.6090 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.5732.\n",
      "Epoch 69: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 0.8373 - sparse_categorical_crossentropy: 0.4824 - val_loss: 1.1756 - val_accuracy: 0.6095 - val_sparse_categorical_crossentropy: 1.1718\n",
      "Epoch 70/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5982 - accuracy: 0.7812 - sparse_categorical_crossentropy: 0.5621.\n",
      "Epoch 70: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.8343 - sparse_categorical_crossentropy: 0.4693 - val_loss: 1.2020 - val_accuracy: 0.6331 - val_sparse_categorical_crossentropy: 1.2007\n",
      "Epoch 71/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.3822 - accuracy: 0.9062 - sparse_categorical_crossentropy: 0.3458.\n",
      "Epoch 71: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.8388 - sparse_categorical_crossentropy: 0.4595 - val_loss: 1.2052 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.2010\n",
      "Epoch 72/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.4160 - accuracy: 0.9062 - sparse_categorical_crossentropy: 0.3792.\n",
      "Epoch 72: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8609 - sparse_categorical_crossentropy: 0.4154 - val_loss: 1.2121 - val_accuracy: 0.6331 - val_sparse_categorical_crossentropy: 1.2120\n",
      "Epoch 73/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.3628 - accuracy: 0.9375 - sparse_categorical_crossentropy: 0.3257.\n",
      "Epoch 73: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.8299 - sparse_categorical_crossentropy: 0.4606 - val_loss: 1.2111 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.2106\n",
      "Epoch 74/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.7651 - accuracy: 0.6250 - sparse_categorical_crossentropy: 0.7277.\n",
      "Epoch 74: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8595 - sparse_categorical_crossentropy: 0.4588 - val_loss: 1.2167 - val_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.2096\n",
      "Epoch 75/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5158 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.4781.\n",
      "Epoch 75: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.8432 - sparse_categorical_crossentropy: 0.4730 - val_loss: 1.2159 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.2119\n",
      "Epoch 76/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5193 - accuracy: 0.9062 - sparse_categorical_crossentropy: 0.4812.\n",
      "Epoch 76: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.8506 - sparse_categorical_crossentropy: 0.4509 - val_loss: 1.2215 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.2142\n",
      "Epoch 77/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5107 - accuracy: 0.8750 - sparse_categorical_crossentropy: 0.4723.\n",
      "Epoch 77: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.8550 - sparse_categorical_crossentropy: 0.4514 - val_loss: 1.2249 - val_accuracy: 0.6154 - val_sparse_categorical_crossentropy: 1.2215\n",
      "Epoch 78/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.5836 - accuracy: 0.8438 - sparse_categorical_crossentropy: 0.5450.\n",
      "Epoch 78: val_loss did not improve from 1.10516\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8772 - sparse_categorical_crossentropy: 0.4081 - val_loss: 1.2363 - val_accuracy: 0.6213 - val_sparse_categorical_crossentropy: 1.2307\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=CALLBACKS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:31.385244100Z",
     "start_time": "2024-02-24T13:52:27.401666300Z"
    }
   },
   "id": "18398cf390d74222",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 48\n"
     ]
    }
   ],
   "source": [
    "# Print the best epoch\n",
    "print(f\"Best epoch: {np.argmin(history.history['val_loss']) + 1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:31.385244100Z",
     "start_time": "2024-02-24T13:52:31.380733700Z"
    }
   },
   "id": "9e94b94dac4e6eeb",
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now using tfdocs.plots.HistoryPlotter, we can visualize the training and validation loss and accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc642328f72f6966"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size_histories = {}\n",
    "size_histories['Baseline'] = history\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric='sparse_categorical_crossentropy', smoothing_std=10)\n",
    "plotter.plot(size_histories)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:31.469964500Z",
     "start_time": "2024-02-24T13:52:31.384243900Z"
    }
   },
   "id": "a7a2ea0769fdc279",
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also plot the training and validation accuracy values, to see how the model performs throughout the epochs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e826876952f5fb0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x2389e73ffd0>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1400x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "history_data = history.history\n",
    "\n",
    "epochs = range(1, len(history_data['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history_data['accuracy'], label='Training Accuracy')\n",
    "plt.plot(epochs, history_data['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:52:31.573156900Z",
     "start_time": "2024-02-24T13:52:31.470964400Z"
    }
   },
   "id": "2ef73d4bcd5566df",
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the model the validation loss becomes stagnant after about 40 epochs.\n",
    "\n",
    "Let's now evaluate the model on the test dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a97fe8c00c1e28e0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0647 - accuracy: 0.6840 - sparse_categorical_crossentropy: 1.0440\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.0646954774856567, 0.6839622855186462, 1.0439884662628174]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, verbose=1, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:53:53.810373100Z",
     "start_time": "2024-02-24T10:53:53.783897Z"
    }
   },
   "id": "d52c2208aed74b8b",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also generate a classification report for the model along with the confusion matrix."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb4f229959c3287d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 833us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64        43\n",
      "           1       0.73      0.71      0.72        31\n",
      "           2       0.85      0.68      0.75        34\n",
      "           3       0.52      0.62      0.56        26\n",
      "           4       0.57      0.63      0.60        27\n",
      "           5       0.78      0.76      0.77        51\n",
      "\n",
      "    accuracy                           0.68       212\n",
      "   macro avg       0.68      0.67      0.67       212\n",
      "weighted avg       0.70      0.68      0.69       212\n",
      "\n",
      "[[28  0  2  6  2  5]\n",
      " [ 2 22  1  1  3  2]\n",
      " [ 3  4 23  2  1  1]\n",
      " [ 5  1  0 16  3  1]\n",
      " [ 2  1  0  5 17  2]\n",
      " [ 4  2  1  1  4 39]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:53:57.591156400Z",
     "start_time": "2024-02-24T10:53:57.526120700Z"
    }
   },
   "id": "73a947990a3f8705",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the model has an accuracy of 0.68, which is not bad considering the small dataset we have.\n",
    "\n",
    "However, we can see that the model is overfitting the training data, as the validation loss becomes higher than the training loss quickly,\n",
    "which makes sense given the small dataset we have.\n",
    "\n",
    "Ironically, the simpler models such as SVM and SGD outperformed the neural network model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ab41048404b3e7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Two-Level Classification\n",
    "\n",
    "As we saw from before, we got the best results using the SGD Classifier.\n",
    "\n",
    "Let's now try to perform a two-level classification, where we first classify the class of the word and then classify the division/section of the word based on the class it belongs to.\n",
    "\n",
    "Firstly, we will create a new column in the dataframe named division/section, \n",
    "where it has as value the division if the division is not 4 (meaning `N/A` in our case),\n",
    " otherwise it has the value of the section.\n",
    "\n",
    "Then we will split the data into training and testing sets, using 80% of the data for training and 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cece51585462464"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# For the cls_df dataframe create a new column named division/section where it has as value the division if the division is not 4, otherwise it has the value of the section\n",
    "cls_df['division/section'] = cls_df['division']\n",
    "\n",
    "# 4 Means No Division and this is evident if we take a look at the dataset\n",
    "cls_df.loc[cls_df['division'] == 4, 'division/section'] = cls_df['section']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:34:14.808145500Z",
     "start_time": "2024-02-24T13:34:14.792206100Z"
    }
   },
   "id": "a7f158c0df67a4a0",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's split the data into training and testing sets, using 80% of the data for training and 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2411460d85eb8e55"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get class and division/section\n",
    "y = cls_df[['class', 'division/section']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:34:15.047855600Z",
     "start_time": "2024-02-24T13:34:15.040314500Z"
    }
   },
   "id": "85fde21674eaec17",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having done that we can now approach the two-level classification using the SGD Classifier as before, but this\n",
    "time we will use the `MultiOutputClassifier` from sklearn to perform the multi-output classification.\n",
    "However, there is a drawback to this approach, because at present, no metric in sklearn.metrics supports the multiclass-multioutput classification task.\n",
    "This means that we will have to create our own custom accuracy metric for the multi-output classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25d67e79115b7dd8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-output Accuracy: 0.5377358490566038\n"
     ]
    }
   ],
   "source": [
    "# Create a multi-output classifier\n",
    "multi_output_model = MultiOutputClassifier(\n",
    "    sgd_model, n_jobs=-1)\n",
    "\n",
    "# Train the multi-output classifier\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = multi_output_model.predict(X_test)\n",
    "\n",
    "# Custom accuracy for multi-output\n",
    "def multioutput_accuracy(y_true, y_pred):\n",
    "    correct = np.all(y_true == y_pred, axis=1)\n",
    "    return np.mean(correct)\n",
    "\n",
    "accuracy = multioutput_accuracy(y_test, y_pred)\n",
    "print(f\"Multi-output Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:34:18.119601500Z",
     "start_time": "2024-02-24T13:34:15.590134400Z"
    }
   },
   "id": "79b2a49fecb749be",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the multi-output accuracy is 0.538 which is not bad considering the small dataset we have,\n",
    "however, it is not as good as the single-output classification we performed earlier.\n",
    "Also, the custom accuracy metric we created may not be the best way to evaluate the multi-output classification.\n",
    "\n",
    "For that reason, let's also look at the accuracy of each target separately."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7326f9175f93ceb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 0 accuracy: 0.7169811320754716\n",
      "Target 1 accuracy: 0.589622641509434\n"
     ]
    }
   ],
   "source": [
    "for i in range(y_test.shape[1]):\n",
    "    # Use .iloc to select all rows and the ith column for both Y_test and predictions\n",
    "    accuracy = metrics.accuracy_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    print(f\"Target {i} accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T13:35:39.651822300Z",
     "start_time": "2024-02-24T13:35:39.629788900Z"
    }
   },
   "id": "aad02505956f90b5",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the accuracy of the first target (class) is around 0.716, which is the same as the single-output classification we performed earlier,\n",
    "however, the accuracy of the second target (division/section) is around 0.589, which is not as good as the single-output classification we performed earlier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f28f8346f842146b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
