{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Roget's Thesaurus in the 21st Century\n",
    "---\n",
    ">Spanakis Panagiotis-Alexios, Pregraduate Student\n",
    "Department of Management Science and Technology\n",
    "Athens University of Economics and Business\n",
    "t8200158@aueb.gr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0de3c4c368d8a2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Before we start\n",
    "\n",
    "We first need to go over the dependencies needed for this notebook to function properly"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8085dad604aba2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dependencies for all the Notebooks in the Project\n",
    "\n",
    "\n",
    "We will need to use libraries that are not included in the Python Standard Library which are handled using Poetry\n",
    "\n",
    "In order to install the dependencies, we will need to run the following commands in the terminal \n",
    "\n",
    "1. (If we haven't already installed Poetry)\n",
    "```bash\n",
    "pip install poetry\n",
    "```\n",
    "\n",
    "2. After we have installed Poetry, we will need to run the following command in the terminal\n",
    "```bash\n",
    "poetry install\n",
    "```\n",
    "\n",
    "3. (Optional) If we want to use the Jupyter Notebook with the virtual environment created by Poetry, we will need to run the following command in the terminal\n",
    "```bash\n",
    "poetry shell\n",
    "```\n",
    "\n",
    "4. After we have installed the dependencies, we will need to run the following command in the terminal\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d1ad5219b142504"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use the following libraries:\n",
    "\n",
    "- `pandas` for data manipulation\n",
    "---\n",
    "- `requests` for making HTTP requests\n",
    "- `beautifulsoup4` for web scraping\n",
    "---\n",
    "- `re` for regular expressions\n",
    "- `os` for file manipulation\n",
    "- `json` for JSON manipulation\n",
    "---\n",
    "- `chromadb` to store the embeddings to a vector database\n",
    "- `nomic` in order to interact with the nomic API\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3881e25aeb3eb08"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import chromadb\n",
    "from nomic import embed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:25.041002300Z",
     "start_time": "2024-02-24T11:49:23.108620200Z"
    }
   },
   "id": "b8a4d04f81d70b0f",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Roget's Thesaurus Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45398213a7eaca50"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's explain how the words along with their classes and divisions and sections are organized in the Gutenberg page\n",
    "\n",
    "The words are organized in the page in the following manner:\n",
    "\n",
    "1) They belong to a class\n",
    "2) They belong to a division (if it exists) within the class\n",
    "3) They belong to a section within the division (if it exists) or within the class\n",
    "\n",
    "Let's start by getting the page and parsing it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "841f2d7796f60f8b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the page\n",
    "r = requests.get(\"https://www.gutenberg.org/files/10681/old/20040627-10681-h-body-pos.htm\")\n",
    "# Parse the page\n",
    "html = r.text\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:28.837169600Z",
     "start_time": "2024-02-24T11:49:25.041002300Z"
    }
   },
   "id": "aff37d0cdd42e896",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "1) We can notice that all classes on the page are represented by a `<dt>` tag with an `<a>` tag inside it. \n",
    "The `<a>` tag has a name attribute that starts with **`CLASS`**. The text of the `<a>` tag is the name of the class.\n",
    "\n",
    "\n",
    "2) We can notice that all divisions on the page are represented by a `<dt>` tag with an `<a>` tag inside it.\n",
    "The `<a>` tag has a name attribute that starts with **`DIVISION`**. The text of the `<a>` tag is the name of the division.\n",
    "\n",
    "\n",
    "3) We can notice that all sections on the page are represented by a `<dt>` tag with an `<a>` tag inside it.\n",
    "The `<a>` tag has a name attribute that starts with **`SECTION`**. The text of the `<a>` tag is the name of the section.\n",
    "\n",
    "Lastly, the words are represented by a `<dt>` tag with an `<a>` tag inside it. The `<a>` tag has a name attribute that is a number or a number with a letter at the end.\n",
    "We notice that the words come after the `<a>` tag where the name attribute is a number and also that tag is inside a `<b>` tag.\n",
    "So in order to get the words we must get the text of the `<b>` tag that comes after the `<a>` tag where the name attribute is a number."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f33736d5050a47f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the above in mind, we can extract the hierarchy of classes, divisions, sections, and words from the page.\n",
    "We can then create a directory structure that mirrors the structure of the page and save the words under each section to a file in the directory structure \n",
    "using a dictionary to hold the entire hierarchy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea14f7c774083d2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the entire hierarchy\n",
    "hierarchy = {}\n",
    "current_class = None\n",
    "current_division = None\n",
    "current_section = None\n",
    "\n",
    "# Find all <dt> tags\n",
    "dt_tags = soup.find_all('dt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:28.845479800Z",
     "start_time": "2024-02-24T11:49:28.825171Z"
    }
   },
   "id": "584ab5f5572f866e",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having the dictionary initialized and the `<dt>` tags found, we can now iterate through each `<dt>` tag and extract the hierarchy of classes, divisions, sections, and words from the page. Also, split the words if they have a comma or a dot and add them to the hierarchy separately.\n",
    "\n",
    "We will use the following logic to extract the hierarchy:\n",
    "\n",
    "1) If the `<dt>` tag has an `<a>` tag with a name attribute that starts with **`CLASS`** then we have found a class. We will add the class to the hierarchy and continue to the next `<dt>` tag to check for division/section.\n",
    "2) If the `<dt>` tag has an `<a>` tag with a name attribute that starts with **`DIVISION`** then we have found a division. We will add the division to the hierarchy and continue to the next `<dt>` tag to check for section.\n",
    "3) If the `<dt>` tag has an `<a>` tag with a name attribute that starts with **`SECTION`** then we have found a section. We will add the section to the hierarchy and continue to the next `<dt>` tag to check for words.\n",
    "4) Lastly, if the `<dt>` tag has an `<a>` tag with a name attribute that is a number or a number with a letter at the end then we have found a word. We will add the word to the hierarchy under the section it belongs to. Important to note that we will split the word regarding the comma and . and add the words to the hierarchy separately. Also, if the word has (\\u0086), a cross,  then we will remove it so that we can have a clean word."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ba3ffdff86f959c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Iterate through each <dt> tag\n",
    "for dt in dt_tags:\n",
    "    # Check for class\n",
    "    class_a_tag = dt.find('a', attrs={'name': re.compile(\"^CLASS\")})\n",
    "    if class_a_tag:\n",
    "        current_class = re.sub(r'\\s+', ' ', class_a_tag.text).strip()\n",
    "        hierarchy[current_class] = {'divisions': {}, 'sections': {}}\n",
    "        current_division = None\n",
    "        current_section = None\n",
    "        # Now that we got the class we can continue to the next <dt> tag to check for division/section\n",
    "        continue\n",
    "\n",
    "    # Check for division\n",
    "    division_a_tag = dt.find('a', attrs={'name': re.compile(\"^DIVISION\")})\n",
    "    if division_a_tag and current_class:\n",
    "        current_division = re.sub(r'\\s+', ' ', division_a_tag.text).strip()\n",
    "        hierarchy[current_class]['divisions'][current_division] = {'sections': {}}\n",
    "        current_section = None\n",
    "        # Now that we got the division we can continue to the next <dt> tag to check for section\n",
    "        continue\n",
    "\n",
    "    # Check for section\n",
    "    section_a_tag = dt.find('a', attrs={'name': re.compile(\"^SECTION\")})\n",
    "    if section_a_tag:\n",
    "        current_section = re.sub(r'\\s+', ' ', section_a_tag.text).strip()\n",
    "        if current_division:\n",
    "            hierarchy[current_class]['divisions'][current_division]['sections'][current_section] = []\n",
    "        else:\n",
    "            hierarchy[current_class]['sections'][current_section] = []\n",
    "        # Now that we got the section we can continue to the next <dt> tag to check for words\n",
    "        continue\n",
    "\n",
    "    # Check for words (the words are before an a tag with a name attribute that is a number (integer or float))\n",
    "    word_a_tags = dt.find_all('a', attrs={'name': re.compile(\"^\\d+(\\.\\d+)?$\")})\n",
    "    for word_a_tag in word_a_tags:\n",
    "        word = word_a_tag.find_next('b').get_text() if word_a_tag.find_next('b') else ''\n",
    "        word = re.sub(r'\\s+', ' ', word).strip()\n",
    "\n",
    "        # Split the word regarding the comma and . and add the words to the hierarchy\n",
    "        words = re.split(r',|\\.', word)\n",
    "        for word in words:\n",
    "            word = word.strip()\n",
    "            # If the word has (\\u0086) then remove it\n",
    "            if '†' in word:\n",
    "                word = word.replace('†', '')\n",
    "            if current_section and word:\n",
    "                if current_division:\n",
    "                    hierarchy[current_class]['divisions'][current_division]['sections'][current_section].append(word)\n",
    "                else:\n",
    "                    hierarchy[current_class]['sections'][current_section].append(word)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.031390100Z",
     "start_time": "2024-02-24T11:49:28.845479800Z"
    }
   },
   "id": "b7aa087148964d5c",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the hierarchy of classes, divisions, sections, and words, we can take at the hierarchy we created."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f19c9ec29f59de8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'divisions': {},\n 'sections': {'EXISTENCE': ['Existence',\n   'Inexistence',\n   'Substantiality',\n   'Unsubstantiality',\n   'Intrinsicality',\n   'Extrinsicality',\n   'State',\n   'Circumstance'],\n  'RELATION': ['Relation',\n   'Irrelation',\n   'Consanguinity',\n   'Correlation',\n   'Identity',\n   'Contrariety',\n   'Difference',\n   'Uniformity',\n   'Nonuniformity',\n   'Similarity',\n   'Dissimilarity',\n   'Imitation',\n   'Nonimitation',\n   'Variation',\n   'Copy',\n   'Prototype',\n   'Agreement',\n   'Disagreement'],\n  'QUANTITY': ['Quantity',\n   'Degree',\n   'Equality',\n   'Inequality',\n   'Mean',\n   'Compensation',\n   'Greatness',\n   'Smallness',\n   'Superiority',\n   'Inferiority',\n   'Increase',\n   'Nonincrease',\n   'Decrease',\n   'Addition',\n   'Nonaddition',\n   'Subtraction',\n   'Adjunct',\n   'Remainder',\n   'Decrement',\n   'Mixture',\n   'Simpleness',\n   'Junction',\n   'Disjunction',\n   'Connection',\n   'Coherence',\n   'Incoherence',\n   'Combination',\n   'Decomposition',\n   'Whole',\n   'Part',\n   'Completeness',\n   'Incompleteness',\n   'Composition',\n   'Exclusion',\n   'Component',\n   'Extraneousness'],\n  'ORDER': ['Order',\n   'Disorder',\n   'Complexity',\n   'Arrangement',\n   'Derangement',\n   'Precedence',\n   'Sequence',\n   'Precursor',\n   'Sequel',\n   'Beginning',\n   'End',\n   'Middle',\n   'Continuity',\n   'Discontinuity',\n   'Term',\n   'Assemblage',\n   'Nonassemblage',\n   'Dispersion',\n   'Focus',\n   'Class',\n   'Inclusion',\n   'Exclusion',\n   'Generality',\n   'Speciality',\n   'Normality',\n   'Multiformity',\n   'Conformity',\n   'Unconformity'],\n  'NUMBER': ['Number',\n   'Numeration',\n   'List',\n   'Unity',\n   'Accompaniment',\n   'Duality',\n   'Duplication',\n   'bisection',\n   'Triality',\n   'Triplication',\n   'Trisection',\n   'Four',\n   'Quadruplication',\n   'Quadrisection',\n   'Five',\n   'Quinquesection',\n   'Plurality',\n   'Fraction',\n   'Zero',\n   'Multitude',\n   'Fewness',\n   'Repetition',\n   'Infinity'],\n  'TIME': ['Time',\n   'Neverness',\n   'Period',\n   'Contingent Duration',\n   'Course',\n   'Diuturnity',\n   'Transientness',\n   'Perpetuity',\n   'Instantaneity',\n   'Chronometry',\n   'Anachronism',\n   'Priority',\n   'Posteriority',\n   'The Present Time',\n   'Different time',\n   'Synchronism',\n   'Futurity',\n   'The Past',\n   'Newness',\n   'Oldness',\n   'Morning',\n   'Evening',\n   'Youth',\n   'Age',\n   'Infant',\n   'Veteran',\n   'Adolescence',\n   'Earliness',\n   'Punctuality',\n   'Lateness',\n   'Occasion',\n   'Untimeliness',\n   'Frequency',\n   'Infrequency',\n   'Periodicity',\n   'Irregularity of recurrence'],\n  'CHANGE': ['Change',\n   'Permanence',\n   'Cessation',\n   'Continuance in action',\n   'Conversion',\n   'Reversion',\n   'Revolution',\n   'Substitution',\n   'Interchange',\n   'Changeableness',\n   'Stability',\n   'Eventuality',\n   'Destiny'],\n  'CAUSATION': ['Cause',\n   'Effect',\n   'Attribution',\n   'Chance',\n   'Power',\n   'Impotence',\n   'Strength',\n   'Weakness',\n   'Production',\n   'Destruction',\n   'Reproduction',\n   'Producer',\n   'Destroyer',\n   'Paternity',\n   'Posterity',\n   'Productiveness',\n   'Unproductiveness',\n   'Agency',\n   'Physical Energy',\n   'Physical Inertness',\n   'Violence',\n   'Moderation',\n   'Influence',\n   'Absence of Influence',\n   'Tendency',\n   'Liability',\n   'Concurrence',\n   'Counteraction']}}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy['WORDS EXPRESSING ABSTRACT RELATIONS']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.036902100Z",
     "start_time": "2024-02-24T11:49:29.032388300Z"
    }
   },
   "id": "aec564994e3210be",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now save the hierarchy to a JSON file so that we can use it later."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e174ef1a4c29c70a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the hierarchy to a json file\n",
    "\n",
    "with open('hierarchy.json', 'w') as file:\n",
    "    json.dump(hierarchy, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.047893600Z",
     "start_time": "2024-02-24T11:49:29.036902100Z"
    }
   },
   "id": "12981f3c6aadc361",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the directory structure and save the words to files (Optional)\n",
    "\n",
    "Now that we have the hierarchy, we can create a directory structure that mirrors the structure of the page and save the words under each section to a file in the directory structure.\n",
    "\n",
    "Let's start by creating a function that writes the words to a file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a61acc8b48c234f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def write_words_to_file(words, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write('\\n'.join(words))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.055735700Z",
     "start_time": "2024-02-24T11:49:29.046894900Z"
    }
   },
   "id": "4a0df396346d21f4",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by creating a directory structure that mirrors the structure of the page."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a32b5d427e6421e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_directory_structure(base_path, hierarchy):\n",
    "    for class_name, class_content in hierarchy.items():\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        os.makedirs(class_path, exist_ok=True)\n",
    "\n",
    "        for division_name, division_content in class_content.get('divisions', {}).items():\n",
    "            division_path = os.path.join(class_path, division_name)\n",
    "            os.makedirs(division_path, exist_ok=True)\n",
    "\n",
    "            for section_name, words in division_content.get('sections', {}).items():\n",
    "                section_path = os.path.join(division_path, section_name)\n",
    "                os.makedirs(section_path, exist_ok=True)\n",
    "                write_words_to_file(words, os.path.join(section_path, 'words.txt'))\n",
    "\n",
    "        for section_name, words in class_content.get('sections', {}).items():\n",
    "            section_path = os.path.join(class_path, section_name)\n",
    "            os.makedirs(section_path, exist_ok=True)\n",
    "            write_words_to_file(words, os.path.join(section_path, 'words.txt'))\n",
    "\n",
    "\n",
    "# Create the directory structure\n",
    "base_path = 'roget_thesaurus_final'\n",
    "create_directory_structure(base_path, hierarchy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.090604200Z",
     "start_time": "2024-02-24T11:49:29.052737900Z"
    }
   },
   "id": "16320faac31a0471",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have created the directory structure and saved the words to files, we can take a look at how many words we have in the thesaurus."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6787e3714a46f793"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1057"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the lines in the files\n",
    "line_count = sum([sum([len(open(os.path\n",
    "                                .join(root, file)).readlines()) for file in files]) for root, dirs, files in\n",
    "                  os.walk(base_path)])\n",
    "line_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.101415700Z",
     "start_time": "2024-02-24T11:49:29.081604800Z"
    }
   },
   "id": "3ec59f5b464d6237",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 1057 words in the thesaurus. \n",
    "\n",
    "> Note: Some words can exist in multiple sections, so the actual number of unique words is less than 1057."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba880ee49fcbde1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Word Embeddings\n",
    "\n",
    "We can get different embedding models from various sources such as `GloVe`, `fastText`, `Word2Vec`, `BERT`. \n",
    "Even better from models such as `Gemini` or `OpenAI's` `text-embedding-3` which are more advanced and can provide better embeddings.\n",
    "\n",
    "In our case, we will use the brand new `Nomic` embeddings and more specifically the `nomic-embed-text-v1`,\n",
    "a text embedding model that supports variable output sizes.\n",
    "Source: [Nomic Embeddings Descriptions](https://docs.nomic.ai/atlas/models/text-embedding).\n",
    "\n",
    "Noteworthy to mention is that the `nomic-embed-text-v1` has a MTEB Score of 62.39 which is a very good score and close to the best score\n",
    "of the `text-embedding-3-large` which has a MTEB Score of 64.6 of OPENAI with the same input sequence length of 8192.\n",
    "However, the `nomic-embed-text-v1` is open-source and free to use, with a free trial of 1M tokens.\n",
    "\n",
    "> Note: The nomic-embed-text-v1.5 model was also tested, \n",
    "> but it did not provide better embeddings for the thesaurus according to some background tests for classification and clustering tasks.\n",
    "\n",
    "More Details here : [Nomic Embeddings](https://blog.nomic.ai/posts/nomic-embed-text-v1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ca9c53585b2d691"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will save two different versions of the embeddings. \n",
    "One will be embeddings with a task type specialized for clustering, \n",
    "and one will be embeddings with a task type specialized for classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dee3c4906a00d915"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best option to use Nomic Embed is through the production-ready Nomic Embedding API.\n",
    "\n",
    "We can access the API via the python package `nomic` which is a Python client for the Nomic API.\n",
    "We will access them nomic library to get the embeddings for the words in the thesaurus.\n",
    "\n",
    "We can get a Nomic Atlas API key at [Nomic Atlas](https://atlas.nomic.ai/) after following the instructions to create an account and get the API key.\n",
    "\n",
    "Then in our terminal we need to run the following command to set the API key as an environment variable\n",
    "```bash\n",
    "nomic login ```YOUR_API_KEY```\n",
    "```\n",
    "\n",
    "With the above set, we can now get the embedding model and use it to get the embeddings for the words in the thesaurus."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2de02e7c969ac20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will store the embeddings to a vector database using `chromadb` which is a vector database that can store and query embeddings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41d468a8f1c5a471"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection_clustering = client.get_or_create_collection(name=\"nomic_clustering_v1\")\n",
    "collection_classification = client.get_or_create_collection(name=\"nomic_classification_v1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.102414200Z",
     "start_time": "2024-02-24T11:49:29.099811900Z"
    }
   },
   "id": "c5a9facda5b176b5",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now retrieve the words along with their respective classes, divisions, and sections from the hierarchy and store them in a DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7760e7bf90e41a59"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"hierarchy.json\", \"r\") as f:\n",
    "    categories = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.108413400Z",
     "start_time": "2024-02-24T11:49:29.102414200Z"
    }
   },
   "id": "39176650dee26687",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now retrieve the words along with their respective classes, divisions, and sections from the hierarchy and store them in a DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b42abeddbfb56ba7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                  word                                            class  \\\n0            Existence              WORDS EXPRESSING ABSTRACT RELATIONS   \n1          Inexistence              WORDS EXPRESSING ABSTRACT RELATIONS   \n2       Substantiality              WORDS EXPRESSING ABSTRACT RELATIONS   \n3     Unsubstantiality              WORDS EXPRESSING ABSTRACT RELATIONS   \n4       Intrinsicality              WORDS EXPRESSING ABSTRACT RELATIONS   \n...                ...                                              ...   \n1052            Clergy  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n1053             Laity  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n1054              Rite  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n1055        Canonicals  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n1056            Temple  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n\n     division               section  \n0         N/A             EXISTENCE  \n1         N/A             EXISTENCE  \n2         N/A             EXISTENCE  \n3         N/A             EXISTENCE  \n4         N/A             EXISTENCE  \n...       ...                   ...  \n1052      N/A  RELIGIOUS AFFECTIONS  \n1053      N/A  RELIGIOUS AFFECTIONS  \n1054      N/A  RELIGIOUS AFFECTIONS  \n1055      N/A  RELIGIOUS AFFECTIONS  \n1056      N/A  RELIGIOUS AFFECTIONS  \n\n[1057 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>class</th>\n      <th>division</th>\n      <th>section</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Existence</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Inexistence</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Substantiality</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unsubstantiality</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Intrinsicality</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>Clergy</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>Laity</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>Rite</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>Canonicals</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>Temple</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n  </tbody>\n</table>\n<p>1057 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def json_to_df(categories, class_name=None, division_name='N/A'):\n",
    "    df = pd.DataFrame()\n",
    "    for key, value in categories.items():\n",
    "        # Check if the current key is a class\n",
    "        if 'divisions' in value and 'sections' in value:\n",
    "            class_df = json_to_df(value['divisions'], class_name=key)\n",
    "            section_df = json_to_df(value['sections'], class_name=key,\n",
    "                                    division_name='N/A')  # Reset division for sections\n",
    "            df = pd.concat([df, class_df, section_df], ignore_index=True)\n",
    "        elif isinstance(value, dict):  # This is a division or a section\n",
    "            if 'sections' in value:  # This is a division\n",
    "                sub_df = json_to_df(value['sections'], class_name=class_name, division_name=key)\n",
    "            else:  # This is a section without a division\n",
    "                sub_df = json_to_df(value, class_name=class_name, division_name=division_name)\n",
    "            df = pd.concat([df, sub_df], ignore_index=True)\n",
    "        else:  # This is the actual list of words\n",
    "            for word in value:\n",
    "                new_row = pd.DataFrame({\n",
    "                    \"word\": [word],\n",
    "                    \"class\": [class_name],\n",
    "                    \"division\": [division_name],\n",
    "                    \"section\": [key],\n",
    "                })\n",
    "                df = pd.concat([df, new_row], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "categories_df = json_to_df(categories)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "categories_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.265547700Z",
     "start_time": "2024-02-24T11:49:29.109413500Z"
    }
   },
   "id": "6f47cabc49744120",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now use the `nomic` library to get the embeddings for the words in the thesaurus with the `nomic-embed-text-v1` model\n",
    "and the specialized task type for clustering and classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "917e51650018a920"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nomic_embeddings_clustering = embed.text(\n",
    "    texts=categories_df['word'].tolist(),\n",
    "    model='nomic-embed-text-v1',\n",
    "    task_type='clustering'\n",
    ")\n",
    "\n",
    "nomic_embeddings_classification = embed.text(\n",
    "    texts=categories_df['word'].tolist(),\n",
    "    model='nomic-embed-text-v1',\n",
    "    task_type='classification'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.265753900Z",
     "start_time": "2024-02-24T11:49:29.259653800Z"
    }
   },
   "id": "7c6eac001e6fb98e",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's separate the different embeddings and store them in the DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f0365a4d15f9fae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categories_df['embedding_clustering'] = nomic_embeddings_clustering['embeddings']\n",
    "categories_df['embedding_classification'] = nomic_embeddings_classification['embeddings']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.267263800Z",
     "start_time": "2024-02-24T11:49:29.263547700Z"
    }
   },
   "id": "9fbea3035b04695d",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "With that done, let's take a look at the DataFrame with the embeddings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9352a37eea47e5d6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                  word                                            class  \\\n0            Existence              WORDS EXPRESSING ABSTRACT RELATIONS   \n1          Inexistence              WORDS EXPRESSING ABSTRACT RELATIONS   \n2       Substantiality              WORDS EXPRESSING ABSTRACT RELATIONS   \n3     Unsubstantiality              WORDS EXPRESSING ABSTRACT RELATIONS   \n4       Intrinsicality              WORDS EXPRESSING ABSTRACT RELATIONS   \n...                ...                                              ...   \n1052            Clergy  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n1053             Laity  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n1054              Rite  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n1055        Canonicals  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n1056            Temple  WORDS RELATING TO THE SENTIENT AND MORAL POWERS   \n\n     division               section  \n0         N/A             EXISTENCE  \n1         N/A             EXISTENCE  \n2         N/A             EXISTENCE  \n3         N/A             EXISTENCE  \n4         N/A             EXISTENCE  \n...       ...                   ...  \n1052      N/A  RELIGIOUS AFFECTIONS  \n1053      N/A  RELIGIOUS AFFECTIONS  \n1054      N/A  RELIGIOUS AFFECTIONS  \n1055      N/A  RELIGIOUS AFFECTIONS  \n1056      N/A  RELIGIOUS AFFECTIONS  \n\n[1057 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>class</th>\n      <th>division</th>\n      <th>section</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Existence</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Inexistence</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Substantiality</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unsubstantiality</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Intrinsicality</td>\n      <td>WORDS EXPRESSING ABSTRACT RELATIONS</td>\n      <td>N/A</td>\n      <td>EXISTENCE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>Clergy</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>Laity</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>Rite</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>Canonicals</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>Temple</td>\n      <td>WORDS RELATING TO THE SENTIENT AND MORAL POWERS</td>\n      <td>N/A</td>\n      <td>RELIGIOUS AFFECTIONS</td>\n    </tr>\n  </tbody>\n</table>\n<p>1057 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.276270200Z",
     "start_time": "2024-02-24T11:49:29.267263800Z"
    }
   },
   "id": "102c12f61ba7e596",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, in order to efficiently store the class, division, and section of each word, we will prepare a dictionary with the word as the key and the class, division, and section as the values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d0b648c5d895ee4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a dictionary where each word maps to its corresponding class, division, and section\n",
    "words_dict = categories_df.groupby('word').agg('first').to_dict('index')\n",
    "\n",
    "# Create the metadata list using list comprehension\n",
    "metadatas = [\n",
    "    {\n",
    "        \"class\": words_dict[word]['class'],\n",
    "        \"division\": words_dict[word].get('division', 'N/A'),\n",
    "        \"section\": words_dict[word]['section']\n",
    "    }\n",
    "    for word in categories_df['word'] if word in words_dict\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.326018700Z",
     "start_time": "2024-02-24T11:49:29.276270200Z"
    }
   },
   "id": "8d9fc334e348d7f1",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the metadata in place, we can now add the embeddings to the vector database using `chromadb` into two different collections, one for clustering and one for classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5439a0d28512984b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "collection_clustering.add(\n",
    "    documents=categories_df['word'].tolist(),\n",
    "    embeddings=nomic_embeddings_clustering['embeddings'],\n",
    "    metadatas=metadatas,\n",
    "    ids = [f\"word_{i}\" for i in range(categories_df.shape[0])]\n",
    ")\n",
    "\n",
    "collection_classification.add(\n",
    "    documents=categories_df['word'].tolist(),\n",
    "    embeddings=nomic_embeddings_classification['embeddings'],\n",
    "    metadatas=metadatas,\n",
    "    ids = [f\"word_{i}\" for i in range(categories_df.shape[0])]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:49:29.326018700Z",
     "start_time": "2024-02-24T11:49:29.295419800Z"
    }
   },
   "id": "8bee8030e4ca31d3",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we have successfully stored the embeddings to a vector database using `chromadb` and we can use them for clustering and classification tasks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3feb9533a9d4166"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
